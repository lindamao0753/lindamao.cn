<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://lindamao.cn</id>
    <title>lindamao</title>
    <updated>2023-02-14T12:41:09.683Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://lindamao.cn"/>
    <link rel="self" href="https://lindamao.cn/atom.xml"/>
    <logo>https://lindamao.cn/images/avatar.png</logo>
    <icon>https://lindamao.cn/favicon.ico</icon>
    <rights>All rights reserved 2023, lindamao</rights>
    <entry>
        <title type="html"><![CDATA[Winsdows11跳过联网]]></title>
        <id>https://lindamao.cn/post/winsdows11-tiao-guo-lian-wang/</id>
        <link href="https://lindamao.cn/post/winsdows11-tiao-guo-lian-wang/">
        </link>
        <updated>2023-02-10T06:39:39.000Z</updated>
        <content type="html"><![CDATA[<p>现在新买回来的电脑原厂几乎都是win11系统 如果联网就等于激活了 如果激活后在验机的时候出现问题将不好进行退换 这里提供winsdow11跳过联网的方法<br>
第1步：选国家（地区）<br>
第2步：选输入法，点是<br>
第3步：选第二种输入法，可以“跳过”<br>
第4步：联网界面：按下键盘的Shift+F10或Fn+Shift+F10<br>
（能插网线的电脑先不插网线，过程可能会自动重启电脑）<br>
会弹出管理员框，用键盘输入：taskmgr  再按回车键（Enter）<br>
此时会出现任务管理器 点击详细信息<br>
找到网络连接流，鼠标右键点击——结束任务，即可跳过联网<br>
到这一步 已经跳过联网了 后面的步骤根据自己的电脑的需求进行修改 验完机可以再联网</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[消息中间件]]></title>
        <id>https://lindamao.cn/post/xiao-xi-zhong-jian-jian/</id>
        <link href="https://lindamao.cn/post/xiao-xi-zhong-jian-jian/">
        </link>
        <updated>2022-09-23T12:18:36.000Z</updated>
        <content type="html"><![CDATA[<h1 id="消息中间件">消息中间件</h1>
<p><strong>定义</strong><br>
消息中间件属于分布式系统中一个字系统，关注于数据的发送和接收，利用高效可靠的异步信息传递机制对分布式系统中的其余各个子系统进行集成。</p>
<figure data-type="image" tabindex="1"><img src="https://img-blog.csdnimg.cn/20210624200708280.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzU2MTA2MA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" loading="lazy"></figure>
<p><strong>为什么要用消息中间件</strong><br>
假设一个电商交易的场景，用户下单之后调用库存系统减库存，然后需要调用物流系统进行发货，如果交易、库存、物流是属于一个系统的，那么就是接口调用。但是随着系统的发展，各个模块越来越庞大、业务逻辑越来越复杂，必然是要做服务化和业务拆分的。这个时候就需要考虑这些系统之间如何交互，第一反应就是RPC（Remote Procedure Call）。系统继续发展，可能一笔交易后续需要调用几十个接口来执行业务，比如还有风控系统、短信服务等等。这个时候就需要消息中间件登场来解决问题了。</p>
<p>所以消息中间件主要解决分布式系统之间信息的传递，同时为分布式系统中其他子系统提供了伸缩性和拓展性。为系统带来了：<br>
低耦合，不管是程序还是模块之间，使用信息中间件进行间接通信。</p>
<p>异步通信能力，使得子系统之间得以充分执行之间的逻辑而无需等待。</p>
<p>缓冲能力：消息中间件像是一个巨大的蓄水池，将高峰期大量的请求存储下来，慢慢交给后台进行处理，对于秒杀业务来说尤为重要。</p>
<p><strong>和RPC有何区别？</strong><br>
RPC和消息中间件的场景的差异很大程度上在于”依赖性“和”同步性“。</p>
<p>消息中间件出现以后对于交易场景可能是调用库存中心等强依赖系统执行业务，之后发布一条消息（这条消息存储于消息中间件中）。像是短信通知服务、数据统计服务等等都是依赖于消息中间件去消费这条消息来完成自己的业务逻辑。</p>
<p>RPC方式是典型的同步方式，让远程调用像本地调用。消息中间件方式属于异步方式。消息队列是系统级、模块级的通信。RPC是对象级、函数级通信。</p>
<p><strong>消息中间件使用场景</strong><br>
<strong>异步处理</strong><br>
场景说明：用户注册后，需要发注册邮件和注册短信。传统的做法有两种：<br>
（1）串行方式：将注册信息写入数据库成功后，发送注册邮件，再发送注册短信。以上三个任务全部完成后，返回给客户端。</p>
<figure data-type="image" tabindex="2"><img src="https://img-blog.csdnimg.cn/20210624202633404.png" alt="在这里插入图片描述" loading="lazy"></figure>
<p>（2）并行方式：将注册信息写入数据库成功后，发送注册邮件的同时，发送注册短信。以上三个任务完成后，返回给客户端。与串行的差别是，并行的方式可以提高处理的时间。</p>
<figure data-type="image" tabindex="3"><img src="https://img-blog.csdnimg.cn/20210624202908586.png" alt="在这里插入图片描述" loading="lazy"></figure>
<p>假设三个业务节点每个使用50毫秒钟，不考虑网络等其他开销，则串行方式的时间是150毫秒，并行的时间可能是100毫秒。</p>
<p>小结：如以上案例描述，传统的方式系统的性能（并发量，吞吐量，响应时间）会有瓶颈。如何解决这个问题呢？<br>
引入消息队列，将不是必须的业务逻辑，异步处理。</p>
<figure data-type="image" tabindex="4"><img src="https://img-blog.csdnimg.cn/20210624203003151.png" alt="img" loading="lazy"></figure>
<p><strong>应用解耦</strong><br>
场景说明：用户下单后，订单系统需要通知库存系统。传统的做法是订单系统调用库存系统的接口。<br>
传统模式的缺点：<br>
（1）假如库存系统无法访问，则订单减库存将失败，从而导致订单失败。<br>
（2）订单系统与库存系统耦合。</p>
<figure data-type="image" tabindex="5"><img src="https://img-blog.csdnimg.cn/20210624203743355.png" alt="在这里插入图片描述" loading="lazy"></figure>
<p>如何解决以上问题呢？引入应用消息队列后的方案<br>
订单系统：用户下单后，订单系统完成持久化处理，将消息写入消息队列，返回用户订单下单成功。<br>
库存系统：订阅下单的消息，采用拉/推的方式，获取下单信息，库存系统根据下单信息，进行库存操作。</p>
<figure data-type="image" tabindex="6"><img src="https://img-blog.csdnimg.cn/20210624204123569.png" alt="在这里插入图片描述" loading="lazy"></figure>
<p>假如：在下单时库存系统不能正常使用。也不影响正常下单，因为下单后，订单系统写入消息队列就不再关心其他的后续操作了。实现订单系统与库存系统的应用解耦。</p>
<p><strong>流量削峰</strong><br>
流量削峰也是消息队列中的常用场景，一般在秒杀或团抢活动中使用广泛。<br>
应用场景：秒杀活动，一般会因为流量过大，导致流量暴增，应用挂掉。为解决这个问题，一般需要在应用前端加入消息队列：可以控制活动的人数；可以缓解短时间内高流量压垮应用。</p>
<figure data-type="image" tabindex="7"><img src="https://img-blog.csdnimg.cn/20210624205023329.png" alt="在这里插入图片描述" loading="lazy"></figure>
<p>用户的请求，服务器接收后，首先写入消息队列。假如消息队列长度超过最大数量，则直接抛弃用户请求或跳转到错误页面；秒杀业务根据消息队列中的请求信息，再做后续处理。</p>
<p><strong>日志处理</strong><br>
日志处理是指将消息队列用在日志处理中，比如Kafka的应用，解决大量日志传输的问题。架构简化如下：</p>
<figure data-type="image" tabindex="8"><img src="https://img-blog.csdnimg.cn/20210624205131419.png" alt="在这里插入图片描述" loading="lazy"></figure>
<p>日志采集客户端，负责日志数据采集，定时写入Kafka队列；<br>
Kafka消息队列：负责日志数据的接收，存储和转发；<br>
日志处理应用：订阅并消费kafka队列中的日志数据。</p>
<p><strong>信息通讯</strong><br>
消息通讯是指，消息队列一般都内置了高效的通信机制，因此也可以用在纯的消息通讯。比如实现点对点消息队列，或者聊天室等。</p>
<p>点对点通讯：客户端A和客户端B使用同一队列，进行消息通讯。<br>
聊天室通讯：客户端A，客户端B，客户端N订阅同一主题，进行消息发布和接收。实现类似聊天室效果。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[数据库连接超时问题解决]]></title>
        <id>https://lindamao.cn/post/shu-ju-ku-lian-jie-chao-shi-wen-ti-jie-jue/</id>
        <link href="https://lindamao.cn/post/shu-ju-ku-lian-jie-chao-shi-wen-ti-jie-jue/">
        </link>
        <updated>2022-08-16T07:13:08.000Z</updated>
        <content type="html"><![CDATA[<p>今天上班在产线上遇到了这么一个bug<br>
com.mysql.jdbc.exceptions.jdbc4.CommunicationsException: Communications link failure<br>
数据库连接超时是指当服务连接到数据库但不对其做任何操作时等待到一定时间之后，这个链接就会与数据库断开，当再次对数据库进行操作时会报数据库连接超时或者连接关闭异常。mysql的连接默认最长等待时间为28800s也就是8个小时。<br>
根据实施反应在出现这个异常之后的时间里服务是正常的但是对DB的查询无法正常执行<br>
问题排查<br>
1.先检查DB的连接配置 公司用的是mybaits 这里根据自身实际情况再进行排查<br>
查看mysql连接最大超时时间<br>
<code>show global variables like '%timeout%';</code><br>
发现产线上的wait_timeout为1800s 也就是30min 这里开始怀疑是不是事务的执行超过了30min 但是还没有有力证据证明<br>
2.紧接着根据日志排查发现出事情的那天相关任务的执行耗时超过了30min 在线上拿到以往没出事情的日志来看任务的执行时间都是少于30min 也就证实了上述猜想是对的 正常是把wait_timeou参数调大一点就行了<br>
跟组长讨论了以往的情况 了解到以前也出现过类似情况 而解决方法也正如我上述所述<br>
修改完参数大小之后重启服务 之后根据实施反馈上述问题再也没出现过<br>
一般情况下 等待超时timeout为 28800s 也就是8小时 事务的执行完成 一般都是在这个时间段内<br>
注意点：<br>
1.一般情况下谨慎修改产线程参数<br>
2.wait_timeout 和interactive_time需要同时修改才能生效</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Git]]></title>
        <id>https://lindamao.cn/post/git/</id>
        <link href="https://lindamao.cn/post/git/">
        </link>
        <updated>2022-07-12T07:32:32.000Z</updated>
        <content type="html"><![CDATA[<h1 id="技巧1优化配置">技巧1:优化配置</h1>
<p>Git 在全局、用户和本地级别上都是高度可配置的。</p>
<p><a href="https://git-scm.com/docs/git-config">git配置文档</a></p>
<h2 id="查找顺序">查找顺序</h2>
<p>每个设置都可以被覆盖：</p>
<pre><code>本地级别:
项目文件夹/.git/config
用户级别:
用户目录/.config/git
用户目录/.gitconfig
全局级别：
git目录/etc/gitconfig
</code></pre>
<h2 id="修改配置">修改配置</h2>
<pre><code class="language-bash"># 全局设置
git config --global &lt;keypath&gt; &lt;value&gt;
# 本地设置
git config &lt;keypath&gt; &lt;value&gt;
</code></pre>
<h2 id="显示当前设置">显示当前设置</h2>
<pre><code class="language-bash"># 显示当前设置及其来源
git config --list --show-origin
</code></pre>
<h2 id="一些有用的配置">一些有用的配置</h2>
<pre><code class="language-bash"># 设定身份
git config --global user.name&quot;&lt;your name&gt;&quot;
git config --global user.email &lt;your email&gt;
</code></pre>
<h1 id="技巧2别名alias">技巧2:别名(alias)</h1>
<p><a href="%5Bhttps://git-scm.com/book/zh/v2/Git-%E5%9F%BA%E7%A1%80-Git-%E5%88%AB%E5%90%8D%5D(https://git-scm.com/book/zh/v2/Git-%E5%9F%BA%E7%A1%80-Git-%E5%88%AB%E5%90%8D)">Git 别名</a></p>
<p>创建别名来保存常用的git命令：</p>
<pre><code class="language-bash"># 创建别名
git config --global alias.&lt;alias-name&gt; &quot;&lt;git command&gt;&quot;
# 使用别名
git &lt;alias-name&gt; &lt;more optional arguments&gt;
</code></pre>
<h2 id="一些有用的别名">一些有用的别名</h2>
<pre><code class="language-bash"># 撤销上次提交
git config --global alias.undo &quot;reset --soft HEAD^&quot;
# 将暂存区更新修订到上次提交 (不改变提交信息)
git config --global alias.amend &quot;commit --amend --no-edit&quot;
# 压缩的状态输出
git config --global alias.st &quot;status -sb&quot;
# 用 GRAPH 为日志着色
git config --global alias.lg &quot;log --graph --pretty=format:'%Cred%h%Creset -%C(yellow)%d%Creset %s %Cgreen(%cr) %C(bold blue)&lt;%an&gt;%Creset'&quot;
# 删除所有已合并的分支
git config --global alias.rmb &quot;!git branch --merged | grep -v '*' | xargs -n 1 git branch -d&quot;
# 贡献排行
git config --global alias.rank &quot;shortlog -n -s --no-merges&quot;
</code></pre>
<h1 id="技巧-3查找-commits-和更改">技巧 3：查找 Commits 和更改</h1>
<h2 id="通过commits信息查找">通过commits信息查找</h2>
<pre><code class="language-bash"># 通过 commit 信息查找 (所有分支)
git log --all --grep='&lt;search term&gt;'
# 通过 commit 信息查找 (包含 reflog)
git log-g --grep='&lt;search term&gt;'
</code></pre>
<h2 id="通过更改查找">通过更改查找</h2>
<pre><code class="language-bash"># 通过更新的内容查找
git log -S '&lt;search term&gt;'
</code></pre>
<h2 id="通过日期查找">通过日期查找</h2>
<pre><code class="language-bash"># 通过日期范围查找
git log --after='DEC 152019' --until='JAN 102020'
</code></pre>
<h1 id="技巧4添加hunk">技巧4:添加hunk</h1>
<p>git add <filepath> 不仅能添加文件的所有变更， --path / -p 参数还可以交互式暂存区块。</p>
<pre><code class="language-bash"># 补丁命令
y = 暂存区块
n = 不暂存这个区块
q = 退出
a = 暂存当前文件的此区块以及所有剩余区块
d = 不暂存当前文件的此区块以及所有剩余区块
/ = 查找区块 (正则表达式)
s = 划分成更小的区块
e = 手动编辑区块
? = 打印帮助说明
g = 选择要前往的区块
j = 将区块设为未定，查看下一个未定区块
J = 将区块设为未定，查看下一个区块
k = 将区块设为未定，查看上一个未定区块
J = 将区块设为未定，查看下一个区块
</code></pre>
<h1 id="技巧-5-储藏stash更改而不提交">技巧 5： 储藏（stash）更改而不提交</h1>
<p>stash 将当前的更改临时搁置起来。在它的帮助下，可以返回当前状态的索引，并能在稍后应用已储藏的更改。</p>
<p>默认情况下，仅储藏当前跟踪文件中的更改，新文件将被忽略。</p>
<p>我们可以独立地创建和应用多个 stash。</p>
<p><a href="%5Bhttps://git-scm.com/book/zh/v2/Git-%E5%B7%A5%E5%85%B7-%E5%82%A8%E8%97%8F%E4%B8%8E%E6%B8%85%E7%90%86%5D(https://git-scm.com/book/zh/v2/Git-%E5%B7%A5%E5%85%B7-%E5%82%A8%E8%97%8F%E4%B8%8E%E6%B8%85%E7%90%86)">Git 工具 - 储藏与清理</a></p>
<h2 id="创建">创建</h2>
<pre><code class="language-bash"># 创建新的 STASH
git stash
# 创建新的 STASH (包含未追踪的更改)
git stash -u/--include-untracked
# 创建新的 STASH 并命名
git stash save&quot;&lt;stash name&gt;&quot;
# 交互式储藏
git stash -p
</code></pre>
<h2 id="罗列">罗列</h2>
<pre><code class="language-bash"># 列出所有的 STASH (为其他命令提供 &quot;n&quot;)
git stash list
</code></pre>
<h2 id="浏览">浏览</h2>
<pre><code class="language-bash"># 浏览 STASH 内容
git stash show
# 浏览 STASH 差异
git stash show -p
</code></pre>
<h2 id="应用">应用</h2>
<pre><code class="language-bash"># 应用上一个 STASH (删除 stash)
git stash pop
# 应用上一个 STASH (保留 stash)
git stash apply
# 应用特定的 STASH (n = stash 列表序号)
git stash pop/apply stash@{n}
# 从 STASH 创建新的分支 (n = stash 列表序号)
git stash branch &lt;newbranch name&gt; stash@{n}
# 从 STASH 应用单个文件 (n = stash 列表序号)
git checkout stash@{n} -- &lt;filepath&gt;
</code></pre>
<h2 id="清理">清理</h2>
<pre><code class="language-bash"># 删除特定的 STASH (n = stash 列表序号)
git stash drop stash@{n}
# 删除所有的 STASH
git stash clear
</code></pre>
<h1 id="技巧-6空运行dry-run">技巧 6：空运行（Dry Run）</h1>
<p>许多 git 操作可能具有破坏性，例如， git clean -f 将删除所有未跟踪的文件，而且无法恢复。</p>
<p>要避免出现这种灾难性的结果，许多命令都支持 <em>dry-run</em> ，可以在实际产生结果前对其进行检查。不过遗憾的是，使用的选项不完全一致：</p>
<pre><code class="language-bash">git clean -n/--dry-run
git add -n/--dry-run
git rm -n/--dry-run
# GIT MERGE 模拟 DRY-RUN
git merge --no-commit --no-ff &lt;branch&gt;
git diff --cached
git merge --abort
</code></pre>
<h1 id="技巧-7安全强制推送">技巧 7：安全强制推送</h1>
<p>在处理旧的 commit、创建新的 head 等情况时时很容易弄乱分支。 git push --force 可以覆盖远程变更，但不应该这样做！</p>
<p>git push --force 是一种具有破坏性且危险的操作，因为它无条件生效，并且会破坏其他提交者已经推送的所有 commit。这对于其他人的代码仓库来说不一定是致命的，但是改变历史记录并影响其他人并不是一个好主意。</p>
<p>更好的选择是使用 git push --force-with-lease 。</p>
<p>git 不会无条件地覆盖上游的远程仓库，而是检查是否有本地不可用的远程更改。如果有，它会失败并显示一条“stale info”消息，并告诉我们需要先运行 git fetch 。</p>
<p><a href="https://git-scm.com/docs/git-push#Documentation/git-push.txt---force-with-leaseltrefnamegt">git push</a></p>
<h1 id="技巧-8修改-commit-信息">技巧 8：修改 commit 信息</h1>
<p>Commit 是不可变的，且不能更改。不过可以用一条新的 commit 信息修订现有的 commit，这会覆盖原始 commit，因此请勿在已推送的 commit 中使用它。</p>
<pre><code class="language-bash">git commit --amend -m &quot;&lt;new commit message&gt;&quot;
</code></pre>
<h1 id="技巧-9修改历史">技巧 9：修改历史</h1>
<p>修改代码仓库的历史不仅限于修改上次提交信息，使用 git rebase 可以修改多个提交：</p>
<pre><code class="language-bash"># 提交的范围
git rebase -i/--interactive HEAD~&lt;number of commits&gt;
# 该 hash 之后的所有提交
git rebase -i/--interactive &lt;commit hash&gt;
</code></pre>
<p>在配置的编辑器中倒序列出所有的 commit，像这样：</p>
<pre><code class="language-bash">#&lt;command&gt;&lt;commit hash&gt;&lt;commit message&gt;
pick5df8fbc revamped logic
pick ca5154e README typos fixed
pick a104aff added awesome new feature
</code></pre>
<p>通过更改编辑器中的实际内容，可以为 git 提供一个方案，来说明如何进行 rebase：</p>
<pre><code class="language-bash"># p, pick = 使用提交而不更改
# r, reword = 修改提交信息
# e, edit = 编辑提交
# s, squash = 汇合提交
# f, fixup = 类似 &quot;squash&quot;，但是会丢弃提交信息
# x, exec = 运行命令 (其余行)
# d, drop = 移除提交
</code></pre>
<p>保存编辑器后，git 将运行该方案以重写历史记录。</p>
<p>e, edit 会暂停 rebase，就可以编辑代码仓库的当前状态。完成编辑后，运行 git rebase --continue 。</p>
<p>如果过程中出现问题（例如合并冲突），我们需要重新开始，可以使用 git rebase --abort 。</p>
<p><a href="https://git-scm.com/docs/git-rebase">git-rebase</a></p>
<h1 id="技巧-10存档跟踪文件">技巧 10：存档跟踪文件</h1>
<p>可以使用不同格式（ zip 或 tar ）来压缩特定引用的跟踪文件：</p>
<pre><code class="language-bash">git archive --format&lt;format&gt; --output&lt;filename&gt; &lt;ref&gt;
</code></pre>
<p><ref> 可以是一个分支、commit hash 或者一个标签。</p>
<p><a href="https://git-scm.com/docs/git-archive">git-archive</a></p>
<h1 id="额外提醒单破折号">额外提醒：单破折号</h1>
<p>有一个快捷方式可以表示刚用过的分支：一个单破折号 -</p>
<pre><code class="language-bash">git checkout my-branch
# 当前分支：my-branch
&lt;dosome git operations, e.g. adding/commiting&gt;
git checkout develop
# 当前分支：develop
git merge -
# 将 my-branch 合并到 develop
</code></pre>
<p>单破折号等同于 @{-1} 。</p>
<p><a href="https://git-scm.com/docs/git-checkout#Documentation/git-checkout.txt-ltbranchgt">git-checkout</a></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[RPC]]></title>
        <id>https://lindamao.cn/post/rpc/</id>
        <link href="https://lindamao.cn/post/rpc/">
        </link>
        <updated>2022-06-09T12:18:47.000Z</updated>
        <content type="html"><![CDATA[<h2 id="什么是-rpc">什么是 RPC？</h2>
<p>RPC 的全称是 Remote Procedure Call，即远程过程调用。简单解读字面上的意思，远程肯定是指要跨机器而非本机，所以需要用到网络编程才能实现，但是不是只要通过网络通信访问到另一台机器的应用程序，就可以称之为 RPC 调用了？显然并不够。</p>
<p><strong>我理解的 RPC 是帮助我们屏蔽网络编程细节，实现调用远程方法就跟调用本地一样的体验</strong>，我们不需要因为这个方法是远程调用就需要编写很多与业务无关的代码。</p>
<p>这就好比建在小河上的桥一样连接着河的两岸，如果没有小桥，我们需要通过划船、绕道等其他方式才能到达对面，但是有了小桥之后，我们就能像在路面上一样行走到达对面，并且跟在路面上行走的体验没有区别。所以我认为，RPC 的作用就是体现在这样两个方面：</p>
<ul>
<li>屏蔽远程调用跟本地调用的区别，让我们感觉就是调用项目内的方法；</li>
<li>隐藏底层网络通信的复杂性，让我们更专注于业务逻辑。</li>
</ul>
<h2 id="rpc-通信流程">RPC 通信流程</h2>
<p>理解了什么是 RPC，接下来我们讲下 RPC 框架的通信流程，方便我们进一步理解 RPC。</p>
<p>如前面所讲，RPC 能帮助我们的应用透明地完成远程调用，发起调用请求的那一方叫做调用方，被调用的一方叫做服务提供方。为了实现这个的目标，我们就需要在 RPC 框架里面对整个通信细节进行封装，那一个完整的RPC 会涉及到哪些步骤呢？</p>
<p>我们已经知道 RPC 是一个远程调用，那肯定就需要通过网络来传输数据，并且 RPC 常用于业务系统之间的数据交互，需要保证其可靠性，所以 <strong>RPC 一般默认采用 TCP 来传输</strong>。我们常用的 HTTP 协议也是建立在 TCP 之上的。</p>
<p>网络传输的数据必须是二进制数据，但调用方请求的出入参数都是对象。对象是肯定没法直接在网络中传输的，需要提前把它转成可传输的二进制，并且要求转换算法是可逆的，这个过程我们一般叫做“序列化”。</p>
<p>调用方持续地把请求参数序列化成二进制后，经过 TCP 传输给了服务提供方。服务提供方从 TCP 通道里面收到二进制数据，那如何知道一个请求的数据到哪里结束，是一个什么类型的请求呢？</p>
<p>在这里我们可以想想高速公路，它上面有很多出口，为了让司机清楚地知道从哪里出去，管理部门会在路上建立很多指示牌，并在指示牌上标明下一个出口是哪里、还有多远。那回到数据包识别这个场景，我们是不是也可以建立一些“指示牌”，并在上面标明数据包的类型和长度，这样就可以正确的解析数据了。确实可以，并且我们把数据格式的约定内容叫做“协议”。大多数的协议会分成两部分，分别是数据头和消息体。数据头一般用于身份识别，包括协议标识、数据大小、请求类型、序列化类型等信息；消息体主要是请求的业务参数信息和扩展属性等。</p>
<p>根据协议格式，服务提供方就可以正确地从二进制数据中分割出不同的请求来，同时根据请求类型和序列化类型，把二进制的消息体逆向还原成请求对象。这个过程叫作“反序列化”。</p>
<p>服务提供方再根据反序列化出来的请求对象找到对应的实现类，完成真正的方法调用，然后把执行结果序列化后，回写到对应的 TCP 通道里面。调用方获取到应答的数据包后，再反序列化成应答对象，这样调用方就完成了一次 RPC 调用。</p>
<p><strong>那上述几个流程就组成了一个完整的 RPC 吗？</strong></p>
<p>在我看来，还缺点东西。因为对于研发人员来说，这样做要掌握太多的 RPC 底层细节，需要手动写代码去构造请求、调用序列化，并进行网络调用，整个 API 非常不友好。</p>
<p>那我们有什么办法来简化 API，屏蔽掉 RPC 细节，让使用方只需要关注业务接口，像调用本地一样来调用远程呢？</p>
<p>如果你了解 Spring，一定对其 AOP 技术很佩服，其核心是采用动态代理的技术，通过字节码增强对方法进行拦截增强，以便于增加需要的额外处理逻辑。其实这个技术也可以应用到 RPC 场景来解决我们刚才面临的问题。</p>
<p><strong>由服务提供者给出业务接口声明，在调用方的程序里面，RPC 框架根据调用的服务接口提前生成动态代理实现类，并通过依赖注入等技术注入到声明了该接口的相关业务逻辑里面。该代理实现类会拦截所有的方法调用，在提供的方法处理逻辑里面完成一整套的远程调用，并把远程调用结果返回给调用方，这样调用方在调用远程方法的时候就获得了像调用本地接口一样的体验。</strong></p>
<p>到这里，一个简单版本的 RPC 框架就实现了。上述流程如下图：</p>
<figure data-type="image" tabindex="1"><img src="https://img-blog.csdnimg.cn/20200917105417654.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ZhbmdtZW5nMTk5Nw==,size_16,color_FFFFFF,t_70#pic_left" alt="在这里插入图片描述" loading="lazy"></figure>
<h2 id="rpc-在架构中的位置">RPC 在架构中的位置</h2>
<p>围绕 RPC 我们讲了这么多，那 RPC 在架构中究竟处于什么位置呢？</p>
<p>如刚才所讲，RPC 是解决应用间通信的一种方式，而无论是在一个大型的分布式应用系统还是中小型系统中，应用架构最终都会从“单体”演进成“微服务化”，整个应用系统会被拆分为多个不同功能的应用，并将它们部署在不同的服务器中，而应用之间会通过 RPC 进行通信，可以说 <strong>RPC 对应的是整个分布式应用系统，就像是“经络”一样的存在</strong>。</p>
<p>那么如果没有 RPC，我们现实中的开发过程是怎样的一个体验呢？</p>
<p>所有的功能代码都会被我们堆砌在一个大项目中，开发过程中你可能要改一行代码，但改完后编译会花掉你 2 分钟，编译完想运行起来验证下结果可能要 5 分钟，是不是很酸爽？更难受的是在人数比较多的团队里面，多人协同开发的时候，如果团队其他人把接口定义改了，你连编译通过的机会都没有，系统直接报错，从而导致整个团队的开发效率都会非常低下。而且当我们准备要上线发版本的时候，QA 也很难评估这次的测试范围，为了保险起见我们只能把所有的功能进行回归测试，这样会导致我们上线新功能的整体周期都特别长。</p>
<p>无论你是研发还是架构师，我相信这种系统架构我们肯定都不能接受，那怎么才能解决这个问题呢？</p>
<p>我们首先都会想到可以采用“分而治之”的思想来进行拆分，但是拆分完的系统怎么保持跟未拆分前的调用方式一样呢？我们总不能因为架构升级，就把所有的代码都推倒重写一遍吧。</p>
<p>**RPC 框架能够帮助我们解决系统拆分后的通信问题，并且能让我们像调用本地一样去调用远程方法。**利用 RPC 我们不仅可以很方便地将应用架构从“单体”演进成“微服务化”，而且还能解决实际开发过程中的效率低下、系统耦合等问题，这样可以使得我们的系统架构整体清晰、健壮，应用可运维度增强。</p>
<p>当然 RPC 不仅可以用来解决通信问题，它还被用在了很多其他场景，比如：MQ、分布式缓存、数据库等。比如下面的应用架构图：</p>
<figure data-type="image" tabindex="2"><img src="https://img-blog.csdnimg.cn/20200917110912736.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ZhbmdtZW5nMTk5Nw==,size_16,color_FFFFFF,t_70#pic_left" alt="在这里插入图片描述" loading="lazy"></figure>
<p>在这个应用中，使用了 MQ 来处理异步流程、Redis 缓存热点数据、MySQL 持久化数据，还有就是在系统中调用另外一个业务系统的接口，对我的应用来说这些都是属于 RPC调用，而 MQ、MySQL 持久化的数据也会存在于一个分布式文件系统中，他们之间的调用也是需要用 RPC 来完成数据交互的。</p>
<p>由此可见，RPC 确实是我们日常开发中经常接触的东西，只是被包装成了各种框架，导致我们很少意识到这就是 RPC，让 RPC 变成了我们最“熟悉的陌生人”。现在，回过头想想，我说 RPC 是整个应用系统的“经络”，这不为过吧？我们真的很有必要学好 RPC，不仅因为 RPC 是构建复杂系统的基石，还是提升自身认知的利器。</p>
<h2 id="总结">总结</h2>
<p>本篇博客讲了下 RPC 的原理，RPC 就是提供一种透明调用机制，让使用者不必显式地区分本地调用和远程调用。RPC 虽然可以帮助开发者屏蔽远程调用跟本地调用的区别，但毕竟涉及到远程网络通信，所以这里还是有很多使用上的区别，比如：</p>
<p>调用过程中超时了怎么处理业务？<br>
什么场景下最适合使用 RPC？<br>
什么时候才需要考虑开启压缩？<br>
无论你是一个初级开发者还是高级开发者，RPC 都应该是你日常开发过程中绕不开的一个话题，所以作为软件开发者的我们，真的很有必要详细地了解 RPC 实现细节。只有这样，才能帮助我们更好地在日常工作中使用 RPC。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Jrebel配置远程热部署]]></title>
        <id>https://lindamao.cn/post/jrebel-pei-zhi-yuan-cheng-re-bu-shu/</id>
        <link href="https://lindamao.cn/post/jrebel-pei-zhi-yuan-cheng-re-bu-shu/">
        </link>
        <updated>2022-04-08T06:36:11.000Z</updated>
        <content type="html"><![CDATA[<h1 id="jrebel配置远程热部署">Jrebel配置远程热部署</h1>
<ul>
<li><a href="https://www.jrebel.com/products/jrebel/learn">官方教程文档</a></li>
</ul>
<h1 id="安装">安装</h1>
<ul>
<li>
<p>下载Jrebel和Xrebel相应的版本。（<a href="https://www.jrebel.com/products/jrebel/download/prev-releases">Jrebel官网下载</a>、<a href="https://www.jrebel.com/products/xrebel/download">Xrebel官网下载</a>）</p>
</li>
<li>
<p>激活地址：</p>
<ul>
<li><code>http://jrebel.cicoding.cn/{GUID}</code></li>
<li><code>https://www.guidgen.com/{GUID}</code></li>
</ul>
</li>
<li>
<p>上传到服务器上，并解压。</p>
</li>
<li>
<p>激活插件：下面两个命令随便一条都行</p>
<pre><code class="language-shell">./bin/activate.sh http://jrebel.cicoding.cn/{GUID} {用户邮箱}
java -jar jrebel.jar -activate http://jrebel.cicoding.cn/{GUID} {用户邮箱}
</code></pre>
</li>
<li>
<p>设置远程密码：</p>
<pre><code class="language-shell">java -jar jrebel.jar -set-remote-password {要设置的密码}
</code></pre>
</li>
</ul>
<h1 id="idea设置">Idea设置</h1>
<ul>
<li>
<p>Idea安装相关插件，详见：<a href="https://mxecy.cn/post/idea-jrebel/">Jrebel配置</a></p>
</li>
<li>
<p>设置远程服务器：<a href="https://manuals.jrebel.com/jrebel/remoteserver/intellij.html">官网配置教程</a></p>
<pre><code class="language-shell">File -&gt; JRebel &amp; Xrebel -&gt; Jrebel Startup -&gt; 勾选[Run on a remote server or VM]
File -&gt; JRebel &amp; Xrebel -&gt; Jrebel Remote Servers -&gt; 点+添加新服务器
</code></pre>
</li>
</ul>
<h1 id="使用">使用</h1>
<ul>
<li>
<p>使用的时候，只需要添加几个启动参数：</p>
<pre><code class="language-shell">-javaagent:{xrebel路径}\xrebel.jar # 启动Xrebel
-agentpath:{jrebel路径}\lib\libjrebel64.so # 启动jrebel
-Drebel.remoting_plugin=true # 启动远程插件
-Drebel.remoting_port={端口号} # 可选，针对没有http的程序才使用，会添加一个jetty容器提供服务。
</code></pre>
</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Liquibase]]></title>
        <id>https://lindamao.cn/post/liquibase/</id>
        <link href="https://lindamao.cn/post/liquibase/">
        </link>
        <updated>2022-03-10T12:12:44.000Z</updated>
        <content type="html"><![CDATA[<h1 id="开始使用-sql-脚本">开始使用 SQL 脚本</h1>
<h2 id="第1步创建一个sql文件夹">第1步创建一个sql文件夹</h2>
<p>在解压的<code>Liquibase</code> 的文件夹中 ，创建一个 <code>sql</code> 文件夹。在这个文件夹中你将放置 <code>Liquibase</code>将跟踪、版本和部署的<code>SQL</code>脚本。</p>
<h2 id="第2步建立一个change-log">第2步建立一个Change Log</h2>
<p>这是一次性步骤，用于配置更改日志以指向将包含 <code>SQL</code> 脚本的 <code>sql</code> 文件夹。在解压的<code>*.zip</code> 或<code>*.tar.gz</code>的 <code>Liquibase</code> 的目录中创建并保存文件名为 <code>myChangeLog.xml</code> 的文件 。<code>myChangeLog.xml</code> 的内容应如下所示：</p>
<pre><code class="language-xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;databaseChangeLog
  xmlns=&quot;http://www.liquibase.org/xml/ns/dbchangelog&quot;
  xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;
  xsi:schemaLocation=&quot;http://www.liquibase.org/xml/ns/dbchangelog
         http://www.liquibase.org/xml/ns/dbchangelog/dbchangelog-3.1.xsd&quot;&gt;

  &lt;includeAll path=&quot;/sql&quot;/&gt;
&lt;/databaseChangeLog&gt;

</code></pre>
<h2 id="第3步在sql文件中新增一个sql脚本">第3步在SQL文件中新增一个SQL脚本</h2>
<p>使用教程设置中的 <code>liquibase.properties</code> 文件以及新创建的<code>myChangeLog.xml</code>，我们现在已准备好开始向 <code>sql</code>文件夹添加<code>SQL</code>脚本。<code>Liquibase</code> 将在文件夹中按字母数字顺序排列脚本。使用以下内容创建 <code>001_create_person_table.sql</code> 并将其保存在 <code>sql</code>文件夹中：</p>
<pre><code class="language-sql">create table PERSON (
    ID int not null,
    FNAME varchar(100) not null
);

</code></pre>
<h2 id="第4步-部署你的第一个修改">第4步 部署你的第一个修改</h2>
<p>现在，我们已准备好部署我们的第一个脚本！打开终端，如果在 <code>UNIX</code>系统上则运行 <code>./liquibase update</code>或 如果在 Windows 上则运行<code>liquibase.bat update</code>。</p>
<h2 id="第5步-检查你的数据库">第5步 检查你的数据库</h2>
<p>您将看到您的数据库现在包含一个名为<code>PERSON</code>的表。要将作为本教程一部分的 <code>H2</code> 数据库写入内容，请打开一个终端，导航到您提取的 <code>Liquibase``*.zip</code> 或 <code>*.tar.gz</code>的文件夹，并运行 <code>java -jar h2-1.4.199.jar</code>注意：输入您下载的 <code>h2*.jar</code> 的特定版本！输入<code>JDBC URL</code>、用户名和密码，从 <code>liquibase.properties</code> 文件输入您根据教程设置创建的属性文件。您会注意到还创建了另外两个表：<code>databasechangeloglock</code>和<code>databasechangeloglock</code>。<code>databasechangelog</code>表包含针对数据库运行的所有更改的列表。<code>databasechangeloglock</code>表用于确保两台计算机不会同时尝试修改数据库。</p>
<h1 id="使用-liquibase-函数入门">使用 Liquibase 函数入门</h1>
<p>本教程使用<code>Liquibase</code>函数。更改将在 <code>XML</code> 中定义，而不是使用 <code>SQL</code>。<code>Liquibase</code> 将根据定义的<code>changeSet(s)</code>生成 <code>SQL</code>，并将该 <code>SQL</code> 部署到目标数据库。所有迁移都在更改日志中显式跟踪和排序。</p>
<h2 id="第一步创建一个changelog文件">第一步创建一个Changelog文件</h2>
<p>database changelog文件是列出所有数据库更改的位置。创建一个名为 <code>myChangeLog.xml</code>的文件，其中包含以下内容：</p>
<pre><code class="language-xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;

&lt;databaseChangeLog
  xmlns=&quot;http://www.liquibase.org/xml/ns/dbchangelog&quot;
  xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;
  xsi:schemaLocation=&quot;http://www.liquibase.org/xml/ns/dbchangelog
         http://www.liquibase.org/xml/ns/dbchangelog/dbchangelog-3.1.xsd&quot;&gt;

&lt;/databaseChangeLog&gt;
</code></pre>
<h2 id="第2步-添加一个change-set">第2步 添加一个Change Set</h2>
<p>每个<code>changeSet</code>都由<code>id</code>属性和<code>author</code>属性进行唯一标识。这两个标记以及更改日志文件的名称和包唯一地标识了更改。如果只需要指定一个<code>id</code>，则很容易意外重用它们，尤其是在处理多个开发人员和代码分支时。包括<code>author</code>属性可最大程度地减少重复的可能性。</p>
<p>将每个<code>changeSet</code>视为要应用于数据库的原子更改。通常最好在<code>changeSet</code>中只包含一个更改，但如果插入多个行时，这些行一起有作为单个事务添加的意义，则允许进行更多更改。<code>Liquibase</code> 将尝试将每个<code>changeSet</code>运行为单个事务，但对于某些命令，许多数据库将静默地提交和回滚事务（创建表、删除表等）。</p>
<pre><code class="language-xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;

&lt;databaseChangeLog
  xmlns=&quot;http://www.liquibase.org/xml/ns/dbchangelog&quot;
  xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;
  xsi:schemaLocation=&quot;http://www.liquibase.org/xml/ns/dbchangelog
         http://www.liquibase.org/xml/ns/dbchangelog/dbchangelog-3.1.xsd&quot;&gt;

    &lt;changeSet id=&quot;1&quot; author=&quot;bob&quot;&gt;
        &lt;createTable tableName=&quot;department&quot;&gt;
            &lt;column name=&quot;id&quot; type=&quot;int&quot;&gt;
                &lt;constraints primaryKey=&quot;true&quot; nullable=&quot;false&quot;/&gt;
            &lt;/column&gt;
            &lt;column name=&quot;name&quot; type=&quot;varchar(50)&quot;&gt;
                &lt;constraints nullable=&quot;false&quot;/&gt;
            &lt;/column&gt;
            &lt;column name=&quot;active&quot; type=&quot;boolean&quot; defaultValueBoolean=&quot;true&quot;/&gt;
        &lt;/createTable&gt;
    &lt;/changeSet&gt;

&lt;/databaseChangeLog&gt;
  
</code></pre>
<h2 id="第3步-运行change-set">第3步 运行change Set</h2>
<p>如果是在<code>UNIX</code>操作系统，可以使用<code>./liquibase update</code>命令来执行<code>myChangeLog.xml</code>；如果是在<code>Windows</code>操作系统上，可以使用<code>liquibase.bat update</code>来运行<code>myChangeLog.xml</code></p>
<h2 id="检查你的数据库">检查你的数据库</h2>
<p>您将看到您的数据库现在包含一个名为<code>PERSON</code>的表。要将作为本教程一部分的 <code>H2</code> 数据库入内容，请打开一个终端，导航到您提取的 <code>Liquibase``*.zip</code> 或 <code>*.tar.gz</code>的文件夹，并运行 <code>java -jar h2-1.4.199.jar</code>注意：输入您下载的 <code>h2*.jar</code> 的特定版本！输入<code>JDBC URL</code>、用户名和密码，从 <code>liquibase.properties</code> 文件输入您根据教程设置创建的属性文件。您会注意到还创建了另外两个表：<code>databasechangeloglock</code>和<code>databasechangeloglock</code>。<code>databasechangelog</code>表包含针对数据库运行的所有更改的列表。<code>databasechangeloglock</code>表用于确保两台计算机不会同时尝试修改数据库。</p>
<h1 id="标准模板">标准模板</h1>
<pre><code class="language-xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&gt;
&lt;databaseChangeLog
        xmlns=&quot;http://www.liquibase.org/xml/ns/dbchangelog&quot;
        xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;
        xsi:schemaLocation=&quot;http://www.liquibase.org/xml/ns/dbchangelog http://www.liquibase.org/xml/ns/dbchangelog/dbchangelog-3.1.xsd&quot;&gt;
    &lt;property name=&quot;now&quot; value=&quot;now()&quot; dbms=&quot;mysql&quot;/&gt;

    &lt;changeSet id=&quot;&quot; author=&quot;修改者&quot;&gt;
        &lt;tagDatabase tag=&quot;数据库tag&quot;/&gt;
    &lt;/changeSet&gt;

    &lt;changeSet id=&quot;id唯一&quot; author=&quot;修改者&quot; runOnChange=&quot;false&quot;&gt;
        &lt;preConditions onFail=&quot;MARK_RAN&quot;&gt;
            &lt;not&gt;
                &lt;columnExists tableName=&quot;&quot; columnName=&quot;&quot;/&gt;
            &lt;/not&gt;
        &lt;/preConditions&gt;
        &lt;comment&gt;此次修改的备注&lt;/comment&gt;
        &lt;sql&gt;
        此次修改的sql语句
        &lt;/sql&gt;
        &lt;rollback&gt;
            失败回滚的语句
        &lt;/rollback&gt;
    &lt;/changeSet&gt;

&lt;/databaseChangeLog&gt;
</code></pre>
<p>changeSetid 为需求的日期加上 tag版本 和jiar版本</p>
<h1 id="命令">命令</h1>
<p>在对应模块下执行<br>
mvn install -Pupdatedb -Ddb.schema=数据库名称 -Dusername=root -Dpassword=数据库密码</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[自定义日志实现切面]]></title>
        <id>https://lindamao.cn/post/zi-ding-yi-ri-zhi-shi-xian-qie-mian/</id>
        <link href="https://lindamao.cn/post/zi-ding-yi-ri-zhi-shi-xian-qie-mian/">
        </link>
        <updated>2022-01-14T12:30:37.000Z</updated>
        <content type="html"><![CDATA[<h1 id="自定义注解实现日志切面">自定义注解实现日志切面</h1>
<h2 id="注解概念">注解概念</h2>
<h3 id="一-注解概念">一、注解概念</h3>
<p>注解（Annotation），也叫元数据。一种代码级别的说明。它是JDK1.5及以后版本引入的一个特性，与类、接口、枚举是在同一个层次。它可以声明在包、类、字段、方法、局部变量、方法参数等的前面，用来对这些元素进行说明，注释。</p>
<h3 id="二-注解分类">二、注解分类</h3>
<p>在Java中，注解分为两种，元注解和自定义注解。</p>
<h3 id="三-常用元注解作用-jdk提供的元注解">三、常用元注解作用 (jdk提供的元注解)</h3>
<h4 id="1target描述当前注解能够作用的位置">1.@Target:描述当前注解能够作用的位置</h4>
<p>ElementType.TYPE:可以作用在类上<br>
ElementType.METHOD:可以作用在方法上<br>
ElementType.FIELD:可以作用在成员变量上</p>
<h4 id="2retention-描述注解被保留到的阶段">2.@Retention: 描述注解被保留到的阶段</h4>
<p>SOURCE &lt; CLASS &lt; RUNTIME<br>
SOURCE:表示当前注解只在代码阶段有效<br>
CLASS:表示该注解会被保留到字节码阶段<br>
RUNTIME:表示该注解会被保留到运行阶段 JVM<br>
自定义的注解：RetentionPolicy.RUNTIME</p>
<p>3.@Documented:描述注解是否被抽取到JavaDoc api中<br>
4.@inherited:描述注解是否可以被子类继承</p>
<h1 id="代码实现">代码实现</h1>
<h2 id="第一步自定义注解">第一步自定义注解</h2>
<pre><code class="language-java">package com.lin.demo.aop;

import java.lang.annotation.ElementType;
import java.lang.annotation.Retention;
import java.lang.annotation.RetentionPolicy;
import java.lang.annotation.Target;

/**
 * @author linmouzhi
 * @create 2022/11/24 15:09
 */
@Target({ElementType.METHOD, ElementType.TYPE})
@Retention(RetentionPolicy.RUNTIME)
public @interface UserAccess {
    String desc() default &quot;无信息&quot;;
}
</code></pre>
<p>第二步 设定一个切面</p>
<p>@Aspect 注解将此类定义为一个切面</p>
<p>@Pointcut 切入点注解 定义方法作为一个切点 这里的参数为controller下的所有的公共类方法  还需定义一个方法</p>
<p>其他注解得在切入点的方法之下做一些修改 即可做出对应响应</p>
<pre><code class="language-json">package com.lin.demo.aop;

import org.aspectj.lang.JoinPoint;
import org.aspectj.lang.ProceedingJoinPoint;
import org.aspectj.lang.annotation.*;
import org.springframework.stereotype.Component;
import org.springframework.web.context.request.RequestContextHolder;
import org.springframework.web.context.request.ServletRequestAttributes;

import javax.servlet.http.HttpServletRequest;
import java.util.Arrays;

/**
 * @author linmouzhi
 * @create 2022/11/24 15:10
 */
@Aspect
@Component
public class LogAspect {
    // 这个目前是对从 com.xncoding.aop.controller.* 下的都进行切入，如果想对上面的自定义注解进行切入，只需改成相对应的路径
    // 例如：@Pointcut(value = &quot;@annotation(com.xncoding.aop.aspect.UserAccess)&quot;)
    @Pointcut(&quot;execution(public * com.lin.demo.controller.*.*(..))&quot;)
    public void webLog(){}

    @Before(&quot;webLog()&quot;)
    public void deBefore(JoinPoint joinPoint) throws Throwable {
        // 接收到请求，记录请求内容
        ServletRequestAttributes attributes = (ServletRequestAttributes) RequestContextHolder.getRequestAttributes();
        HttpServletRequest request = attributes.getRequest();
        // 记录下请求内容
        System.out.println(&quot;URL : &quot; + request.getRequestURL().toString());
        System.out.println(&quot;HTTP_METHOD : &quot; + request.getMethod());
        System.out.println(&quot;IP : &quot; + request.getRemoteAddr());
        System.out.println(&quot;CLASS_METHOD : &quot; + joinPoint.getSignature().getDeclaringTypeName() + &quot;.&quot; + joinPoint.getSignature().getName());
        System.out.println(&quot;ARGS : &quot; + Arrays.toString(joinPoint.getArgs()));
    }

    @AfterReturning(returning = &quot;ret&quot;, pointcut = &quot;webLog()&quot;)
    public void doAfterReturning(Object ret) throws Throwable {
        // 处理完请求，返回内容
        System.out.println(&quot;方法的返回值 : &quot; + ret);
    }

    //后置异常通知
    @AfterThrowing(&quot;webLog()&quot;)
    public void throwss(JoinPoint jp){
        System.out.println(&quot;方法异常时执行.....&quot;);
    }

    //后置最终通知,final增强，不管是抛出异常或者正常退出都会执行
    @After(&quot;webLog()&quot;)
    public void after(JoinPoint jp){
        System.out.println(&quot;方法最后执行.....&quot;);
    }

    //环绕通知,环绕增强，相当于MethodInterceptor
    @Around(&quot;webLog()&quot;)
    public Object arround(ProceedingJoinPoint pjp) throws Throwable{
        System.out.println(&quot;方法环绕start.....&quot;);
        try {
            Object o =  pjp.proceed();
            System.out.println(&quot;方法环绕proceed，结果是 :&quot; + o);
            return o;
        } catch (Throwable e) {
            throw e;
        }
    }
}

</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[RabbitMq]]></title>
        <id>https://lindamao.cn/post/rabbitmq/</id>
        <link href="https://lindamao.cn/post/rabbitmq/">
        </link>
        <updated>2021-05-22T06:06:58.000Z</updated>
        <content type="html"><![CDATA[<h2 id="1-什么是中间件">1. 什么是中间件</h2>
<blockquote>
<p>什么是中间件</p>
</blockquote>
<p>我国企业从20世纪80年代开始就逐渐进行信息化建设，由于方法和体系的不成熟，以及企业业务的市场需求的不断变化，一个企业可能同时运行着多个不同的业务系统，这些系统可能基于不同的操作系统、不同的数据库、异构的网络环境。现在的问题是，如何把这些信息系统结合成一个有机地协同工作的整体，真正实现企业跨平台、分布式应用。中间件便是解决之道，它用自己的复杂换取了企业应用的简单。</p>
<p>中间件（Middleware）是处于操作系统和应用程序之间的软件，也有人认为它应该属于操作系统中的一部分。人们在使用中间件时，往往是一组中间件集成在一起，构成一个平台（包括开发平台和运行平台），但在这组中间件中必须要有一个通信中间件，即中间件+平台+通信，这个定义也限定了只有用于分布式系统中才能称为中间件，同时还可以把它与支撑软件和使用软件区分开来</p>
<blockquote>
<p>为什么需要使用消息中间件</p>
</blockquote>
<p>具体地说，中间件屏蔽了底层操作系统的复杂性，使程序开发人员面对一个简单而统一的开发环境，减少程序设计的复杂性，将注意力集中在自己的业务上，不必再为程序在不同系统软件上的移植而重复工作，从而大大减少了技术上的负担，中间件带给应用系统的，不只是开发的简便、开发周期的缩短，也减少了系统的维护、运行和管理的工作量，还减少了计算机总体费用的投入。</p>
<blockquote>
<p>中间件特点</p>
</blockquote>
<p>为解决分布异构问题，人们提出了中间件（middleware)的概念。中间件时位于平台（硬件和操作系统）和应用之间的通用服务，如下图所示，这些服务具有标准的程序接口和协议。针对不同的操作系统和硬件平台，它们可以有符合接口的协议规范的多种实现。</p>
<p>也很难给中间件一个严格的定义，但中间件应具有如下的一些特点：</p>
<p>（1）满足大量应用的需要</p>
<p>（2）运行于多种硬件和 OS平台</p>
<p>（3）支持分布计算，提供跨网络、硬件和 OS平台的透明性的应用或服务的交互</p>
<p>（4）支持标准的协议</p>
<p>（5）支持标准的接口</p>
<p>由于标准接口对于可移植性和标准协议对于互操作性的重要性，中间件已成为许多标准化工作的主要部分。对于应用软件开发，中间件远比操作系统和网络服务更为重要，中间件提供的程序接口定义了一个相对稳定的高层应用环境，不管底层的计算机硬件和系统软件怎样更新换代，只要将中间件升级更新，并保持中间件对外的接口定义不变，应用软件几乎不需任何修改，从而保护了企业在应用软件开发和维护中的重大投资。</p>
<p>简单说：中间件有个很大的特点，是脱离于具体设计目标，而具备提供普遍独立功能需求的模块。这使得中间件一定是可替换的。如果一个系统设计中，中间件时不可替代的，不是架构、框架设计有问题，那么就是这个中间件，在别处可能是个中间件，在这个系统内是引擎。</p>
<blockquote>
<p>在项目中什么时候使用中间件技术</p>
</blockquote>
<p>在项目的架构和重构中，使用任何技术和架构的改变我们都需要谨慎斟酌和思考，因为任何技术的融入和变化都可能人员，技术，和成本的增加，中间件的技术一般现在一些互联网公司或者项目中使用比较多，如果你仅仅还只是一个初创公司建议还是使用单体架构，最多加个缓存中间件即可，不要盲目追求新或者所谓的高性能，而追求的背后一定是业务的驱动和项目的驱动，因为一旦追求就意味着你的学习成本，公司的人员结构以及服务器成本，维护和运维的成本都会增加，所以需要谨慎选择和考虑。</p>
<p>但是作为一个开放人员，一定要有学习中间件技术的能力和思维，否则很容易当项目发展到一个阶段在去掌握估计或者在面试中提及，就会给自己带来不小的困扰，在当今这个时代这些技术也并不是什么新鲜的东西，如果去掌握和挖掘最关键的还是自己花时间和经历去探讨和研究。</p>
<h2 id="2-中间件技术及架构的概述">2. 中间件技术及架构的概述</h2>
<blockquote>
<p>学习中间件的方式和技巧</p>
</blockquote>
<ol>
<li>理解中间件在项目架构中的作用，以及各中间件的底层实现</li>
<li>可以使用一些类比的生活概念去理解中间件</li>
<li>使用一些流程图或者脑图的方式去梳理各个中间件在架构中的作用</li>
<li>尝试用 java技术去实现中间件的原理</li>
<li>静下来去思考中间件在项目中设计的和使用的原因</li>
<li>如果找到对应的代替总结方案</li>
<li>尝试编写博文总结类同中间件技术的对比和使用场景</li>
<li>学会查看中间件的源码以及开源项目和博文</li>
</ol>
<blockquote>
<p>什么是消息中间件</p>
</blockquote>
<p>在实际的项目中，大部分的企业项目开发中，在早起都采用的是单体的架构模式</p>
<blockquote>
<p>单体架构</p>
</blockquote>
<p>在企业开发当中，大部分的初期架构都采用的是单体架构的模式进行架构，而这种架构的典型的特点：就是把所有的业务和模块，源代码，静态资源文件等都放在一个工程中，如果其中的一个模块升级或者迭代发生一个很小的变动都会重新编译和重新部署项目。这种这狗存在的问题是：</p>
<ol>
<li>耦合度太高</li>
<li>不易维护</li>
<li>服务器的成本高</li>
<li>以及升级架构的复杂度也会增大</li>
</ol>
<p>这样就有后续的分布式架构系统。如下</p>
<blockquote>
<p>分布式架构</p>
</blockquote>
<p><strong>何谓分布式系统：</strong></p>
<blockquote>
<p>通俗一点：就是一个请求由服务器端的多个服务（服务或者系统）协同处理完成</p>
</blockquote>
<p>和单体架构不同的是，单体架构是一个请求发起 jvm调度线程（确切的是 tomcat线程池）分配线程 Thread来处理请求直到释放，而分布式系统是：一个请求时由多个系统共同来协同完成，jvm和环境都可能是独立。如果生活中的比喻的话，单体架构就像建设一个小房子很快就能够搞定，如果你要建设一个鸟巢或者大型的建筑，你就必须是各个环节的协同和分布，这样目的也是项目发展到后期的时候要去部署和思考的问题。我们也不难看出来：分布式架构系统存在的特点和问题如下：</p>
<p><strong>存在问题：</strong></p>
<ol>
<li>学习成本高，技术栈过多</li>
<li>运维成本和服务器成本增高</li>
<li>人员的成本也会增高</li>
<li>项目的负载度也会上升</li>
<li>面临的错误和容错性也会成倍增加</li>
<li>占用的服务器端口和通讯的选择的成本高</li>
<li>安全性的考虑和因素逼迫可能选择 RMI/MQ相关的服务器端通讯</li>
</ol>
<p><strong>好处：</strong></p>
<ol>
<li>服务系统的独立，占用的服务器资源减少和占用的硬件成本减少，确切的说是：可以合理的分配服务资</li>
<li>源，不造成服务器资源的浪费</li>
<li>系统的独立维护和部署，耦合度降低，可插拔性</li>
<li>系统的架构和技术栈的选择可以变的灵活（而不是单纯地选择 java）</li>
<li>弹性的部署，不会造成平台因部署造成的瘫痪和停服的状态</li>
</ol>
<h2 id="3-基于消息中间件的分布式系统的架构">3. 基于消息中间件的分布式系统的架构</h2>
<ol>
<li>利用可靠的消息传递机制进行系统和系统直接的通讯</li>
<li>通过提供消息传递和消息的派对机制，它可以在分布式系统环境下扩展进程间的通讯</li>
</ol>
<blockquote>
<p>消息中间件应用的场景</p>
</blockquote>
<ol>
<li>跨系统数据传递</li>
<li>高并发的流量削峰</li>
<li>数据的并发和异步处理</li>
<li>大数据分析与传递</li>
<li>分布式事务比如你有一个数据要进行迁移或者请求并发过多的时候，</li>
</ol>
<p>比如你有10 W的并发请求下订单，我们可以在这些订单入库之前，我们可以把订单请求堆积到消息队列中，让它稳健可靠的入库和执行</p>
<blockquote>
<p>常见的消息中间件</p>
</blockquote>
<p>ActiveMQ、RabbitMQ、Kafka、RocketMQ等</p>
<blockquote>
<p>消息中间件的本质及设计</p>
</blockquote>
<p>它是一种接受数据、接受请求、存储数据、发送数据等功能的技术服务</p>
<p>MQ消息队列：负责数据的传接受，存储和传递，所以性能要高于普通服务和技术</p>
<p>谁来生产消息，存储消息和消费消息呢？</p>
<blockquote>
<p>消息中间件的核心组成部分</p>
</blockquote>
<p>消息的协议<br>
消息的持久化机制<br>
消息的分发策略<br>
消息的高可用，高可靠<br>
消息的容错机制</p>
<blockquote>
<p>小结</p>
</blockquote>
<p>其实不论选择单体架构还是分布式架构都是项目开发的一个阶段，在什么阶段选择合适的架构方式，而不能盲目追求，最后造成的后果和问题都需要自己买单。但作为一个开发人员学习和探讨新的技术使我们每个程序开发者都应该去保持和思考的问题。当我们没办法去改变社会和世界的时候，我们为了生活和生存那就必须要迎合企业和市场的需求，发挥你的价值和所学的才能，创造价值和实现自我</p>
<h2 id="4-消息队列协议">4. 消息队列协议</h2>
<blockquote>
<p>什么是协议</p>
</blockquote>
<p>所谓协议是指：</p>
<ol>
<li>计算机底层操作系统和应用程序通讯时共同遵守的一组约定，只有遵循共同的约定和规范，系统和底层操作系统之间才能相互交流</li>
<li>和一般的网络应用程序的不同它主要负责数据的接受和传递，所以性能比较的高</li>
<li>协议对数据格式和计算机之间交换数据都必须严格遵守规范</li>
</ol>
<blockquote>
<p>网络协议的三要素</p>
</blockquote>
<ol>
<li>语法：语法是用户数据与控制信息的结构与格式，以及数据出现的顺序</li>
<li>语义：语义是解释控制信息每个部分的意义，它规定了需要发出何种控制信息，以及完成的动作与做出什么样的响应</li>
<li>时序：时序是对事件发生顺序的详细说明</li>
</ol>
<p>比如我 MQ发送一个信息，是以什么数据格式发送到队列中，然后每个部分的含义是什么，发送完毕以后的执行的动作，以及消费者消费消息的动作，消费完毕的相应结构和反馈是什么，然后按照对应的执行顺序进行处理。如果你还是不理解：大家每天都在接触的 http请求协议：</p>
<ol>
<li>语法：http规定了请求报文和响应报文的格式</li>
<li>语义：客户端主动发起请求称之为请求（这是一种定义，同时你发起的是 post/get请求）</li>
<li>时序：一个请求对应一个响应（一定先有请求在有响应，这个是时序）</li>
</ol>
<p>而消息中间件采用的并不是 http协议，而常见的消息中间件协议有有：OpenWire、AMQP、MQTT、Kafka，OpenMessage协议</p>
<p><strong>面试题：为什么消息中间件不直接使用 http协议</strong></p>
<ol>
<li>因为 http请求报文头和响应报文头是比较复杂的，包含了Cookie，数据的加密解密，窗台吗，响应码等附加的功能，但是对于一个消息而言，我们并不需要这么复杂，也没有这个必要性，它其实就是负责数据传递，存储，分发就行，一定要追求的是高性能。尽量简洁，快速</li>
<li>大部分情况下 http大部分都是短链接，在实际的交互过程中，一个请求到响应都很有可能会中断，中断以后就不会执行持久化，就会造成请求的丢失。这样就不利于消息中间件的业务场景，因为消息中间件可能是一个长期的获取信息的过程，出现问题和故障要对数据或消息执行持久化等，目的是为了保证消息和数据的高可靠和稳健的运行</li>
</ol>
<blockquote>
<p>AMQP协议</p>
</blockquote>
<p>AMQP：（全称：Advanced Message Queuing Protocol）是高级消息队列协议。由摩根大通集团联合其他公司共同设计。是一个提供统一消息服务的应用层标准高级消息队列协议，是应用层协议的一个开放标准，为面向消息的中间件设计。基于此协议的客户端与消息中间件可传递消息，并不受客户端/中间件不同产品，不同的开发语言等条件的限制。Erlang中的实现由 RabbitMQ等</p>
<p>特性：</p>
<ol>
<li>分布式事务支持</li>
<li>消息的持久化支持</li>
<li>高性能和高可靠的消息处理优势</li>
</ol>
<blockquote>
<p>MQTT协议</p>
</blockquote>
<p>MQTT协议（Message Queueing Telemetry Transport）消息队列是 IBM开放的及时通讯协议，物联网系统架构中的重要组成部分</p>
<p>特点：</p>
<ol>
<li>轻量</li>
<li>结构简单</li>
<li>传输快，不支持事务</li>
<li>没有持久化设计</li>
</ol>
<p>应用场景：</p>
<ol>
<li>适用于计算能力有限</li>
<li>低带宽</li>
<li>网络不稳定的场景</li>
</ol>
<p>支持者：</p>
<blockquote>
<p>OpenMessage协议</p>
</blockquote>
<p>是近几年由阿里、雅虎和滴滴出行、Stremalio等公司共同参与创立的分布式信息中间件、流处理等领域的应用开发标准</p>
<p>特点：</p>
<ol>
<li>结构简单</li>
<li>解析速度快</li>
<li>支持事务和持久化设计</li>
</ol>
<blockquote>
<p>Kafka协议</p>
</blockquote>
<p>Kafka协议是基于 TCP/IP的二进制协议。消息内部是 通过长度来分割，由一些基本数据类型组成</p>
<p>特点：</p>
<ol>
<li>结构简单</li>
<li>解析速度快</li>
<li>无事务支持</li>
<li>有持久化设计</li>
</ol>
<blockquote>
<p>小结</p>
</blockquote>
<p>协议：实在 tcp/ip协议基础之上构建的一种约定俗称的规范和机制、它的主要目的可以让客户端（应用程序 java，go）进行沟通和通讯。并且这种写一下规范必须具有持久性，高可用，高可靠的性能</p>
<h2 id="5-消息队列持久化">5. 消息队列持久化</h2>
<blockquote>
<p>持久化</p>
</blockquote>
<p>简单来说就是将数据存入磁盘，而不是存在内存中随服务器重启断开而消失，使数据能够永久保存</p>
<blockquote>
<p>常见的持久化方式</p>
</blockquote>
<h2 id="6-消息的分发策略">6. 消息的分发策略</h2>
<blockquote>
<p>消息的分发策略</p>
</blockquote>
<p>MQ消息 队列有如下几个角色</p>
<ol>
<li>生产者</li>
<li>存储消息</li>
<li>消费者</li>
</ol>
<p>那么生产者生成消息以后，MQ进行存储，消费者是如何获取消息的呢？一般获取数据的方式无外乎推（push）或者拉（pull）两种方式，典型的 git就有推拉机制，我们发送的 http请求就是一种典型的拉取数据库数据返回的过程。而消息队列 MQ是一种推送的过程，而这些推机制会使用到很多的业务场景也有很多对应推机制策略</p>
<blockquote>
<p>场景分析一</p>
</blockquote>
<figure data-type="image" tabindex="1"><img src="E:%5Cnote%5C5-%E4%B8%AD%E9%97%B4%E4%BB%B6%5CRabbitMQ%5Cimage%5C15.jpg" alt="[外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-fQ6t7C7S-1615813808736)(C:\Users\VULCAN\AppData\Roaming\Typora\typora-user-images\image-20210315134437071.png)]" loading="lazy"></figure>
<p>比如我在 APP上下了一个订单，我们的系统和服务很多，我们如何得知这个消息被哪个系统或者哪些服务器或者系统进行消费，那这个时候就需要一个分发的策略。这就需要消费策略。或者称之为消费的方法论</p>
<blockquote>
<p>场景分析二</p>
</blockquote>
<figure data-type="image" tabindex="2"><img src="E:%5Cnote%5C5-%E4%B8%AD%E9%97%B4%E4%BB%B6%5CRabbitMQ%5Cimage%5C16.jpg" alt="[外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-l0CNvOUV-1615813808737)(C:\Users\VULCAN\AppData\Roaming\Typora\typora-user-images\image-20210315134747313.png)]" loading="lazy"></figure>
<p>在发送消息的过程中可能会出现异常，或者网络的抖动，故障等等因为造成消息的无法消费，比如用户在下订单，消费 MQ接受，订单系统出现故障，导致用户支付失败，那么这个时候就需要消息中间件就必须支持消息重试机制策略。也就是支持：出现问题和故障的情况下，消息不丢失还可以进行重发<br>
消息分发策略的机制和对比</p>
<h2 id="7-消息队列高可用和高可靠">7. 消息队列高可用和高可靠</h2>
<blockquote>
<p>什么是高可用机制</p>
</blockquote>
<p>所谓高可用：是指产品在规定的条件和规定的时刻或时间内处于可执行规定功能状态的能力</p>
<p>当业务量增加时，请求也过大，一台消息中间件服务器的会触及硬件（CPU，内存，磁盘）的极限，一台消息服务器你已经无法满足业务的需求，所以消息中间件必须支持集群部署，来达到高可用的目的</p>
<blockquote>
<p>集群模式1 - Master-slave主从共享数据的部署方式</p>
</blockquote>
<blockquote>
<p>集群模式2 - Master-slave主从同步部署方式</p>
</blockquote>
<p>解释：这种模式写入消息同样在 Master主节点上，但是主节点会同步数据到 slave节点形成副本，和 zookeeper或者 redis主从机制很雷同。这样可以达到负载均衡的效果，如果消费者有多个这样就可以去不同的节点进行消费，以为消息的拷贝和同步会占用很大的带宽和网络资源。在后去的 rabbitmq中会有使用</p>
<blockquote>
<p>集群模式3 - 多主集群同步部署模式</p>
</blockquote>
<p>解释：和上面的区别不是特别的大，但是它的写入可以往任意节点去写入</p>
<blockquote>
<p>集群模式4 - 多主集群转发部署模式</p>
</blockquote>
<p>解释：如果你插入的数据是 broker-1中国，元数据信息会存储数据的相关描述和记录存放的位置（队列）。它会对描述信息也就是元数据信息进行同步，如果消费者在 broker-2中进行消费，发现自己节点没有对应的信息，可以从对应的元数据信息中去查询，然后返回对应的消息信息，场景：比如买火车票或者黄牛买演唱会门票，比如第一个黄牛有顾客说要买的演唱会门票，但是没有但是他回去联系其他的黄牛询问，如果有就返回</p>
<blockquote>
<p>集群模式5 Master-slave与 Broker-cluster组合的方案</p>
</blockquote>
<p>解释：实现多主多从的热备机制来完成消息的高可用以及数据的热备机制，在生产规模达到一定的阶段的时候，这种使用的频率比较高</p>
<blockquote>
<p>什么是高可靠机制</p>
</blockquote>
<p>所谓高可靠是指：系统可以无故障低持续运行，比如一个系统突然崩溃，报错，异常等等并不影响线上业务的正常运行，出错的几率极低，就称之为：高可靠</p>
<p>在高并发的业务场景中，如果不能保证系统的高可靠，那造成的隐患和损失是非常严重的</p>
<p>如何保证中间件消息的可靠性呢，可以从两个方面考虑：</p>
<ol>
<li>消息的传输：通过协议来保证系统间数据解析的正确性</li>
<li>消息的存储区可靠：通过持久化来保证消息的可靠性</li>
</ol>
<h1 id="二-入门及安装">二、入门及安装</h1>
<h2 id="1-rabbitmq入门及安装">1. RabbitMQ入门及安装</h2>
<p>https://www.bilibili.com/video/BV1dX4y1V73G?p=27</p>
<h3 id="01-概述">01 概述</h3>
<p>简单概述：</p>
<p>RabbitMQ是一个开源的遵循 AMQP协议实现的基于 Erlang语言编写，支持多种客户端（语言），用于在分布式系统中存储消息，转发消息，具有高可用，高可扩性，易用性等特征</p>
<h3 id="02下载rabbitmq">02下载RabbitMQ</h3>
<ol>
<li>下载地址：https://www.rabbitmq.com/download.html</li>
<li>环境准备：CentOS7.x + /Erlang</li>
</ol>
<p>RabbitMQ是采用 Erlang语言开发的，所以系统环境必须提供 Erlang环境，第一步就是安装 Erlang</p>
<figure data-type="image" tabindex="3"><img src="E:%5Cnote%5C5-%E4%B8%AD%E9%97%B4%E4%BB%B6%5CRabbitMQ%5Cimage%5C24.jpg" alt="[外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-WVkC8e8q-1615876872944)(C:\Users\VULCAN\AppData\Roaming\Typora\typora-user-images\image-20210315164044604.png)]" loading="lazy"></figure>
<h3 id="03-安装erlang">03 安装Erlang</h3>
<blockquote>
<p>查看系统版本号</p>
</blockquote>
<blockquote>
<p>安装下载</p>
</blockquote>
<pre><code>mkdir -p /usr/rabbitmq
ca /usr//rabbitmq
# 将安装包上传到linux系统中
erlang-22.0.7-1.el7.x86_64.rpm
rabbitmq-server-3.7.18-1.el7.noarch.rpm

rpm -Uvh erlang-solutions-2.0-1.noarch.rpm
yum install -y erlang
erl -v
</code></pre>
<h3 id="04-安装socat">04 安装socat</h3>
<blockquote>
<p>安装下载</p>
</blockquote>
<pre><code>yum install -y socat
</code></pre>
<h3 id="05-安装rabbitmq">05 安装rabbitmq</h3>
<figure data-type="image" tabindex="4"><img src="E:%5Cnote%5C5-%E4%B8%AD%E9%97%B4%E4%BB%B6%5CRabbitMQ%5Cimage%5C26.jpg" alt="" loading="lazy"></figure>
<blockquote>
<p>安装下载</p>
</blockquote>
<pre><code>rpm -Uvh rabbitmq-server-3.7.18-1.el7.noarch.rpm
yum install rabbitmq-server -y
</code></pre>
<blockquote>
<p>启动服务</p>
</blockquote>
<pre><code># 启动服务
systemctl start rabbitmq-server
# 查看服务状态，如图
systemctl status rabbitmq-server.service
# 开机自启动
systemctl enable rabbitmq-server
# 停止服务
systemctl stop rabbitmq-server
</code></pre>
<h2 id="2-rabbitmqweb管理界面及授权操作">2. RabbitMQWeb管理界面及授权操作</h2>
<h3 id="01-rabbitmq管理界面">01 RabbitMQ管理界面</h3>
<blockquote>
<p>默认情况下，是没有安装web端的客户端插件，需要安装才可以生效</p>
</blockquote>
<pre><code>rabbitmq-plugins enable rabbitmq_management
</code></pre>
<p>说明：rabbitmq有一个默认账号和密码是：<code>guest</code>默认情况只能在 localhost本计下访问，所以需要添加一个远程登录的用户</p>
<blockquote>
<p>安装完毕以后，重启服务即可</p>
</blockquote>
<pre><code class="language-shell">systemctl restart rabbitmq-server
</code></pre>
<p>一定要记住，在对应服务器（阿里云，腾讯云等）的安全组中开放<code>15672</code>端口</p>
<blockquote>
<p>在浏览器访问</p>
</blockquote>
<figure data-type="image" tabindex="5"><img src="E:%5Cnote%5C5-%E4%B8%AD%E9%97%B4%E4%BB%B6%5CRabbitMQ%5Cimage%5C28.jpg" alt="" loading="lazy"></figure>
<pre><code># 10.关闭防火墙服务
systemctl disable firewalld
Removed symlink /etc/systemd/system/multi-user.target.wants/firewalld.service.
Removed symlink /etc/systemd/system/dbus-org.fedoraproject.FirewallD1.service.
systemctl stop firewalld   
# 11.访问web管理界面
http://10.15.0.8:15672/
</code></pre>
<h3 id="02-授权账号和密码">02 授权账号和密码</h3>
<blockquote>
<p>新增用户</p>
</blockquote>
<pre><code>rabbitmqctl add_user admin admin
</code></pre>
<blockquote>
<p>设置用户分配操作权限</p>
</blockquote>
<pre><code>rabbitmqctl set_user_tags admin administrator
</code></pre>
<p>用户级别：</p>
<ol>
<li>administrator：可以登录控制台、查看所有信息、可以对 rabbitmq进行管理</li>
<li>monitoring：监控者 登录控制台，查看所有信息</li>
<li>policymaker：策略制定者 登录控制台，指定策略</li>
<li>managment 普通管理员 登录控制台</li>
</ol>
<blockquote>
<p>为用户添加资源权限</p>
</blockquote>
<pre><code class="language-shell">rabbitmqctl set_permissions -p / admin &quot;.*&quot;&quot;.*&quot;&quot;.*&quot;
</code></pre>
<blockquote>
<p>网页登录成功</p>
</blockquote>
<h3 id="03小结">03小结：</h3>
<h2 id="3-rabbitmq之docker安装">3. RabbitMQ之Docker安装</h2>
<h3 id="01-dokcer安装rabbitmq">01 Dokcer安装RabbitMQ</h3>
<blockquote>
<p>虚拟化容器技术 - Docker的安装</p>
</blockquote>
<figure data-type="image" tabindex="6"><img src="E:%5Cnote%5C5-%E4%B8%AD%E9%97%B4%E4%BB%B6%5CRabbitMQ%5Cimage%5C31.jpg" alt="" loading="lazy"></figure>
<blockquote>
<p>docker的相关命令</p>
</blockquote>
<figure data-type="image" tabindex="7"><img src="E:%5Cnote%5C5-%E4%B8%AD%E9%97%B4%E4%BB%B6%5CRabbitMQ%5Cimage%5C32.jpg" alt="" loading="lazy"></figure>
<blockquote>
<p>安装rabbitmq</p>
</blockquote>
<figure data-type="image" tabindex="8"><img src="E:%5Cnote%5C5-%E4%B8%AD%E9%97%B4%E4%BB%B6%5CRabbitMQ%5Cimage%5C33.jpg" alt="" loading="lazy"></figure>
<p><code>可以直接走图中代码，不用走下面两项！</code></p>
<blockquote>
<p>获取rabbit镜像</p>
</blockquote>
<pre><code class="language-java">docker pull rabbitmq:management
</code></pre>
<blockquote>
<p>创建并运行容器</p>
</blockquote>
<pre><code class="language-java">docker run -id --name=myrabbit -p 15672:15672 rabbitmq:management
--hostname：指定容器主机名称
--name:指定容器名称
-p：将mq端口号映射到本地
或者运行时设置用户和密码
</code></pre>
<figure data-type="image" tabindex="9"><img src="E:%5Cnote%5C5-%E4%B8%AD%E9%97%B4%E4%BB%B6%5CRabbitMQ%5Cimage%5C34.jpg" alt="[外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-787v1Med-1615876872953)(C:\Users\VULCAN\AppData\Roaming\Typora\typora-user-images\image-20210315173500241.png)]" loading="lazy"></figure>
<blockquote>
<p>启动</p>
</blockquote>
<figure data-type="image" tabindex="10"><img src="E:%5Cnote%5C5-%E4%B8%AD%E9%97%B4%E4%BB%B6%5CRabbitMQ%5Cimage%5C35.jpg" alt="[外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-84RcXU0z-1615876872954)(C:\Users\VULCAN\AppData\Roaming\Typora\typora-user-images\image-20210315173924970.png)]" loading="lazy"></figure>
<p>访问网页，访问成功！</p>
<h2 id="4-rabbitmq的角色分类">4. RabbitMQ的角色分类</h2>
<figure data-type="image" tabindex="11"><img src="E:%5Cnote%5C5-%E4%B8%AD%E9%97%B4%E4%BB%B6%5CRabbitMQ%5Cimage%5C36.jpg" alt="" loading="lazy"></figure>
<figure data-type="image" tabindex="12"><img src="E:%5Cnote%5C5-%E4%B8%AD%E9%97%B4%E4%BB%B6%5CRabbitMQ%5Cimage%5C37.jpg" alt="" loading="lazy"></figure>
<h1 id="三-入门案例">三、入门案例</h1>
<h2 id="1-rabbitmq入门案例-simple-简单模式">1. RabbitMQ入门案例 - Simple 简单模式</h2>
<p>https://www.bilibili.com/video/BV1dX4y1V73G?p=44 实现步骤</p>
<ol>
<li>jdk1.8</li>
<li>构建一个 maven工程</li>
<li>导入 rabbitmq的 maven依赖</li>
<li>启动 rabbitmq-server服务</li>
<li>定义生产者</li>
<li>定义消费者</li>
<li>观察消息的在 rabbitmq-server服务中的进程</li>
</ol>
<h3 id="01-构建一个maven工程">01 构建一个maven工程</h3>
<figure data-type="image" tabindex="13"><img src="E:%5Cnote%5C5-%E4%B8%AD%E9%97%B4%E4%BB%B6%5CRabbitMQ%5Cimage%5C38.jpg" alt="" loading="lazy"></figure>
<h3 id="02-导入依赖">02 导入依赖</h3>
<blockquote>
<p>java原生依赖</p>
</blockquote>
<pre><code class="language-xml">&lt;dependency&gt;
    &lt;groupId&gt;com.rabbitmq&lt;/groupId&gt;
    &lt;artifactId&gt;amqp-client&lt;/artifactId&gt;
    &lt;version&gt;5.10.0&lt;/version&gt;
&lt;/dependency&gt;
</code></pre>
<h3 id="03-第一种模型">03 第一种模型</h3>
<figure data-type="image" tabindex="14"><img src="E:%5Cnote%5C5-%E4%B8%AD%E9%97%B4%E4%BB%B6%5CRabbitMQ%5Cimage%5C39.jpg" alt="" loading="lazy"></figure>
<p>在上图的模型中，有以下概念：</p>
<ol>
<li>生产者，也就是要发送消息的程序</li>
<li>消费者：消息的接受者，会一直等待消息到来。</li>
<li>消息队列：图中红色部分。类似一个邮箱，可以缓存消息；生产者向其中投递消息，消费者从其中取出消息。</li>
</ol>
<blockquote>
<p>生产者</p>
</blockquote>
<pre><code class="language-java">//简单模式
public class Producer{
    //1.创建连接工厂
    ConnectionFactory connectionFactory = new ConnectionFactory();
    connectionFactory.setHost(&quot;10.15.0.9&quot;);
    connectionFactory.setPort(5672);
    connectionFactory.setUsername(&quot;admin&quot;);
    connectionFactory.setPassword(&quot;admin&quot;);
    connectionFactory.setVirtualHost(&quot;/&quot;);
    Connection connection = connectionFactory.newConnection(&quot;生产者&quot;);
    //2.创建通道
    Channel channel = connection.createChannel();
    //3.通过创建交换机，声明队列，绑定关系，路由key，发送消息和接受消息
    /*参数1: 是否持久化，非持久化消息会存盘吗？会存盘，但是会随着重启服务器而丢失
      参数2:是否独占队列 
      参数3:是否自动删除，随着最后一个消费者消息完毕消息以后是否把队列自动删除
        参数4:携带附属属性
    */
    String queueName = &quot;queue1&quot;;
    channel.queueDeclare(queueName,false,false,false,null);
    //4.发送消息给队列queue
    /*参数1: 交换机
      参数2:队列、路由key
      参数3:消息的状态控制
        参数4:消息主题
    */
    //面试题：可以存在没有交换机的队列吗？不可能，虽然没有指定交换机但是一定会存在一个默认的交换机
    String message = &quot;Hello&quot;;
    channel.basicPublish(&quot;&quot;,message, null,message.getBytes());
    //5.关闭
    channel.close();
    connection.close();
}
</code></pre>
<blockquote>
<p>消费者</p>
</blockquote>
<pre><code class="language-java">//简单模式
public class Consumer{
    //1.创建连接工厂
    ConnectionFactory connectionFactory = new ConnectionFactory();
    connectionFactory.setHost(&quot;10.15.0.9&quot;);
    connectionFactory.setPort(5672);
    connectionFactory.setUsername(&quot;admin&quot;);
    connectionFactory.setPassword(&quot;admin&quot;);
    connectionFactory.setVirtualHost(&quot;/&quot;);
    Connection connection = connectionFactory.newConnection(&quot;生产者&quot;);
    //2.创建通道
    Channel channel = connection.createChannel();
    //3.接受内容
    channel.basicConsume(&quot;queue1&quot;,true,new DefaultConsumer(){
        public void handle(String consumerTag, Delivery message) throws IOException {
          System.out.println(new String(&quot;收到消息是&quot; + new String(meassage.getBody()),&quot;UTF-8&quot;));
        },new CancelCallback(){
            public void handle(String consumerTag) throws IOException {
                System.out.println(&quot;接受失败了&quot;);
        }
      });
    //4.关闭
    channel.close();
    connection.close();
}
</code></pre>
<h2 id="2-什么是amqp">2. 什么是AMQP</h2>
<h3 id="01-什么是amqp">01 什么是AMQP</h3>
<p>AMQP全称：Advanced Message Queuing Protocol（高级消息队列协议）。是应用层协议的一个开发标准，为面向消息的中间件设计</p>
<h3 id="02-amqp生产者流转过程">02 AMQP生产者流转过程</h3>
<figure data-type="image" tabindex="15"><img src="E:%5Cnote%5C5-%E4%B8%AD%E9%97%B4%E4%BB%B6%5CRabbitMQ%5Cimage%5C40.jpg" alt="[外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-78cQpQXh-1615906714913)(C:\Users\VULCAN\AppData\Roaming\Typora\typora-user-images\image-20210315201857946.png)]" loading="lazy"></figure>
<h3 id="03-amqp消费者流转过程">03 AMQP消费者流转过程</h3>
<figure data-type="image" tabindex="16"><img src="E:%5Cnote%5C5-%E4%B8%AD%E9%97%B4%E4%BB%B6%5CRabbitMQ%5Cimage%5C41.jpg" alt="" loading="lazy"></figure>
<h2 id="3-rabbitmq的核心组成部分">3. RabbitMQ的核心组成部分</h2>
<h3 id="01-rabbitmq的核心组成部分">01 RabbitMQ的核心组成部分</h3>
<figure data-type="image" tabindex="17"><img src="E:%5Cnote%5C5-%E4%B8%AD%E9%97%B4%E4%BB%B6%5CRabbitMQ%5Cimage%5C43.jpg" alt="" loading="lazy"></figure>
<figure data-type="image" tabindex="18"><img src="E:%5Cnote%5C5-%E4%B8%AD%E9%97%B4%E4%BB%B6%5CRabbitMQ%5Cimage%5C42.jpg" alt="" loading="lazy"></figure>
<h3 id="02-rabbitmq整体架构是什么样子的">02 RabbitMQ整体架构是什么样子的？</h3>
<figure data-type="image" tabindex="19"><img src="E:%5Cnote%5C5-%E4%B8%AD%E9%97%B4%E4%BB%B6%5CRabbitMQ%5Cimage%5C44.jpg" alt="" loading="lazy"></figure>
<h3 id="03-rabbitmq的运行流程">03 RabbitMQ的运行流程</h3>
<figure data-type="image" tabindex="20"><img src="E:%5Cnote%5C5-%E4%B8%AD%E9%97%B4%E4%BB%B6%5CRabbitMQ%5Cimage%5C45.jpg" alt="" loading="lazy"></figure>
<h3 id="04-rabbitmq支持的消息模型">04 RabbitMQ支持的消息模型</h3>
<figure data-type="image" tabindex="21"><img src="E:%5Cnote%5C5-%E4%B8%AD%E9%97%B4%E4%BB%B6%5CRabbitMQ%5Cimage%5C46.jpg" alt="" loading="lazy"></figure>
<figure data-type="image" tabindex="22"><img src="E:%5Cnote%5C5-%E4%B8%AD%E9%97%B4%E4%BB%B6%5CRabbitMQ%5Cimage%5C47.jpg" alt="" loading="lazy"></figure>
<ol>
<li>简单模式 Simple</li>
<li>工作模式 Work</li>
<li>发布订阅模式</li>
<li>路由模式</li>
<li>主题 Topic模式</li>
<li>参数模式</li>
</ol>
<h2 id="4-rabbitmq入门案例-fanout-模式">4. RabbitMQ入门案例 - fanout 模式</h2>
<h3 id="01-rabbitmq的模式之发布订阅模式">01 RabbitMQ的模式之发布订阅模式</h3>
<blockquote>
<p>图解</p>
</blockquote>
<figure data-type="image" tabindex="23"><img src="E:%5Cnote%5C5-%E4%B8%AD%E9%97%B4%E4%BB%B6%5CRabbitMQ%5Cimage%5C48.jpg" alt="" loading="lazy"></figure>
<p><strong>发布订阅模式的具体实现</strong></p>
<ol>
<li>web操作查看视频</li>
<li>类型：fanout</li>
<li>特点：Fanout - 发布与订阅模式，是一种广播机制，它是没有路由 key的模式</li>
</ol>
<blockquote>
<p>生产者</p>
</blockquote>
<pre><code class="language-java">//简单模式
public class Producer{
    //1.创建连接工厂
    ConnectionFactory connectionFactory = new ConnectionFactory();
    connectionFactory.setHost(&quot;10.15.0.9&quot;);
    connectionFactory.setPort(5672);
    connectionFactory.setUsername(&quot;admin&quot;);
    connectionFactory.setPassword(&quot;admin&quot;);
    connectionFactory.setVirtualHost(&quot;/&quot;);
    Connection connection = connectionFactory.newConnection(&quot;生产者&quot;);
    //2.创建通道
    Channel channel = connection.createChannel();
    //3.通过创建交换机，声明队列，绑定关系，路由key，发送消息和接受消息
    /*参数1: 是否持久化，非持久化消息会存盘吗？会存盘，但是会随着重启服务器而丢失
      参数2:是否独占队列 
      参数3:是否自动删除，随着最后一个消费者消息完毕消息以后是否把队列自动删除
        参数4:携带附属属性
    */
    String queueName = &quot;queue1&quot;;
    channel.queueDeclare(queueName,false,false,false,null);
    //4.发送消息给队列queue
    /*参数1: 交换机
      参数2:队列、路由key
      参数3:消息的状态控制
        参数4:消息主题
    */
    //面试题：可以存在没有交换机的队列吗？不可能，虽然没有指定交换机但是一定会存在一个默认的交换机
    String message = &quot;Hello&quot;;
    //5.准备交换机
    String exchangeName = &quot;fanout-exchange&quot;;
    //6.定义路由key
    String routeKey = &quot;&quot;;
    //7.指定交换机的类型
    String type = &quot;fanout&quot;;
    channel.basicPublish(exchangeName,routeKey, null,message.getBytes());
    //8.关闭
    channel.close();
    connection.close();
}
</code></pre>
<blockquote>
<p>消费者</p>
</blockquote>
<p>代码一样，使用线程启动测试而已！</p>
<figure data-type="image" tabindex="24"><img src="E:%5Cnote%5C5-%E4%B8%AD%E9%97%B4%E4%BB%B6%5CRabbitMQ%5Cimage%5C49.jpg" alt="[外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-uud19sfq-1615906714934)(C:\Users\VULCAN\AppData\Roaming\Typora\typora-user-images\image-20210315222738258.png)]" loading="lazy"></figure>
<p>此处没有通过代码去绑定交换机和队列，而是通过可视化界面去绑定的！</p>
<h2 id="5-rabbitmq入门案例-direct-模式">5. RabbitMQ入门案例 - Direct 模式</h2>
<pre><code class="language-java">//6.定义路由key
String routeKey = &quot;email&quot;;
//7.指定交换机的类型
String type = &quot;direct&quot;;
channel.basicPublish(exchangeName,routeKey, null,message.getBytes());
</code></pre>
<h2 id="6-rabbitmq入门案例-topic-模式">6. RabbitMQ入门案例 - Topic 模式</h2>
<figure data-type="image" tabindex="25"><img src="E:%5Cnote%5C5-%E4%B8%AD%E9%97%B4%E4%BB%B6%5CRabbitMQ%5Cimage%5C50.jpg" alt="" loading="lazy"></figure>
<pre><code class="language-java">//6.定义路由key
String routeKey = &quot;com.order.test.xxx&quot;;
//7.指定交换机的类型
String type = &quot;direct&quot;;
channel.basicPublish(exchangeName,routeKey, null,message.getBytes());
</code></pre>
<blockquote>
<p>代码创建及绑定</p>
</blockquote>
<pre><code class="language-java">//5.准备交换机
String exchangeName = &quot;direct_message_exchange&quot;;
String exchangeType = &quot;direct&quot;;
//如果你用界面把queue和exchange的关系先绑定话，代码就不需要在编写这些声明代码可以让代码变得更简洁
//如果用代码的方式去声明，我们要学习一下
//6.声明交换机 所谓的持久化就是指，交换机会不会随着服务器重启造成丢失
channel.exchangeDeclare(exchangeName,exchangeType,true);

//7.声明队列
channel.queueDeclare(&quot;queue5&quot;,true,false,false,null);
channel.queueDeclare(&quot;queue6&quot;,true,false,false,null);
channel.queueDeclare(&quot;queue7&quot;,true,false,false,null);

//8.绑定队列和交换机的关系
channel.queueBind(&quot;queue5&quot;,exchangeName,&quot;order&quot;);
channel.queueBind(&quot;queue6&quot;,exchangeName,&quot;order&quot;);
channel.queueBind(&quot;queue7&quot;,exchangeName,&quot;course&quot;);

channel.basicPublish(exchangeName,course, null,message.getBytes());
</code></pre>
<h2 id="7-rabbitmq入门案例-work模式">7. RabbitMQ入门案例 - Work模式</h2>
<h3 id="01-work模式轮询模式round-robin">01 Work模式轮询模式（Round-Robin）</h3>
<blockquote>
<p>图解</p>
</blockquote>
<p>当有多个消费者时，我们的消息会被哪个消费者消费呢，我们又该如何均衡消费者消费信息的多少呢？</p>
<p>主要有两种模式：</p>
<ol>
<li>轮询模式的分发：一个消费者一条，按均分配</li>
<li>公平分发：根据消费者的消费能力进行公平分发，处理快的处理的多，处理慢的处理的少；按劳分配</li>
</ol>
<blockquote>
<p>生产者</p>
</blockquote>
<p>跟简单模式一样！</p>
<blockquote>
<p>消费者</p>
</blockquote>
<p>创建两个一样的！</p>
<h3 id="02-work模式公平分发模式">02 Work模式公平分发模式</h3>
<blockquote>
<p>生产者</p>
</blockquote>
<p>跟简单模式一样！</p>
<blockquote>
<p>消费者</p>
</blockquote>
<pre><code class="language-java">//简单模式
public class Consumer{
    //3.接受内容
    //指标定义出来
    channel.basicQos(1);
    channel.basicConsume(&quot;queue1&quot;,false,new DefaultConsumer(){
        public void handle(String consumerTag, Delivery message) throws IOException {
          System.out.println(new String(&quot;收到消息是&quot; + new String(meassage.getBody()),&quot;UTF-8&quot;));
          //改成手动应答
          channel.basicAck(delivery.getEnvelope().getDeliveryTag(),false);
        },new CancelCallback(){
            public void handle(String consumerTag) throws IOException {
                System.out.println(&quot;接受失败了&quot;);
        }
      });
    //4.关闭
    channel.close();
    connection.close();
}
</code></pre>
<p>创建两个一样的！</p>
<h2 id="8-rabbitmq使用场景">8. RabbitMQ使用场景</h2>
<h3 id="01-解耦-削峰-异步">01 解耦、削峰、异步</h3>
<blockquote>
<p>同步异步的问题（串行）</p>
</blockquote>
<p>串行方式：将订单信息写入数据库成功后，发送注册邮件，再发送注册短信。以上三个任务全部完成后，返回给客户端</p>
<figure data-type="image" tabindex="26"><img src="E:%5Cnote%5C5-%E4%B8%AD%E9%97%B4%E4%BB%B6%5CRabbitMQ%5Cimage%5C52.jpg" alt="" loading="lazy"></figure>
<pre><code class="language-java">public void makeOrder(){
    //1.发送订单
    //2.发送短信服务
    //3.发送email服务
    //4.发送app服务
}
</code></pre>
<blockquote>
<p>并行方式 异步线程池</p>
</blockquote>
<p>并行方式：将订单信息写入数据库成功后，发送注册邮件的同时，发送注册短信。以上三个任务完成后，返回给客户端。与串行的差别是，并行的方式可以提高处理的时间</p>
<figure data-type="image" tabindex="27"><img src="E:%5Cnote%5C5-%E4%B8%AD%E9%97%B4%E4%BB%B6%5CRabbitMQ%5Cimage%5C53.jpg" alt="" loading="lazy"></figure>
<pre><code class="language-java">public void test(){
    //异步
    theadpool.submit(new Callable&lt;Object&gt;{
        //1.发送短信服务
    })
    //异步
    theadpool.submit(new Callable&lt;Object&gt;{
        //2.
    })
    //异步
    theadpool.submit(new Callable&lt;Object&gt;{
        //3.
    })
    //异步
    theadpool.submit(new Callable&lt;Object&gt;{
        //4.
    })
}
</code></pre>
<p>存在问题</p>
<ol>
<li>耦合度高</li>
<li>需要自己写线程池自己维护成本太高</li>
<li>出现了消息可能会丢失，需要你自己做消息补偿</li>
<li>如何保证消息的可靠性你自己写</li>
<li>如果服务器承载不了，你需要自己去写高可用</li>
</ol>
<blockquote>
<p>异步消息队列的方式</p>
</blockquote>
<figure data-type="image" tabindex="28"><img src="E:%5Cnote%5C5-%E4%B8%AD%E9%97%B4%E4%BB%B6%5CRabbitMQ%5Cimage%5C54.jpg" alt="" loading="lazy"></figure>
<p>好处：</p>
<ol>
<li>完全解耦，用 MQ建立桥接</li>
<li>有独立的线程池和运行模型</li>
<li>出现了消息可能会丢失，MQ有持久化功能</li>
<li>如何保证消息的可靠性，死信队列和消息转移等</li>
<li>如果服务器承载不了，你需要自己去写高可用，HA镜像模型高可用</li>
</ol>
<p>按照以上约定，用户的响应时间相当于是订单信息写入数据库的时间，也就是50毫秒。注册邮件，发送短信写入消息队列后，直接返回，因此写入消息队列的速度很快，基本可以忽略，因此用户的响应时间可能是50毫秒。因此架构改变后，系统的吞吐量提高到每秒20QPS。比串行提高了3倍，比并行提高了两倍</p>
<h3 id="02-高内聚低耦合">02 高内聚，低耦合</h3>
<figure data-type="image" tabindex="29"><img src="E:%5Cnote%5C5-%E4%B8%AD%E9%97%B4%E4%BB%B6%5CRabbitMQ%5Cimage%5C55.jpg" alt="在这里插入图片描述" loading="lazy"></figure>
<p>好处：</p>
<ol>
<li>完全解耦，用 MQ建立桥接</li>
<li>有独立的线程池和运行模型</li>
<li>出现了消息可能会丢失，MQ有持久化功能</li>
<li>如何保证消息的可靠性，死信队列和消息转移等</li>
<li>如果服务器承载不了，你需要自己去写高可用，HA镜像模型高可用</li>
</ol>
<p>按照以上约定，用户的响应时间相当于是订单信息写入数据库的时间，也就是50毫秒。注册邮件，发送短信写入消息队列后，直接返回，因此写入消息队列的速度很快，基本可以忽略，因此用户的响应时间可能是50毫秒。因此架构改变后，系统的吞吐量提高到每秒20QPS。比串行提高了3倍，比并行提高了两倍</p>
<h1 id="四-springboot案例">四、Springboot案例</h1>
<h2 id="1-fanout-模式">1. Fanout 模式</h2>
<p>https://www.bilibili.com/video/BV1dX4y1V73G?p=44</p>
<blockquote>
<p>生产者</p>
</blockquote>
<p><strong>application.yml</strong></p>
<pre><code class="language-yml"># 服务端口
server:
  port: 8080
# 配置rabbitmq服务
spring:
    rabbitmq:
        username: admin
        password: admin
        virtual-host: /
        host: 127.0.0.1
        port: 5672
</code></pre>
<p>OrderService.java</p>
<pre><code class="language-java">public class OrderService{
    @Autowired
    private RabbitTemplate rabbitTemplate;
    //模拟用户下单
    public void makeOrder(String userid,String productid,int num){
        //1.根据商品id查询库存是否足够
        //2.保存订单
        String orderId = UUID.randomUUID().toString();
        sout(&quot;订单生产成功：&quot;+orderId);
        //3.通过MQ来完成消息的分发
        //参数1：交换机 参数2：路由key/queue队列名称 参数3：消息内容
        String exchangeName = &quot;fanout_order_exchange&quot;;
        String routingKey = &quot;&quot;;
        rabbitTemplate.convertAndSend(exchangeName,routingKey,orderId);
    }
}
</code></pre>
<blockquote>
<p>消费者</p>
</blockquote>
<p><strong>application.yml</strong></p>
<pre><code class="language-yml"># 服务端口
server:
  port: 8080
# 配置rabbitmq服务
spring:
    rabbitmq:
        username: admin
        password: admin
        virtual-host: /
        host: 127.0.0.1
        port: 5672
</code></pre>
<p><strong>RabbitMqConfiguration.java</strong></p>
<pre><code class="language-java">@Configuration
public class RabbitMqConfiguration{
    //1.声明注册fanout模式的交换机
    @Bean
    public FanoutExchange fanoutExchange(){
        return new FanoutExchange(&quot;fanout_order_exchange&quot;,true,false);
    }
    //2.声明队列
    @Bean
    public Queue smsQueue(){
        return new Queue(&quot;sms.fanout.queue&quot;,true);
    }
    @Bean
    public Queue duanxinQueue(){
        return new Queue(&quot;duanxin.fanout.queue&quot;,true);
    }
    @Bean
    public Queue emailQueue(){
        return new Queue(&quot;email.fanout.queue&quot;,true);
    }
    //3.完成绑定关系
    @Bean
    public Binding smsBingding(){
        return BindingBuilder.bin(smsQueue()).to(fanoutExchange());
    }
    @Bean
    public Binding duanxinBingding(){
        return BindingBuilder.bin(duanxinQueue()).to(fanoutExchange());
    }
    @Bean
    public Binding emailBingding(){
        return BindingBuilder.bin(emailQueue()).to(fanoutExchange());
    }
}
</code></pre>
<p><strong>FanoutSmsConsumer.java</strong></p>
<pre><code class="language-java">@Component
@RabbitListener(queue = {&quot;sms.direct.queue&quot;})
public class FanoutSmsConsumer{
    @RabbitHandler
    public void reviceMessage(String message){
        sout(&quot;sms接收到了的订单信息是：&quot;+message);
    }
}
</code></pre>
<p><strong>FanoutDuanxinConsumer.java</strong></p>
<pre><code class="language-java">@Component
@RabbitListener(queue = {&quot;duanxin.direct.queue&quot;})
public class FanoutDuanxinConsumer{
    @RabbitHandler
    public void reviceMessage(String message){
        sout(&quot;duanxin接收到了的订单信息是：&quot;+message);
    }
}
</code></pre>
<p><strong>FanoutEmailConsumer.java</strong></p>
<pre><code class="language-java">@Component
@RabbitListener(queue = {&quot;duanxin.direct.queue&quot;})
public class FanoutEmailConsumer{
    @RabbitHandler
    public void reviceMessage(String message){
        sout(&quot;email接收到了的订单信息是：&quot;+message);
    }
}
</code></pre>
<h2 id="2-direct-模式">2. Direct 模式</h2>
<blockquote>
<p>生产者</p>
</blockquote>
<p><strong>OrderService.java</strong></p>
<pre><code class="language-java">public class OrderService{
    @Autowired
    private RabbitTemplate rabbitTemplate;
    //模拟用户下单
    public void makeOrder(String userid,String productid,int num){
        //1.根据商品id查询库存是否足够
        //2.保存订单
        String orderId = UUID.randomUUID().toString();
        sout(&quot;订单生产成功：&quot;+orderId);
        //3.通过MQ来完成消息的分发
        //参数1：交换机 参数2：路由key/queue队列名称 参数3：消息内容
        String exchangeName = &quot;direct_order_exchange&quot;;
        String routingKey = &quot;&quot;;
        rabbitTemplate.convertAndSend(exchangeName,&quot;email&quot;,orderId);
        rabbitTemplate.convertAndSend(exchangeName,&quot;duanxin&quot;,orderId);
    }
}
</code></pre>
<blockquote>
<p>消费者</p>
</blockquote>
<p><strong>RabbitMqConfiguration.java</strong></p>
<pre><code class="language-java">@Configuration
public class RabbitMqConfiguration{
    //1.声明注册fanout模式的交换机
    @Bean
    public DirectExchange directExchange(){
        return new DirectExchange(&quot;direct_order_exchange&quot;,true,false);
    }
    //2.声明队列
    @Bean
    public Queue smsQueue(){
        return new Queue(&quot;sms.direct.queue&quot;,true);
    }
    @Bean
    public Queue duanxinQueue(){
        return new Queue(&quot;duanxin.direct.queue&quot;,true);
    }
    @Bean
    public Queue emailQueue(){
        return new Queue(&quot;email.direct.queue&quot;,true);
    }
    //3.完成绑定关系
    @Bean
    public Binding smsBingding(){
        return BindingBuilder.bin(smsQueue()).to(fanoutExchange()).with(&quot;sms&quot;);
    }
    @Bean
    public Binding duanxinBingding(){
        return BindingBuilder.bin(duanxinQueue()).to(fanoutExchange()).with(&quot;duanxin&quot;);
    }
    @Bean
    public Binding emailBingding(){
        return BindingBuilder.bin(emailQueue()).to(fanoutExchange()).with(&quot;email&quot;);
    }
}
</code></pre>
<h2 id="3-topic-模式">3. Topic 模式</h2>
<blockquote>
<p>生产者</p>
</blockquote>
<pre><code class="language-java">public class OrderService{
    @Autowired
    private RabbitTemplate rabbitTemplate;
    //模拟用户下单
    public void makeOrder(String userid,String productid,int num){
        //1.根据商品id查询库存是否足够
        //2.保存订单
        String orderId = UUID.randomUUID().toString();
        sout(&quot;订单生产成功：&quot;+orderId);
        //3.通过MQ来完成消息的分发
        //参数1：交换机 参数2：路由key/queue队列名称 参数3：消息内容
        String exchangeName = &quot;direct_order_exchange&quot;;
        String routingKey = &quot;com.duanxin&quot;;
        rabbitTemplate.convertAndSend(exchangeName,routingKey,orderId);
    }
}
</code></pre>
<blockquote>
<p>消费者（采用注解）</p>
</blockquote>
<p><strong>FanoutSmsConsumer.java</strong></p>
<pre><code class="language-java">@Component
@RabbitListener(bindings = @QueueBinding(
    value = @Queue(value = &quot;sms.topic.queue&quot;,durable = &quot;true&quot;,antoDelete = &quot;false&quot;),
    exchange = @Exchange(value = &quot;topic_order_exchange&quot;,type = &quot;ExchangeTypes.TOPIC&quot;)
    key = &quot;#.sms.#&quot;
))
public class TopicSmsConsumer{
    @RabbitHandler
    public void reviceMessage(String message){
        sout(&quot;sms接收到了的订单信息是：&quot;+message);
    }
}
</code></pre>
<p><strong>FanoutDuanxinConsumer.java</strong></p>
<pre><code class="language-java">@Component
@RabbitListener(bindings = @QueueBinding(
    value = @Queue(value = &quot;duanxin.topic.queue&quot;,durable = &quot;true&quot;,antoDelete = &quot;false&quot;),
    exchange = @Exchange(value = &quot;topic_order_exchange&quot;,type = &quot;ExchangeTypes.TOPIC&quot;)
    key = &quot;#.duanxin.#&quot;
))
public classTopicDuanxinConsumer{
    @RabbitHandler
    public void reviceMessage(String message){
        sout(&quot;duanxin接收到了的订单信息是：&quot;+message);
    }
}
</code></pre>
<p><strong>FanoutEmailConsumer.java</strong></p>
<pre><code class="language-java">@Component
@RabbitListener(bindings = @QueueBinding(
    value = @Queue(value = &quot;email.topic.queue&quot;,durable = &quot;true&quot;,antoDelete = &quot;false&quot;),
    exchange = @Exchange(value = &quot;topic_order_exchange&quot;,type = &quot;ExchangeTypes.TOPIC&quot;)
    key = &quot;#.email.#&quot;
))
public class TopicEmailConsumer{
    @RabbitHandler
    public void reviceMessage(String message){
        sout(&quot;email接收到了的订单信息是：&quot;+message);
    }
}
</code></pre>
<h1 id="五-rabbitmq高级">五、RabbitMQ高级</h1>
<p>##1.  过期时间TTL</p>
<p>https://www.bilibili.com/video/BV1dX4y1V73G?p=44</p>
<blockquote>
<p>概述</p>
</blockquote>
<p>过期时间 TTl表示可以对消息设置预期的时间，在这个时间内都可以被消费者接收获取；过了之后消息将自动被删除。RabbitMQ可以对消息和队列设置 TTL，目前有两种方法可以设置</p>
<ol>
<li>第一种方法是通过队列属性设置，队列中所有消息都有相同的过期时间</li>
<li>第二种方法是对消息进行单独设置，每条消息 TTL可以不同</li>
</ol>
<p>如果上述两种方法同时使用，则消息的过期时间以两者 TTL较小的那个数值为准。消息在队列的生存时间一旦超过设置的 TTL值，就称为 dead message被投递到死信队列，消费者将无法再收到该消息</p>
<blockquote>
<p>设置队列TTL</p>
</blockquote>
<p><strong>RabbitMqConfiguration.java</strong></p>
<pre><code class="language-java">@Configuration
public class TTLRabbitMQConfiguration{
    //1.声明注册direct模式的交换机
    @Bean
    public DirectExchange ttldirectExchange(){
        return new DirectExchange(&quot;ttl_direct_exchange&quot;,true,false);}
    //2.队列的过期时间
    @Bean
    public Queue directttlQueue(){
        //设置过期时间
        Map&lt;String,Object&gt; args = new HashMap&lt;&gt;();
        args.put(&quot;x-message-ttl&quot;,5000);//这里一定是int类型
        return new Queue(&quot;ttl.direct.queue&quot;,true,false,false,args);}

    @Bean
    public Binding ttlBingding(){
        return BindingBuilder.bin(directttlQueue()).to(ttldirectExchange()).with(&quot;ttl&quot;);
    }
}
</code></pre>
<blockquote>
<p>设置消息TTL</p>
</blockquote>
<pre><code class="language-java">public class OrderService{
    @Autowired
    private RabbitTemplate rabbitTemplate;
    //模拟用户下单
    public void makeOrder(String userid,String productid,int num){
        //1.根据商品id查询库存是否足够
        //2.保存订单
        String orderId = UUID.randomUUID().toString();
        sout(&quot;订单生产成功：&quot;+orderId);
        //3.通过MQ来完成消息的分发
        //参数1：交换机 参数2：路由key/queue队列名称 参数3：消息内容
        String exchangeName = &quot;ttl_order_exchange&quot;;
        String routingKey = &quot;ttlmessage&quot;;
        //给消息设置过期时间
        MessagePostProcessor messagePostProcessor = new MessagePostProcessor(){
            public Message postProcessMessage(Message message){
                //这里就是字符串
                message.getMessageProperties().setExpiration(&quot;5000&quot;);
                message.getMessageProperties().setContentEncoding(&quot;UTF-8&quot;);
                return message;
            }
        }
        rabbitTemplate.convertAndSend(exchangeName,routingKey,orderId,messagePostProcessor);
    }
}
</code></pre>
<p><strong>RabbitMqConfiguration.java</strong></p>
<pre><code class="language-java">@Configuration
public class TTLRabbitMQConfiguration{
    //1.声明注册direct模式的交换机
    @Bean
    public DirectExchange ttldirectExchange(){
        return new DirectExchange(&quot;ttl_direct_exchange&quot;,true,false);}
    //2.队列的过期时间
    @Bean
    public Queue directttlQueue(){
        //设置过期时间
        Map&lt;String,Object&gt; args = new HashMap&lt;&gt;();
        args.put(&quot;x-message-ttl&quot;,5000);//这里一定是int类型
        return new Queue(&quot;ttl.direct.queue&quot;,true,false,false,args);}
    @Bean
    public Queue directttlMessageQueue(){
        return new Queue(&quot;ttlMessage.direct.queue&quot;,true,false,false,args);}

    @Bean
    public Binding ttlBingding(){
        return BindingBuilder.bin(directttlMessageQueue()).to(ttldirectExchange()).with(&quot;ttlmessage&quot;);
    }
}
</code></pre>
<h2 id="2-死信队列">2. 死信队列</h2>
<blockquote>
<p>概述</p>
</blockquote>
<p>DLX，全称 <code>Dead-Letter-Exchange</code>，可以称之为死信交换机，也有人称之为死信邮箱。当消息再一个队列中变成死信之后，它能被重新发送到另一个交换机中，这个交换机就是 DLX，绑定 DLX的队列就称之为死信队列。消息变成死信，可能是由于以下原因：</p>
<ol>
<li>消息被拒绝</li>
<li>消息过期</li>
<li>队列达到最大长度</li>
</ol>
<p>DLX也是一个正常的交换机，和一般的交换机没有区别，它能在任何的队列上被指定，实际上就是设置某一个队列的属性，当这个队列中存在死信时，Rabbitmq就会自动地将这个消息重新发布到设置的 DLX上去，进而被路由到另一个队列，即死信队列。</p>
<p>要想使用死信队列，只需要在定义队列的时候设置队列参数<code>x-dead-letter-exchange</code>指定交换机即可</p>
<blockquote>
<p>代码</p>
</blockquote>
<p><strong>DeadRabbitMqConfiguration.java</strong></p>
<pre><code class="language-java">@Configuration
public class DeadRabbitMqConfiguration{
    //1.声明注册direct模式的交换机
    @Bean
    public DirectExchange deadDirect(){
        return new DirectExchange(&quot;dead_direct_exchange&quot;,true,false);}
    //2.队列的过期时间
    @Bean
    public Queue deadQueue(){
        return new Queue(&quot;dead.direct.queue&quot;,true);}
    @Bean
    public Binding deadbinds(){
        return BindingBuilder.bind(deadDirect()).to(deadQueue()).with(&quot;dead&quot;);
    }
}
</code></pre>
<p><strong>RabbitMqConfiguration.java</strong></p>
<pre><code class="language-java">@Configuration
public class TTLRabbitMQConfiguration{
    //1.声明注册direct模式的交换机
    @Bean
    public DirectExchange ttldirectExchange(){
        return new DirectExchange(&quot;ttl_direct_exchange&quot;,true,false);}
    //2.队列的过期时间
    @Bean
    public Queue directttlQueue(){
        //设置过期时间
        Map&lt;String,Object&gt; args = new HashMap&lt;&gt;();
        //args.put(&quot;x-max-length&quot;,5);
        args.put(&quot;x-message-ttl&quot;,5000);//这里一定是int类型
        args.put(&quot;x-dead-letter-exchange&quot;,&quot;dead_direct_exchange&quot;);
        args.put(&quot;x-dead-letter-routing-key&quot;,&quot;dead&quot;);//fanout不需要配置
        return new Queue(&quot;ttl.direct.queue&quot;,true,false,false,args);}
    @Bean
    public Queue directttlMessageQueue(){
        return new Queue(&quot;ttlMessage.direct.queue&quot;,true,false,false,args);}

    @Bean
    public Binding ttlBingding(){
        return BindingBuilder.bin(directttlMessageQueue()).to(ttldirectExchange()).with(&quot;ttlmessage&quot;);
    }
}
</code></pre>
<figure data-type="image" tabindex="30"><img src="E:%5Cnote%5C5-%E4%B8%AD%E9%97%B4%E4%BB%B6%5CRabbitMQ%5Cimage%5C73.jpg" alt="" loading="lazy"></figure>
<h2 id="3-内存磁盘的监控">3. 内存磁盘的监控</h2>
<h3 id="01-rabbitmq内存警告">01 RabbitMQ内存警告</h3>
<figure data-type="image" tabindex="31"><img src="E:%5Cnote%5C5-%E4%B8%AD%E9%97%B4%E4%BB%B6%5CRabbitMQ%5Cimage%5C74.jpg" alt="" loading="lazy"></figure>
<h3 id="02-rabbitmq的内存控制">02 RabbitMQ的内存控制</h3>
<p>参考帮助文档：<code>http://www.rabbbitmq.com/configure.html</code></p>
<p>当出现警告的时候，可以通过配置去修改和调整</p>
<blockquote>
<p>命令的方式</p>
</blockquote>
<pre><code>rabbitmqctl set_vm_memory_high_watermark &lt;fraction&gt;
rabbitmqctl set_vm_memory_high_watermark absolute 50MB
</code></pre>
<p>fraction/value 为内存阈值。默认情况是：0.4/2GB，代表的含义是：当 RabbitMQ的内存超过40%时，就会产生警告并且会阻塞所有生产者的连接。通过此命令修改阈值在 Broker重启以后将会失效，通过修改配置文件设置的阈值则不会随着重启而消失，但修改了配置文件一样要重启 Broker才会生效</p>
<figure data-type="image" tabindex="32"><img src="E:%5Cnote%5C5-%E4%B8%AD%E9%97%B4%E4%BB%B6%5CRabbitMQ%5Cimage%5C75.jpg" alt="" loading="lazy"></figure>
<blockquote>
<p>配置文件方式 rabbitmq.conf</p>
</blockquote>
<figure data-type="image" tabindex="33"><img src="E:%5Cnote%5C5-%E4%B8%AD%E9%97%B4%E4%BB%B6%5CRabbitMQ%5Cimage%5C76.jpg" alt="" loading="lazy"></figure>
<h3 id="03-rabbitmq的内存换页">03 RabbitMQ的内存换页</h3>
<figure data-type="image" tabindex="34"><img src="E:%5Cnote%5C5-%E4%B8%AD%E9%97%B4%E4%BB%B6%5CRabbitMQ%5Cimage%5C77.jpg" alt="" loading="lazy"></figure>
<h3 id="04-rabbitmq的磁盘预警">04 RabbitMQ的磁盘预警</h3>
<figure data-type="image" tabindex="35"><img src="E:%5Cnote%5C5-%E4%B8%AD%E9%97%B4%E4%BB%B6%5CRabbitMQ%5Cimage%5C78.jpg" alt="" loading="lazy"></figure>
<h2 id="4-集群">4.  集群</h2>
<figure data-type="image" tabindex="36"><img src="E:%5Cnote%5C5-%E4%B8%AD%E9%97%B4%E4%BB%B6%5CRabbitMQ%5Cimage%5C79.jpg" alt="" loading="lazy"></figure>
<h3 id="01-集群搭建">01 集群搭建</h3>
<p>配置的前提是你的 rabbitmq可以运行起来，比如<code>ps aix|grep rebbitmq</code>你能看到相关进程，又比如运行<code>rabbitmqct status</code>你可以看到类似如下信息而不报错：</p>
<figure data-type="image" tabindex="37"><img src="E:%5Cnote%5C5-%E4%B8%AD%E9%97%B4%E4%BB%B6%5CRabbitMQ%5Cimage%5C80.jpg" alt="" loading="lazy"></figure>
<h3 id="02-单机多实例搭建">02 单机多实例搭建</h3>
<figure data-type="image" tabindex="38"><img src="E:%5Cnote%5C5-%E4%B8%AD%E9%97%B4%E4%BB%B6%5CRabbitMQ%5Cimage%5C81.jpg" alt="" loading="lazy"></figure>
<blockquote>
<p>启动第二个节点</p>
</blockquote>
<figure data-type="image" tabindex="39"><img src="E:%5Cnote%5C5-%E4%B8%AD%E9%97%B4%E4%BB%B6%5CRabbitMQ%5Cimage%5C82.jpg" alt="" loading="lazy"></figure>
<blockquote>
<p>验证启动</p>
</blockquote>
<pre><code class="language-shell">ps aux|grep rabbitmq
</code></pre>
<blockquote>
<p>rabbit-1操作作为主节点</p>
</blockquote>
<figure data-type="image" tabindex="40"><img src="E:%5Cnote%5C5-%E4%B8%AD%E9%97%B4%E4%BB%B6%5CRabbitMQ%5Cimage%5C83.jpg" alt="" loading="lazy"></figure>
<blockquote>
<p>rabbit-2操作作为从节点</p>
</blockquote>
<figure data-type="image" tabindex="41"><img src="E:%5Cnote%5C5-%E4%B8%AD%E9%97%B4%E4%BB%B6%5CRabbitMQ%5Cimage%5C84.jpg" alt="" loading="lazy"></figure>
<blockquote>
<p>验证集群状态</p>
</blockquote>
<figure data-type="image" tabindex="42"><img src="E:%5Cnote%5C5-%E4%B8%AD%E9%97%B4%E4%BB%B6%5CRabbitMQ%5Cimage%5C85.jpg" alt="" loading="lazy"></figure>
<blockquote>
<p>Web监控</p>
</blockquote>
<pre><code class="language-shell">rabbitmq-plugins enable rabbitmq_management
</code></pre>
<figure data-type="image" tabindex="43"><img src="E:%5Cnote%5C5-%E4%B8%AD%E9%97%B4%E4%BB%B6%5CRabbitMQ%5Cimage%5C86.jpg" alt="在这里插入图片描述" loading="lazy"></figure>
<blockquote>
<p>小结</p>
</blockquote>
<h2 id="5-分布式事务">5. 分布式事务</h2>
<h3 id="01-简述">01 简述</h3>
<p>分布式事务指事务的操作位于不同的节点上，需要保证事务的ACID特性。</p>
<p>例如在下单场景下，库存和订单如果不在同一个节点上，就涉及分布式事务</p>
<h3 id="02-分布式事务方式">02 分布式事务方式</h3>
<p>在分布式系统中，要实现分布式事务，无外乎哪几种解决方案。</p>
<p>####①两阶段提交（2PC）需要数据库严商</p>
<p>两阶段提交（Two-phase Commit，2PC），通过引协调者（coordinator）来协调参与者的行为，并最终决定这些参与者是否真正要执行事务。</p>
<h5 id="准备阶段">准备阶段</h5>
<p>协调者询问参与事务是否执行成功，参与者发回事务执行结果</p>
<p>#####提交阶段<br>
如果事务在每个参与者上都执行成功，事务协调者发送通知让参与者提交事务;否则，协调者发送通知让参与者回滚事务。<br>
需要注意的是，在准备阶段，参与者执行了事务，但是还未提交。只有在提交阶段接收到协调者发来的通知后，才进行提交或者回滚。</p>
<h5 id="存在的问题">存在的问题</h5>
<ol>
<li>同步阻塞所有事务参与者在等待其它参与者响应的时候都处于同步阻塞状态，无法进行其它操作。</li>
<li>单点问题协调者在2PC中起到非常大的作用，发生故障将会造成很大影响。特别是在阶段二发生故障，所有参与者会—直等待状态，无法完成其它操作。</li>
<li>数据不一致在阶段二，如果协调者只发送了部分Commit 消息，此时网络发生异常，那么只有部分参与者接收到Commit消息，也就是说只有部分参与者提交了事务，使得系统数据不一致。</li>
<li>太过保守任意一个节点失败就会导致整个事务失败，没有完善的容错机制。</li>
</ol>
<p>####②补偿事务（TCC）严选，阿里、蚂蚁金服</p>
<p>TCC 其实就是采用的补偿机制，其核心思想是:针对每个操作，都要注册一个与其对应的确认和补偿（撒销）操作。它分为三个阶段:</p>
<ul>
<li>Try阶段主要是对业务系统做检测及资源预留</li>
<li>Confirm阶段主要是对业务系统做确认提交，Try阶段执行成功并开始执行Confirm阶段时，默认---Confirm阶段是不会出错的。即:只要Try成功,Confirm一定成功。</li>
<li>Cancel阶段主要是在业务执行错误，需要回滚的状态下执行的业务取消，预留资源释放。</li>
</ul>
<p>举个例子，假入Bob要向Smith转账，思路大概是:我们有一个本地方法，里面依次调用</p>
<ol>
<li>首先在Try阶段，要先调用远程接口把Smith 和 Bob 的钱给冻结起来。</li>
<li>在 Confirm阶段，执行远程调用的转账的操作，转账成功进行解冻。</li>
<li>如果第2步执行成功，那么转账成功，如果第二步执行失败，则调用远程冻结接口对应的解冻方法(Cancel)。</li>
</ol>
<p>优点:跟2PC比起来，实现以及流程相对简单了一些，但数据的一致性比2PC也要差一些<br>
缺点:缺点还是比较明显的，在2,3步中都有可能失败。TCC属于应用层的一种补偿方式，所以需要程序员在实现的时候多写很多补偿的代码，在一些场景中，一些业务流程可能用TCC不太好定义及处理。</p>
<p>####③本地消息（异步确保）比如：支付宝、微信支付主动查询支付状态，对账单的形式</p>
<p>本地消息表与业务数据表处于同一个数据库中，这样就能利用本地事务来保证在对这两个表的操作满足事务特性，并且使用了消息队列来保证最终—致性。</p>
<ul>
<li>在分布式事务操作的一方完成写业务数据的操作之后向本地消息表发送一个消息，本地事务能保证这个消息一定会被写入本地消息表中。</li>
<li>之后将本地消息表中的消息转发到Kafka等消息队列中，如果转发成功则将消息从本地消息表中删除，否则继续重新转发。</li>
<li>在分布式事务操作的另一方从消息队列中读取一个消息，并执行消息中的操作。</li>
</ul>
<figure data-type="image" tabindex="44"><img src="E:%5Cnote%5C5-%E4%B8%AD%E9%97%B4%E4%BB%B6%5CRabbitMQ%5Cimage%5C90.jpg" alt="image-20210501231747242" loading="lazy"></figure>
<blockquote>
<p>优点：一种非常经典的实现，避免了分布式事务，实现了最终—致性。<br>
缺点：消息表会耦合到业务系统中，如果没有封装好的解决方案，会有很多杂活需要处理。</p>
</blockquote>
<p>####④MQ事务消息，异步场景，通用性较强，拓展性较高。</p>
<p>有一些第三方的MQ是支持事务消息的，比如RocketMQ，他们支持事务消息的方式也是类似于采用的二阶段提交，但是市面上一些主流的MQ都是不支持事务消息的，比如Kafka不支持。<br>
以阿里的RabbitMQ中间件为例，其思路大致为：</p>
<ul>
<li>第一阶段Prepared消息，会拿到消息的地址。第二阶段执行本地事务，第三阶段通过第一阶段拿到的地址去访问消息，并修改状态。<br>
也就是说在业务方法内要想消息队列提交两次请求，一次发送消息和一次确认消息。如果确认消息发送失败了，RabbitMQ会定期扫描消息集群中的事务消息，这时候发现了Prepared消息，它会向消息发送者确认，所以生产方需要实现一个check接口，RabbitMQ会根据发送端设置的第略来决定是回滚还是继续发送确认消息。这样就保证了消息发送与本地事务同时成功或同时失败。</li>
</ul>
<figure data-type="image" tabindex="45"><img src="E:%5Cnote%5C5-%E4%B8%AD%E9%97%B4%E4%BB%B6%5CRabbitMQ%5Cimage%5C91.jpg" alt="image-20210501232113553" loading="lazy"></figure>
<p>优点：实现了最终一致性，不需要依赖本地数据库事务。<br>
缺点：实现难度大，主流MQ不支持，RocketMQ事务消息部分代码也未开源。</p>
<h4 id="5总结">⑤总结</h4>
<p>通过本文我们总结并对比了几种分布式分解方案的优缺点，分布式事务本身是一个技术难题，是没有一种完美的方案应对所有场景的，具体还是要根据业务场景去抉择吧。阿里RocketMQ去实现的分布式事务，现在也有除了很多分布式事务的协调器，比如LCN等，大家可以多去尝试。</p>
<h3 id="具体实现">具体实现</h3>
<p>分布式事务的完整架构图</p>
<figure data-type="image" tabindex="46"><img src="E:%5Cnote%5C5-%E4%B8%AD%E9%97%B4%E4%BB%B6%5CRabbitMQ%5Cimage%5C92.jpg" alt="" loading="lazy"></figure>
<figure data-type="image" tabindex="47"><img src="E:%5Cnote%5C5-%E4%B8%AD%E9%97%B4%E4%BB%B6%5CRabbitMQ%5Cimage%5C93.jpg" alt="" loading="lazy"></figure>
<p>####①系统与系统之间的分布式事问题</p>
<figure data-type="image" tabindex="48"><img src="E:%5Cnote%5C5-%E4%B8%AD%E9%97%B4%E4%BB%B6%5CRabbitMQ%5Cimage%5C94.jpg" alt="" loading="lazy"></figure>
<p>####②系统间调用过程中事务回滚问题</p>
<pre><code class="language-java">package com.xuexiangban .rabbitmq.service;2.
import com.xuexiangban.rabbitmq.dao.orderDataBaseService;
import com.xuexiangban.rabbitmq.pojo.Order;
import org.springframework.beans.factory .annotation.Autowired;
import org.springframework.http.client.SimpleclientHttpRequestFactory;
import org.springframework.stereotype. Service;
import org.springframework.transaction.annotation.Transactional;
import org.springframework.web.client.RestTemplate;

public class OrderService {
    @Autowired
    private OrderDataBaseService orderDataBaseservice;
    //创建订单
    @Transactional(rollbackFor = Exception.class)//订单创建整个方法添加事务
    public void createOrder(Order orderInfo) throws Exception {
        // 1:订单信息--插入丁订单系统，订单数据库事务orderDataBaseService.saveOrder(orderInfo);
        //2∶通通Http接口发途订单信息到运单系统
        String result = dispatchHttpApi(orderInfo.getorderId());
            if( !&quot;success&quot;.equals(result)) {
            throw new Exception(&quot;订单创建失败,原因是运单接口调用失败!&quot;);
        }
    }
    /**
    * 模拟http请求接口发途，运单系统，将订单号传过去 springcloud
    */
    private String dispatchHttpApi(String orderId){
        SimpleclientHttpRehyuestFactory factory - new SimpleClientHttpRequestFactory();
                //链接超时&gt;3秒
        factory .setConnectTimeout ( 300e) ;
        //处理超时&gt;2秒
         factory .setReadTimeout ( 2000) ;
                //发送http请求
        String url = &quot;http: / /localhost:9000/dispatch/order?orderId=&quot;+orderId;
                RestTemplate restTemplate = new RestTemplate(factory);//异常
        String result = restTemplate.getForobject(url，string.class);
                return result;
    }
}
</code></pre>
<p>####③基于MQ的分布式事务整体设计思路</p>
<figure data-type="image" tabindex="49"><img src="E:%5Cnote%5C5-%E4%B8%AD%E9%97%B4%E4%BB%B6%5CRabbitMQ%5Cimage%5C95.jpg" alt="" loading="lazy"></figure>
<p>####④基于MQ的分布式事务消息的可靠生产问题-定时重发</p>
<p>如果这个时候MQ服务器出现了异常和故障，那么消息是无法获取到回执信息。怎么解决呢?</p>
<p>####⑤基于MQ的分布式事务消息的可靠消费</p>
<p>####⑥基于MQ的分布式事务消息的消息重发</p>
<p>解决消息重试的集中方案</p>
<ol>
<li>控制重发的次数</li>
<li>try+catch+手动ack</li>
<li>try+catch+手动ack +死信队列处理</li>
</ol>
<p>####⑦基于MQ的分布式事务消息的死信队列消息转移+人工处理</p>
<p>如果死信队列报错就进行人工处理</p>
<p>####⑧基于MQ的分布式事务消息的死信队列消息重试注意事项</p>
<p>####⑨基于MQ的分布式事务消息的定式重发</p>
<h3 id="总结">总结</h3>
<p>####①基于MQ的分布式事务解决方案优点：</p>
<ol>
<li>通用性强</li>
<li>拓展方便</li>
<li>耦合度低,方案也比较成熟</li>
</ol>
<p>####②基于MQ的分布式事务解决方案缺点：</p>
<ol>
<li>基于消息中间件,只适合异步场景</li>
<li>消息会延迟处理，需要业务上能够容忍</li>
</ol>
<p>####③建议</p>
<ol>
<li>尽量去避免分布式事务</li>
<li>尽量将非核心业务做成异步</li>
</ol>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Redis]]></title>
        <id>https://lindamao.cn/post/redis/</id>
        <link href="https://lindamao.cn/post/redis/">
        </link>
        <updated>2021-03-11T06:13:43.000Z</updated>
        <content type="html"><![CDATA[<h2 id="介绍一下-redis">介绍⼀下 Redis</h2>
<p>简单来说 <strong>Redis 就是⼀个使⽤ C 语⾔开发的数据库</strong>，不过与传统数据库不同的是 <strong>Redis 的数据</strong>是存在内存中的 ，也就是它是内存数据库，所以读写速度⾮常快，因此 Redis 被⼴泛应⽤于缓存⽅向。</p>
<p>另外，<strong>Redis 除了做缓存之外，Redis 也经常⽤来做分布式锁，甚⾄是消息队列</strong>。</p>
<p><strong>Redis 提供了多种数据类型来⽀持不同的业务场景。Redis 还⽀持事务 、持久化、Lua 脚本、多种集群⽅案。</strong></p>
<h2 id="分布式缓存常的技术选型方案有哪些">分布式缓存常⻅的技术选型⽅案有哪些？</h2>
<p>分布式缓存的话，使⽤的比较多的主要是 Memcached 和 Redis。不过，现在基本没有看过还有项⽬使⽤ Memcached 来做缓存，都是直接⽤ Redis。</p>
<p>Memcached 是分布式缓存最开始兴起的那会，比较常⽤的。后来，随着 Redis 的发展，⼤家慢慢都转⽽使⽤更加强⼤的 Redis 了。</p>
<p>分布式缓存主要解决的是单机缓存的容量受服务器限制并且⽆法保存通⽤的信息。因为，本地缓存只在当前服务⾥有效，⽐如你部署了两个相同的服务，他们两者之间的缓存数据是⽆法共同的。</p>
<h2 id="说一下-redis-和-memcached-的区别和共同点">说⼀下 Redis 和 Memcached 的区别和共同点</h2>
<p>现在公司⼀般都是⽤ Redis 来实现缓存，⽽且 Redis ⾃身也越来越强⼤了！不过，了解 Redis 和<br>
Memcached 的区别和共同点，有助于我们在做相应的技术选型的时候，能够做到有理有据！<br>
<strong>共同点 ：</strong></p>
<ol>
<li>都是基于内存的数据库，⼀般都⽤来当做缓存使⽤。</li>
<li>都有过期策略。</li>
<li>两者的性能都⾮常⾼。</li>
</ol>
<p><strong>区别 ：</strong></p>
<ol>
<li>Redis ⽀持更丰富的数据类型（<strong>⽀持更复杂的应⽤场景</strong>）。Redis 不仅仅⽀持简单的 k/v 类型的数据，同时还提供 list，set，zset，hash 等数据结构的存储。Memcached 只⽀持最简单的 k/v 数据类型。</li>
<li><strong>Redis ⽀持数据的持久化</strong>，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进⾏使⽤,⽽ Memecache 把数据全部存在内存之中。</li>
<li>Redis <strong>有灾难恢复机制</strong>。 因为可以把缓存中的数据持久化到磁盘上。</li>
<li>Redis 在服务器内存使⽤完之后，可以将不⽤的数据放到磁盘上。但是，Memcached 在服务器内存使⽤完之后，就会直接报异常。</li>
<li>Memcached 没有原⽣的集群模式，需要依靠客户端来实现往集群中分⽚写⼊数据；但是Redis ⽬前是<strong>原⽣⽀持 cluster 模式</strong>的.</li>
<li>Memcached 是<strong>多线程，⾮阻塞 IO 复⽤的⽹络模型</strong>；Redis 使⽤<strong>单线程的多路 IO 复⽤模型</strong>。 （Redis 6.0 引⼊了多线程 IO ）</li>
<li>Redis <strong>⽀持发布订阅模型、Lua 脚本、事务</strong>等功能，⽽ Memcached 不⽀持。并且，Redis⽀持更多的编程语⾔。</li>
<li>Memcached过期数据的删除策略只⽤了惰性删除，⽽ Redis 同时使⽤了<strong>惰性删除与定期删除</strong>。</li>
</ol>
<p><strong>更推荐Redis作为分布式的缓存</strong></p>
<h2 id="缓存数据的处理流程是怎样的">缓存数据的处理流程是怎样的？</h2>
<p>流程图：</p>
<ol>
<li>如果⽤户请求的数据在缓存中就直接返回。</li>
<li>缓存中不存在的话就看数据库中是否存在。</li>
<li>数据库中存在的话就更新缓存中的数据。</li>
<li>数据库中不存在的话就返回空数</li>
</ol>
<figure data-type="image" tabindex="1"><img src="D:%5Cnote%5C%E9%9D%A2%E8%AF%95%5C%E9%9D%A2%E8%AF%95.assets%5Cimage-20230203111116721.png" alt="image-20230203111116721" loading="lazy"></figure>
<h2 id="为什么要用-redis为什么要用缓存">为什么要⽤ Redis/为什么要⽤缓存？</h2>
<figure data-type="image" tabindex="2"><img src="D:%5Cnote%5C%E9%9D%A2%E8%AF%95%5C%E9%9D%A2%E8%AF%95.assets%5Cimage-20230203111135947.png" alt="image-20230203111135947" loading="lazy"></figure>
<p><strong>针对高性能和高并发出发</strong></p>
<p><strong>⾼性能 ：</strong></p>
<p>假如⽤户第⼀次访问数据库中的某些数据的话，这个过程是⽐᫾慢，毕竟是从硬盘中读取的。但是，如果说，⽤户访问的数据属于⾼频数据并且不会经常改变的话，那么我们就可以很放⼼地将该⽤户访问的数据存在缓存中。<strong>这样有什么好处</strong>呢？ 那就是保证⽤户下⼀次再访问这些数据的时候就可以直接从缓存中获取了。</p>
<p>操作缓存就是<strong>直接操作内存，所以速度相当快</strong>。</p>
<p>不过，要保持数据库和缓存中的数据的⼀致性。 如果数据库中的对应数据改变的之后，<strong>同步改变缓存中相应的数据即可</strong>！</p>
<p><strong>⾼并发：</strong></p>
<p>⼀般像 MySQL 这类的数据库的 QPS ⼤概都在 1w 左右（4 核 8g） ，但是使⽤ Redis 缓存之后很容易达到 10w+，甚⾄最⾼能达到 30w+（就单机 redis 的情况，redis 集群的话会更⾼）。</p>
<p><strong>QPS（Query Per Second）：服务器每秒可以执⾏的查询次数</strong></p>
<p>所以，直接操作缓存能够承受的数据库请求数量是远远⼤于直接访问数据库的，所以我们可以考虑把数据库中的部分数据转移到缓存中去，这样⽤户的⼀部分请求会直接到缓存这⾥⽽不⽤经过数据库进⽽我们也就提⾼的系统整体的</p>
<h2 id="io模型">IO模型</h2>
<p>https://zhuanlan.zhihu.com/p/115912936</p>
<h2 id="io多路复用机制">IO多路复用机制</h2>
<p>https://blog.csdn.net/sehanlingfeng/article/details/78920423</p>
<h2 id="bionioaio-有什么区别"><strong>BIO,NIO,AIO 有什么区别?</strong></h2>
<p><strong>BIO (Blocking I/O): 同步阻塞 I/O 模式</strong>，<strong>数据的读取写⼊必须阻塞在⼀个线程内等待其完成</strong>。在活动连接数不是特别⾼（⼩于单机 1000）的情况下，这种模型是比较不错的，可以让每⼀个连接专注于⾃⼰的 I/O 并且编程模型简单，也不⽤过多考虑系统的过载、限流等问题。线程池本身就是⼀个天然的漏⽃，可以缓冲⼀些系统处理不了的连接或请求。但是，当⾯对⼗万甚⾄百万级连接的时候，传统的 BIO 模型是⽆能为⼒的。因此，我们需要⼀种更⾼效的 I/O 处理模型来应对更⾼的并发量。</p>
<p><strong>NIO (Non-blocking/New I/O): NIO 是⼀种同步⾮阻塞的 I/O 模型</strong>，在 Java 1.4 中引⼊了NIO 框架，对应 java.nio 包，提供了 <strong>Channel</strong> , <strong>Selector</strong>，Buffer 等抽象。NIO 中的 N 可以理解为 Non-blocking，不单纯是 New。它⽀持<strong>⾯向缓冲</strong>的，基于通道的 I/O 操作⽅法。</p>
<p>NIO 提供了与传统 BIO 模型中的 Socket 和 ServerSocket 相对应的 SocketChannel 和ServerSocketChannel 两种不同的套接字通道实现,两种通道都⽀持阻塞和⾮阻塞两种模式。阻塞模式使⽤就像传统中的⽀持⼀样，比较简单，但是性能和可靠性都不好；⾮阻塞模式正好与之相反。对于低负载、低并发的应⽤程序，可以使⽤同步阻塞 I/O 来提升开发速率和更好的维护性；对于⾼负载、⾼并发的（⽹络）应⽤，应使⽤ NIO 的⾮阻塞模式来开发</p>
<p><strong>AIO (Asynchronous I/O): AIO 也就是 NIO 2</strong>。在 Java 7 中引⼊了 NIO 的改进版 NIO 2,它是<strong>异步⾮阻塞的 IO 模型</strong>。异步 IO 是<strong>基于事件和回调机制实现</strong>的，也就是应⽤操作之后会直接返回，不会堵塞在那⾥，当后台处理完成，操作系统会通知相应的线程进⾏后续的操作。<br>
AIO 是异步 IO 的缩写，<strong>虽然 NIO 在⽹络操作中，提供了⾮阻塞的⽅法，但是 NIO 的 IO ⾏为还是同步的</strong>。对于 NIO 来说，我们的业务线程是在 IO 操作准备好时，得到通知，接着就由这个线程⾃⾏进⾏ IO 操作，IO 操作本身是同步的。查阅⽹上相关资料，我发现就⽬前来说 AIO 的应⽤还不是很⼴泛，Netty 之前也尝试使⽤过 AIO，不过⼜放弃了</p>
<p><strong>NIO与BIO区别</strong></p>
<ul>
<li>通讯方式：NIO 通过<strong>Channel（通道）</strong> 进行读写，通道是<strong>双向</strong>的，可读也可写。而BIO使用的<strong>流读写是单向</strong>的。</li>
<li>BIO流是阻塞的，NIO流是不阻塞的。</li>
<li><strong>BIO 面向流(Stream oriented)</strong>，<strong>而 NIO 面向缓冲区(Buffer oriented)</strong>。
<ol>
<li>在面向流的I/O中·可以将数据直接写入或者将数据直接读到 Stream 对象中。<strong>虽然 Stream 中也有 Buffer 开头的扩展类，但只是流的包装类，还是从流读到缓冲区</strong>，而 NIO 却是<strong>直接读到 Buffer 中进行操作</strong>。</li>
<li>在NIO厍中，所有数据都是用缓冲区处理的。在读取数据时，它是直接读到缓冲区中的; 在写入数据时，写入到缓冲区中。<strong>任何时候访问NIO中的数据，都是通过缓冲区进行操作</strong>。</li>
</ol>
</li>
</ul>
<p>NIO 带来了什么</p>
<ul>
<li><strong>避免多线程</strong></li>
<li><strong>非阻塞I/O，I/O读写不再阻塞，而是返回0</strong></li>
<li>单线程处理多任务</li>
<li>基于block的传输，通常比基于流的传输更高效</li>
<li>更高级的IO函数，zero-copy</li>
<li><strong>事件驱动模型</strong></li>
<li><strong>IO多路复用大大提高了Java网络应用的可伸缩性和实用性</strong></li>
</ul>
<h2 id="redis-常数据结构以及使用场景分析">Redis 常⻅数据结构以及使⽤场景分析</h2>
<h3 id="string"><strong>String</strong></h3>
<p>​	1.<strong>介绍</strong> ：string 数据结构是简单的 key-value 类型。虽然 Redis 是⽤ C 语⾔写的，但是 Redis并没有使⽤ C 的字符串表示，⽽是⾃⼰构建了⼀种 简单动态字符串（simple dynamicstring，SDS）。相⽐于 C 的原⽣字符串，Redis 的 SDS 不光可以保存⽂本数据还可以保存<br>
⼆进制数据，并且获取字符串⻓度复杂度为 O(1)（C 字符串为 O(N)）,除此之外,Redis 的SDS API 是安全的，不会造成缓冲区溢出。</p>
<ol start="2">
<li><strong>常⽤命令</strong>: set,get,strlen,exists,dect,incr,setex 等等。</li>
<li><strong>应⽤场景</strong> ：⼀般常⽤在需要<strong>计数的场景</strong>，⽐如⽤户的访问次数、热点⽂章的点赞转发数量等，共享用户session。<br>
等。</li>
<li>.redis 的 string 类型存储的限制为<strong>512M</strong></li>
</ol>
<h3 id="list">list</h3>
<ol>
<li><strong>介绍</strong> ：list 即是 链表。链表是⼀种⾮常常⻅的数据结构，特点是易于数据元素的插⼊和删除并且且可以灵活调整链表⻓度，但是链表的随机访问困难。许多⾼级编程语⾔都内置了链表的实现⽐如 Java 中的 <strong>LinkedList</strong>，但是 C 语⾔并没有实现链表，所以 Redis 实现了⾃⼰的链表数据结构。Redis 的 list 的实现为⼀个 <strong>双向链表</strong>，即可以⽀持<strong>反向查找和遍历</strong>，更⽅便操作，不过带来了部分额外的内存开销。</li>
<li><strong>常⽤命令</strong>: rpush,lpop,lpush,rpop,lrange.llen 等。</li>
<li><strong>应⽤场景</strong>: <strong>发布与订阅或者说消息队列、慢查询</strong>。</li>
</ol>
<h3 id="hash">hash</h3>
<ol>
<li><strong>介绍</strong> ：hash 类似于 JDK1.8 前的 HashMap，内部实现也差不多(数组 + 链表)。不过，Redis 的 hash 做了更多优化。另外，<strong>hash 是⼀个 string 类型的 field 和 value 的映射表，特别适合⽤于存储对象，后续操作的时候，你可以直接仅仅修改这个对象中的某个字段的值。</strong> ⽐如我们可以 hash 数据结构来存储<strong>⽤户信息，商品信息</strong>等等。</li>
<li><strong>常⽤命令</strong>： hset,hmset,hexists,hget,hgetall,hkeys,hvals 等。</li>
<li><strong>应⽤场景:</strong> 系统中对象数据的存储。</li>
</ol>
<h3 id="set">set</h3>
<ol>
<li><strong>介绍</strong> ： set 类似于 Java 中的 HashSet 。Redis 中的 set 类型是⼀种⽆序集合，集合中的元素没有先后顺序。当你需要存储⼀个列表数据，⼜不希望出现重复数据时，set 是⼀个很好的选择，并且 set 提供了判断某个成员是否在⼀个 set 集合内的重要接⼝，这个也是 list 所不能提供的。可以基于 set 轻易实现交集、并集、差集的操作。</li>
<li>⽐如：你可以将⼀个⽤户所有的关注⼈存在⼀个集合中，将其所有粉丝存在⼀个集合。Redis 可以⾮常⽅便的实现如共同关注、共同粉丝、共同喜好等功能。这个过程也就是求交集的过程。</li>
<li><strong>常⽤命令</strong>： sadd,spop,smembers,sismember,scard,sinterstore,sunion 等。<br>
3. <strong>应⽤场景:</strong> 需要存放的数据不能重复以及需要获取多个数据源交集和并集等场景 例如：在微博应⽤中，可以将⼀个⽤户所有的关注⼈存在⼀个集合中，将其所有粉丝存在⼀个集合。Redis可以⾮常⽅便的实现如<strong>共同关注、共同粉丝、共同喜好</strong>等功能。这个过程也就是求交集的过程，</li>
</ol>
<h3 id="sorted-set">sorted set</h3>
<ol>
<li><strong>介绍</strong>： 和 set 相⽐，sorted set 增加了⼀个权重参数 score，使得集合中的元素能够按 score进⾏有序排列，还可以通过 score 的范围来获取元素的列表。有点像是 Java 中 HashMap和 TreeSet 的结合体。</li>
<li><strong>常⽤命令</strong>： zadd,zcard,zscore,zrange,zrevrange,zrem 等。</li>
<li><strong>应⽤场景：</strong> 需要对数据根据某个权重进⾏排序的场景，比如微博热搜，做带权重的队列⽐如在直播系统中，实时排⾏信息包含直播间<strong>在线⽤户列表，各种礼物排⾏榜，弹幕消息</strong>（可以理解为按消息维度的消息排⾏榜）等信息 。</li>
</ol>
<h2 id="redis线程">Redis线程</h2>
<h3 id="redis单线程原理">Redis单线程原理</h3>
<p>首先必须明确，Redis单线程指的是网络请求模块使用了一个线程（，其他模块仍用了多个线程。并不是一个线程完成了所有功能。原理上，其采用了利用epoll的多路复用特性，因此可以采用单线程处理其网络请求。</p>
<h3 id="redis-单线程模型详解">Redis 单线程模型详解</h3>
<p><strong>Redis 基于 Reactor 模式来设计开发了⾃⼰的⼀套⾼效的事件处理模型</strong> （Netty 的线程模型也基于 Reactor 模式，Reactor 模式不愧是⾼性能 IO 的基⽯），这套事件处理模型对应的是 Redis中的<strong>⽂件事件处理器</strong>（file event handler）。由于⽂件事件处理器（file event handler）是单线程⽅式运⾏的，所以我们⼀般都说 Redis 是单线程模型。</p>
<p><strong>既然是单线程，那怎么监听⼤量的客户端连接呢？</strong></p>
<p>Redis 通过<strong>IO 多路复⽤程序</strong> 来监听来⾃客户端的⼤量连接（或者说是监听多个 socket），它会将感兴趣的事件及类型(读、写）注册到内核中并监听每个事件是否发⽣。</p>
<p>这样的好处⾮常明显： <strong>I/O 多路复⽤技术的使⽤让 Redis 不需要额外创建多余的线程来监听客户端的⼤量连接，降低了资源的消耗</strong>（和 NIO 中的 Selector 组件很像）。</p>
<p>另外， Redis 服务器是⼀个事件驱动程序，服务器需要处理两类事件： 1. ⽂件事件; 2. 时间事件。</p>
<p>时间事件不需要多花时间了解，我们接触最多的还是 ⽂件事件（<strong>客户端进⾏读取写⼊等操作，涉及⼀系列⽹络通信</strong>）。</p>
<pre><code>Redis 基于 Reactor 模式开发了⾃⼰的⽹络事件处理器：这个处理器被称为⽂件事件处理器（file event handler）。⽂件事件处理器使⽤ I/O 多路复⽤（multiplexing）程序来同时监听多个套接字，并根据 套接字⽬前执⾏的任务来为套接字关联不同的事件处理器。当被监听的套接字准备好执⾏连接应答（accept）、读取（read）、写⼊（write）、关 闭（close）等操作时，与操作相对应的⽂件事件就会产⽣，这时⽂件事件处理器就会调⽤套接字之前关联好的事件处理器来处理这些事件。虽然⽂件事件处理器以单线程⽅式运⾏，但通过使⽤ I/O 多路复⽤程序来监听多个套接字，⽂件事件处理器既实现了⾼性能的⽹络通信模型，⼜可以很好地与 Redis 服务器中其他同样以单线程⽅式运⾏的模块进⾏对接，这保持了 Redis 内部单线程设计的简单性。
</code></pre>
<p>可以看出，⽂件事件处理器（file event handler）主要是包含 4 个部分：</p>
<ul>
<li>
<p>多个 socket（客户端连接）</p>
</li>
<li>
<p>IO 多路复⽤程序（⽀持多个客户端连接的关键）</p>
</li>
<li>
<p>⽂件事件分派器（将 socket 关联到相应的事件处理器）</p>
</li>
<li>
<p>事件处理器（连接应答处理器、命令请求处理器、命令回复处理器）</p>
<figure data-type="image" tabindex="3"><img src="D:%5Cnote%5C%E9%9D%A2%E8%AF%95%5C%E9%9D%A2%E8%AF%95.assets%5Cimage-20230203111214293.png" alt="image-20230203111214293" loading="lazy"></figure>
</li>
</ul>
<h3 id="redis-没有使用多线程为什么不使用多线程">Redis 没有使⽤多线程？为什么不使⽤多线程</h3>
<p>虽然说 Redis 是单线程模型，但是， 实际上，Redis 在 4.0 之后的版本中就已经加⼊了对多线程的支持</p>
<p>不过，Redis 4.0 增加的多线程主要是针对⼀些⼤键值对的删除操作的命令，使⽤这些命令就会使⽤主处理之外的其他线程来“异步处理”。<br>
⼤体上来说，Redis 6.0 之前主要还是**单线程处理。**那，Redis6.0 之前 为什么不使⽤多线程？<br>
主要原因：</p>
<ol>
<li>单线程编程容易并且更<strong>容易维护</strong>；</li>
<li>Redis的性能瓶颈不在 <strong>CPU</strong> ，主要在<strong>内存和⽹络</strong>；</li>
<li>多线程就会存在<strong>死锁、线程上下⽂切换</strong>等问题，甚⾄<strong>会影响性能</strong>。</li>
</ol>
<h3 id="redis60-之后为何引入了多线程">Redis6.0 之后为何引⼊了多线程？</h3>
<p>Redis6.0 引⼊多线程主要是为了提⾼⽹络 IO 读写性能，因为这个算是 Redis 中的⼀个性能瓶颈（Redis 的瓶颈主要受限于内存和⽹络）。</p>
<p>虽然，Redis6.0 引⼊了多线程，但是 Redis 的<strong>多线程只是在⽹络数据的读写</strong>这类耗时操作上使⽤了， <strong>执⾏命令仍然是单线程顺序执⾏</strong>。因此，你也不需要担⼼线程安全问题。</p>
<p>Redis6.0 的<strong>多线程默认是禁⽤的</strong>，只使⽤主线程。如需开启需要修改 <strong>redis</strong> 配置⽂件 <strong>redis.conf</strong></p>
<figure data-type="image" tabindex="4"><img src="D:%5Cnote%5C%E9%9D%A2%E8%AF%95%5C%E9%9D%A2%E8%AF%95.assets%5Cimage-20230203111239352.png" alt="image-20230203111239352" loading="lazy"></figure>
<p>开启多线程后还需要设置线程数否则是不⽣效的。同样需要修改 redis 配置⽂件 <strong>redis.conf :</strong></p>
<figure data-type="image" tabindex="5"><img src="D:%5Cnote%5C%E9%9D%A2%E8%AF%95%5C%E9%9D%A2%E8%AF%95.assets%5Cimage-20230203111247809.png" alt="image-20230203111247809" loading="lazy"></figure>
<p>参考连接：https://mp.weixin.qq.com/s/FZu3acwK6zrCBZQ_3HoUgw</p>
<p>​				   https://draveness.me/whys-the-design-redis-single-thread/</p>
<h2 id="redis多线程">Redis多线程</h2>
<p>https://blog.csdn.net/lizhengze1117/article/details/108032406</p>
<h2 id="什么情况下使用redis">什么情况下使用redis</h2>
<p>https://blog.csdn.net/qq_35190492/article/details/103105780</p>
<ol>
<li>针对热点数据进行缓存</li>
<li>对于特定限时数据的存放</li>
<li>针对带热点权值数据的<a href="https://www.nowcoder.com/jump/super-jump/word?word=%E6%8E%92%E5%BA%8F">排序</a>list</li>
<li>分布式锁</li>
</ol>
<h2 id="为什么要给redis缓存数据设置过期时间">为什么要给Redis缓存数据设置过期时间</h2>
<p>因为内存是有限的，如果缓存中的所有数据都是⼀直保存的话，分分钟直接**Out of memory。**Redis ⾃带了给缓存数据设置过期时间的功能，⽐如：</p>
<figure data-type="image" tabindex="6"><img src="D:%5Cnote%5C%E9%9D%A2%E8%AF%95%5C%E9%9D%A2%E8%AF%95.assets%5Cimage-20230203111259581.png" alt="image-20230203111259581" loading="lazy"></figure>
<p>注意：Redis中除了字符串类型有⾃⼰独有设置过期时间的命令 <strong>setex</strong> 外，其他⽅法都需要依靠<strong>expire</strong> 命令来设置过期时间 。另外， persist 命令可以移除⼀个键的过期时间<br>
<strong>过期时间除了有助于缓解内存的消耗，还有什么其他⽤么？</strong></p>
<p><strong>验证码有效时间 token有效时间</strong></p>
<p>很多时候，我们的业务场景就是需要某个数据只在某⼀时间段内存在，⽐如我们的短信验证码可能只在1分钟内有效，⽤户登录的 token 可能只在 1 天内有效。如果使⽤传统的数据库来处理的话，⼀般都是⾃⼰判断过期，这样更麻烦并且<strong>性能</strong>要差很多。</p>
<p><strong>避免数据库和缓存的不一致</strong></p>
<p><strong>设置缓存过期时间当缓存当中的值失效了之后就会到数据库当中去更新数据</strong></p>
<h2 id="redis是如何判断数据是否过期">Redis是如何判断数据是否过期</h2>
<p>Redis 通过⼀个叫做<strong>过期字典</strong>（可以看作是hash表）来保存数据过期的时间。过期字典的键指向<br>
Redis数据库中的某个key(键)，过期字典的值是⼀个long long类型的整数，这个整数保存了key所<br>
指向的数据库键的过期时间（毫秒精度的UNIX时间戳）。</p>
<figure data-type="image" tabindex="7"><img src="D:%5Cnote%5C%E9%9D%A2%E8%AF%95%5C%E9%9D%A2%E8%AF%95.assets%5Cimage-20230203111310626.png" alt="image-20230203111310626" loading="lazy"></figure>
<p><strong>过期字典</strong>是存储在redisDb这个结构⾥的：</p>
<figure data-type="image" tabindex="8"><img src="D:%5Cnote%5C%E9%9D%A2%E8%AF%95%5C%E9%9D%A2%E8%AF%95.assets%5Cimage-20230203111320481.png" alt="image-20230203111320481" loading="lazy"></figure>
<h2 id="过期的数据的删除策略">过期的数据的删除策略</h2>
<p>如果假设你设置了⼀批 key 只能存活 1 分钟，那么 1 分钟后，Redis 是怎么对这批 key 进⾏删除的呢？<br>
常⽤的过期数据的删除策略就两个（重要！⾃⼰造缓存轮⼦的时候需要格外考虑的东⻄）：</p>
<ol>
<li>
<p><strong>惰性删除</strong> ：只会在取出key的时候才对数据进⾏过期检查。这样对CPU最友好，但是可能会造成太多过期 key 没有被删除。</p>
</li>
<li>
<p><strong>定期删除</strong> ： 每隔⼀段时间抽取⼀批 key 执⾏删除过期key操作。并且，Redis 底层会通过限制删除操作执⾏的时⻓和频率来减少删除操作对CPU时间的影响。<br>
定期删除对内存更加友好，惰性删除对CPU更加友好。两者各有千秋，所以Redis 采⽤的是 定期删除+惰性/懒汉式删除 。<br>
但是，仅仅通过给 key 设置过期时间还是有问题的。因为还是可能存在定期删除和惰性删除漏掉了很多过期 key 的情况。这样就导致⼤量过期 key 堆积在内存⾥，然后就Out of memory了。</p>
<p>怎么解决这个问题呢？答案就是： <strong>Redis 内存淘汰机制。</strong></p>
</li>
</ol>
<h2 id="redis-内存淘汰机制">Redis 内存淘汰机制</h2>
<p><strong>相关问题</strong>：MySQL ⾥有 2000w 数据，Redis 中只存 20w 的数据，如何保证 Redis 中的数据都是热点数据?</p>
<p><strong>Redis 提供 6 种数据淘汰策略：</strong></p>
<ol>
<li>volatile-lru（least recently used）：从已设置过期时间的数据集（server.db[i].expires）中挑选<strong>最近最少使⽤</strong>的数据淘汰</li>
<li>volatile-ttl：从已设置过期时间的数据集（server.db[i].expires）中挑选<strong>将要过期</strong>的数据淘汰</li>
<li>volatile-random：从已设置过期时间的数据集（server.db[i].expires）中<strong>任意选择数据淘汰</strong></li>
<li>allkeys-lru（least recently used）：当内存不⾜以容纳新写⼊数据时，在键空间中，移除<br>
最近最少使⽤的 key（这个是最常⽤的）</li>
<li>allkeys-random：从数据集（server.db[i].dict）中任意选择数据淘汰</li>
<li>no-eviction：禁⽌驱逐数据，也就是说当内存不⾜以容纳新写⼊数据时，新写⼊操作会报错。这个应该没⼈使⽤吧！<br>
4.0 版本后增加以下两种：</li>
<li>volatile-lfu（least frequently used）：<strong>从已设置过期时间的数据集(server.db[i].expires)中挑选最不经常使⽤的数据淘汰</strong></li>
<li>allkeys-lfu（least frequently used）：<strong>当内存不⾜以容纳新写⼊数据时，在键空间中，移除最不经常使⽤的 key</strong></li>
</ol>
<h2 id="redis-持久化机制">Redis 持久化机制</h2>
<p><strong>(怎么保证 Redis 挂掉之后再重启数据可以进⾏恢复)</strong></p>
<p>很多时候我们需要持久化数据也就是将内存中的数据写⼊到硬盘⾥⾯，⼤部分原因是为了之后重⽤数据（⽐如重启机器、机器故障之后恢复数据），或者是为了防⽌系统故障⽽将数据备份到个远程位置。Redis 不同于 Memcached 的很重要⼀点就是，Redis ⽀持持久化，⽽且⽀持两种不同的持久化操作。Redis 的⼀种持久化⽅式叫快照（snapshotting，<strong>RDB</strong>），另⼀种⽅式是只追加⽂件append-only file, （<strong>AOF</strong>）。这两种⽅法各有千秋，下⾯我会详细这两种持久化⽅法是什么，么⽤，如何选择适合⾃⼰的持久化⽅法。<br>
<strong>快照（snapshotting）持久化（RDB)</strong><br>
Redis 可以通过创建快照来获得存储在内存⾥⾯的数据在某个时间点上的副本。Redis 创建快照之后，可以对快照进⾏备份，可以将快照复制到其他服务器从⽽创建具有相同数据的服务器副本（<strong>Redis 主从结构，主要⽤来提⾼ Redis 性能</strong>），还可以将快照留在原地以便重启服务器的时候使⽤。</p>
<p>快照持久化RDB是 **Redis 默认采⽤的持久化⽅式，**在 Redis.conf 配置⽂件中默认有此下配置：</p>
<figure data-type="image" tabindex="9"><img src="D:%5Cnote%5C%E9%9D%A2%E8%AF%95%5C%E9%9D%A2%E8%AF%95.assets%5Cimage-20230203111331829.png" alt="image-20230203111331829" loading="lazy"></figure>
<p><strong>AOF（append-only file）持久化</strong></p>
<p>与快照持久化相⽐，AOF 持久化 的<strong>实时性</strong>更好，因此已成为主流的持久化⽅案。默认情况下Redis 没有开启 AOF（append only file）⽅式的持久化，可以通过 appendonly 参数开启：</p>
<figure data-type="image" tabindex="10"><img src="D:%5Cnote%5C%E9%9D%A2%E8%AF%95%5C%E9%9D%A2%E8%AF%95.assets%5Cimage-20230203111338949.png" alt="image-20230203111338949" loading="lazy"></figure>
<p>开启 AOF 持久化后每执⾏⼀条会更改 Redis 中的数据的命令，Redis 就会将该命令写⼊硬盘中的 AOF ⽂件。AOF ⽂件的保存位置和 RDB ⽂件的位置相同，都是通过 dir 参数设置的，默认的<br>
⽂件名是 **appendonly.aof。**在 Redis 的配置⽂件中存在三种不同的 AOF 持久化⽅式，它们分别是：</p>
<figure data-type="image" tabindex="11"><img src="D:%5Cnote%5C%E9%9D%A2%E8%AF%95%5C%E9%9D%A2%E8%AF%95.assets%5Cimage-20230203111346448.png" alt="image-20230203111346448" loading="lazy"></figure>
<p>为了兼顾数据和写⼊性能，⽤户可以考虑 <strong>appendfsync everyse</strong>c 选项 ，让 Redis 每秒同步⼀次AOF ⽂件，Redis 性能⼏乎没受到任何影响。⽽且这样即使出现系统崩溃，⽤户最多只会丢失⼀秒之内产⽣的数据。当硬盘忙于执⾏写⼊操作的时候，Redis 还会优雅的放慢⾃⼰的速度以便适应硬盘的最⼤写⼊速度。</p>
<p><strong>补充内容：AOF 重写</strong></p>
<p>AOF 重写可以产⽣⼀个新的 AOF ⽂件，这个新的 AOF ⽂件和原有的 AOF ⽂件所保存的数据库状态⼀样，但体积更⼩。</p>
<p>AOF 重写是⼀个有歧义的名字，该功能是通过读取数据库中的键值对来实现的，程序⽆须对现有AOF ⽂件进⾏任何读⼊、分析或者写⼊操作。</p>
<p>在执⾏ BGREWRITEAOF 命令时，Redis 服务器会维护⼀个 AOF 重写缓冲区，该缓冲区会在⼦进程创建新 AOF ⽂件期间，记录服务器执⾏的所有写命令。当⼦进程完成创建新 AOF ⽂件的⼯作之后，服务器会将重写缓冲区中的所有内容追加到新 AOF ⽂件的末尾，使得新旧两个 AOF ⽂件所保存的数据库状态⼀致。最后，服务器⽤新的 AOF ⽂件替换旧的 AOF ⽂件，以此来完成AOF ⽂件重写操作</p>
<h3 id="rdb">RDB</h3>
<p>RDB即将当前数据生成快照，并保存于硬盘中。可以通过手动命令，也可以设置自动触发。</p>
<h3 id="简述redis的aof">简述Redis的AOF</h3>
<p><strong>AOF通过日志</strong>，对数据的写入修改操作进行记录。这种持久化方式实时性更好。通过配置文件打开AOF。</p>
<h3 id="简述aof的持久化策略">简述AOF的持久化策略</h3>
<ol>
<li>always。每执行一次数据修改命令就将其命令写入到磁盘日志文件上。</li>
<li>everysec。每秒将命令写入到磁盘日志文件上。</li>
<li>no。不主动设置，由操作系统决定什么时候写入到磁盘日志文件上。</li>
</ol>
<h3 id="简述aof的重写">简述AOF的重写</h3>
<p>随着<a href="">客户端</a>不断进行操作，AOF对应的文件也越来越大。<a href="">redis</a>提供了<strong>bgrewriteaof函数</strong>，针对目前数据库中数据，在不读取原有AOF文件的基础上，重写了一个新的AOF文件，减少文件大小。</p>
<h3 id="rdb与aof优缺点比较">RDB与AOF优缺点比较</h3>
<p>AOF占用的文件体积比RDB大。一般来说利用AOF备份对系统的消耗比RDB低。对于备份时出现系统故障，RDB数据可能会全丢，但AOF只会损失一部分。RDB恢复速度比AOF低。</p>
<h3 id="redis自动触发rdb机制">Redis自动触发RDB机制</h3>
<ol>
<li>通过<strong>配置文件</strong>，设置<strong>一定时间后自动执行RDB</strong></li>
<li>如采用<strong>主从复制过程</strong>，会<strong>自动执行RDB</strong></li>
<li>Redis执行shutdown时，在未开启AOF后会执行RDB</li>
</ol>
<h2 id="redis-事务">Redis 事务</h2>
<p>Redis 可以通过 <strong>MULTI，EXEC，DISCARD 和 WATCH</strong> 等命令来实现事务(transaction)功能。</p>
<figure data-type="image" tabindex="12"><img src="D:%5Cnote%5C%E9%9D%A2%E8%AF%95%5C%E9%9D%A2%E8%AF%95.assets%5Cimage-20230203111358081.png" alt="image-20230203111358081" loading="lazy"></figure>
<p>使⽤ <strong>MULTI</strong>命令后可以输⼊多个命令。Redis不会⽴即执⾏这些命令，⽽是将它们放到队列，当调⽤了<strong>EXEC</strong>命令将执⾏所有命令。</p>
<p>但是Redis 的事务和我们平时理解的关系型数据库的事务不同于我们知道事务具有四大特性</p>
<p><strong>Redis 是不⽀持 roll back 的因⽽不满⾜原⼦性的（⽽且不满⾜持久性）</strong></p>
<p>Redis官⽹也解释了⾃⼰为啥不⽀持回滚。简单来说就是Redis开发者们觉得没必要⽀持回滚，这样更简单便捷并且性能更好。<strong>Redis开发者觉得即使命令执⾏错误也应该在开发过程中就被发现⽽不是⽣产过程中</strong></p>
<p>你可以将Redis中的事务就理解为 ：<strong>Redis事务提供了⼀种将多个命令请求打包的功能 ，将这些任务放到队列里面就不会出现被打断的现象 并且任务会按照顺序执行</strong>。</p>
<p>多数事务失败是由语法错误或者数据结构类型错误导致的，语法错误说明在命令入队前就进行检测的，而类型错误是在执行时检测的，Redis为提升性能而采用这种简单的事务，这是不同于关系型数据库的，特别要注意区分</p>
<h2 id="缓存穿透">缓存穿透</h2>
<h3 id="什么是缓存穿透">什么是缓存穿透</h3>
<p>缓存穿透说简单点就是⼤量请求的 key 根本<strong>不存在于缓存中</strong>，导致请求直接到了数据库上，根本没有经过缓存这⼀层。举个例⼦：某个⿊客故意制造我们缓存中不存在的 key 发起⼤量请求，导致⼤量请求落到数据库。</p>
<h3 id="缓冲穿透情况的处理流程">缓冲穿透情况的处理流程</h3>
<figure data-type="image" tabindex="13"><img src="D:%5Cnote%5C%E9%9D%A2%E8%AF%95%5C%E9%9D%A2%E8%AF%95.assets%5Cimage-20230203111412798.png" alt="image-20230203111412798" loading="lazy"></figure>
<h3 id="解决缓存穿透的方法">解决缓存穿透的方法</h3>
<ul>
<li>解决方案：
<ul>
<li><strong>对参数进行校验。错误的参数直接过滤</strong>。</li>
<li><strong>缓存无效key</strong>，<strong>并设置过期时间</strong>。
<ul>
<li>缺点：会导致大量的无效缓存</li>
</ul>
</li>
<li><strong>布隆过滤器</strong>：把所有可能存在的请求的值都存放在布隆过滤器中,当用户请求过来,先判断用户发来的请求的值是否存在于布隆过滤器中。不存在的话,直接返回请求参数错误信息给客户端,存在的话才会走下面的流程。
<ul>
<li>缺点：可能会导致误判</li>
<li>布隆过滤器通过哈希函数计算key的哈系值然后获取相应的位置。并把位置的值置为1。由于会存在哈希冲突，所以布隆过滤器说某个元素存在，小概率会误判。布隆过滤器说某个元素不在，那么这个元素一定不在。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="缓存雪崩">缓存雪崩</h2>
<h3 id="什么是缓存雪崩">什么是缓存雪崩</h3>
<p>缓存在同⼀时间⼤⾯积的失效，后⾯的请求都直接落到了数据库上，造成数据库短时间内承受⼤量请求。 这就好⽐雪崩⼀样，摧枯拉朽之势数据库的压⼒可想⽽知，可能直接就被这么多请求弄宕机了。</p>
<p>举个例⼦：系统的缓存模块出了问题⽐如宕机导致不可⽤。造成系统的所有访问，都要⾛数据库。</p>
<p><strong>还有⼀种缓存雪崩的场景</strong>是：有⼀些被⼤量访问数据（热点缓存）在某⼀时刻⼤⾯积失效，导致对应的请求直接落到了数据库上。 这样的情况，有下⾯⼏种解决办法：举个例⼦ ：秒杀开始 12 个⼩时之前，我们统⼀存放了⼀批商品到 Redis 中，设置的缓存过期时间也是 12 个⼩时，那么秒杀开始的时候，这些秒杀的商品的访问直接就失效了。导致的情况就是，相应的请求直接就落到了数据库上，就像雪崩⼀样可怕。</p>
<h3 id="解决方法">解决方法</h3>
<ul>
<li>解决方案：
<ul>
<li>加锁：如果缓存失效的话，则对操作进行加锁，然后获取数据。</li>
<li>Redis集群：使用redis集群并设置不同的失效时间比如随机设置缓存的失效时间。</li>
<li>随机指数退避算法：如果发现缓存失效，则随机一个很短的时间，并sleep，再次查询，如果失败再执行更新。</li>
<li>双缓存：我们有两个缓存，缓存A和缓存B。缓存A的失效时间为20分钟，缓存B不设失效时间。自己做缓存预热操作。然后细分以下几个小点：
<ul>
<li>从缓存A读数据，有则直接返回</li>
<li>A没有数据，直接从B读数据，直接返回，并且异步启动一个更新线程。</li>
<li>更新线程同时更新缓存A和缓存B。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="缓存击穿">缓存击穿</h2>
<ul>
<li>key对应的数据存在，但在redis中过期，此时若有大量并发请求过来，这些请求发现缓存过期一般都会从后端DB加载数据并回设到缓存，这个时候大并发的请求可能会瞬间把后端DB压垮。</li>
<li>解决方案：
<ul>
<li>热点数据设置永不过期</li>
<li>加锁：如果缓存失效的话，则对操作进行加锁，然后获取数据。</li>
<li>Redis集群：使用redis集群并设置不同的失效时间比如随机设置缓存的失效时间。</li>
<li>随机指数退避算法：如果发现缓存失效，则随机一个很短的时间，并sleep，再次查询，如果失败再执行更新。</li>
</ul>
</li>
</ul>
<h2 id="如何保证缓存和数据库数据的一致性">如何保证缓存和数据库数据的⼀致性</h2>
<p>https://blog.csdn.net/v123411739/article/details/124237900</p>
<p>https://blog.csdn.net/lans_g/article/details/124652284</p>
<h2 id="redis集群策略">Redis集群策略</h2>
<p><strong>主从复制</strong></p>
<ul>
<li><strong>主数据库可以进行读写操作</strong>，当读写操作导致数据变化时会自动将数据同步给从数据库</li>
<li><strong>slave从数据库一般都是只读</strong>的，并且接收主数据库同步过来的数据</li>
<li>一个master可以拥有多个slave，但是一个slave只能对应一个master</li>
</ul>
<p><strong>哨兵模式</strong></p>
<ul>
<li>监控主从数据库是否正常运行</li>
<li>master出现故障时，自动将slave转化为master</li>
<li>多哨兵配置的时候，哨兵之间也会自动监控</li>
<li>多个哨兵可以监控同一个redis</li>
</ul>
<p><strong>集群模式</strong></p>
<ul>
<li>Redis的集群部署可以将数据划分为多个子集存在不同的节点上，每个节点负责自己整个数据的一部分。</li>
<li>Redis Cluster采用哈希分区规则中的虚拟槽分区。虚拟槽分区巧妙地使用了哈希空间，使用分散度良好的哈希函数把所有的数据映射到一个固定范围内的整数集合，整数定义为槽（slot）。Redis的槽的范围是（0 - 16383，2^14-1）。槽是集群内数据管理和迁移的基本单位。所有的键根据哈希函数映射到哈希槽，每个节点负责维护一部分的槽和其映射的键值数据。</li>
<li>计算规则为：key = CRC16 % 16384</li>
<li>哈希槽让在集群中添加和移除节点非常容易。例如，如果我想添加一个新节点 D ，我需要从节点 A 、B、C 移动一些哈希槽到节点 D。同样地，如果我想从集群中移除节点 A ，我只需要移动 A 的哈希槽到 B 和 C。当节点 A 变成空的以后，我就可以从集群中彻底删除它。因为从一个节点向另一个节点移动哈希槽并不需要停止操作，所以添加和移除节点，或者改变节点持有的哈希槽百分比，都不需要任何停机时间（downtime）。</li>
</ul>
<h2 id="主从同步">主从同步</h2>
<ul>
<li>全量同步：
<ul>
<li>流程：
<ul>
<li>从服务器连接主服务器，发送SYNC命令</li>
<li>主服务器收到SYNC命令，开始执行BGSAVE命令，生成RDB文件，并使用缓冲区记录备份过程中执行的所有命令。</li>
<li>主服务器BGSAVE完成后，向所有从服务器发送快照文件，并在发送期间继续记录被执行的写命令。</li>
<li>从服务器收到快照文件后丢弃所有旧数据，载入收到的快照</li>
<li>主服务器快照发送完毕后向从服务器发送写命令，将BGSAVE期间收到的命令发送给从服务器</li>
</ul>
</li>
</ul>
</li>
<li>增量同步：
<ul>
<li>主服务器执行一个写命令，并且向从服务器发送相同的写命令，从服务器收到后就会执行收到的写命令</li>
</ul>
</li>
</ul>
<h2 id="redis高并发和快速的原因">Redis高并发和快速的原因</h2>
<p>参考https://www.cnblogs.com/angelyan/p/10450885.html</p>
<p>1.redis是基于<strong>内存</strong>的，内存的读写速度非常快；</p>
<p>2.redis是<strong>单线程</strong>的，省去了很多上下文切换线程的时间；</p>
<p>3.redis使用<strong>多路复用技术，可以处理并发的连接</strong>。非阻塞IO 内部实现采用epoll，采用了epoll+自己实现的简单的事件框架。epoll中的读、写、关闭、连接都转化成了事件，然后利用epoll的多路复用特性，绝不在io上浪费一点时间。</p>
<h2 id="什么情况下使用redis-2">什么情况下使用<a href="https://www.nowcoder.com/jump/super-jump/word?word=redis">redis</a></h2>
<ol>
<li>针对热点数据进行缓存</li>
<li>对于特定限时数据的存放</li>
<li>针对带热点权值数据的<a href="https://www.nowcoder.com/jump/super-jump/word?word=%E6%8E%92%E5%BA%8F">排序</a>list</li>
<li>分布式锁</li>
</ol>
<h2 id="什么是缓存与数据库双写一致问题">什么是缓存与数据库双写一致问题？</h2>
<p>如果仅仅查询的话，缓存的数据和数据库的数据是没问题的。但是，当我们要<strong>更新</strong>时候呢？各种情况很可能就<strong>造成数据库和缓存的数据不一致</strong>了。</p>
<ul>
<li>这里不一致指的是：<strong>数据库的数据跟缓存的数据不一致</strong></li>
</ul>
<p><img src="https://mmbiz.qpic.cn/mmbiz_png/2BGWl1qPxib2l33BGMSoKYvGQ9LHw02ZOqNExlaAAtCUfWtuYW3qEPnv3wOs7Raz11wy7jlGhu9HJzplBaia72pw/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy">数据库和缓存的数据不一致</p>
<p>从理论上说，只要我们设置了<strong>键的过期时间</strong>，我们就能保证缓存和数据库的数据<strong>最终是一致</strong>的。因为只要缓存数据过期了，就会被删除。随后读的时候，因为缓存里没有，就可以查数据库的数据，然后将数据库查出来的数据写入到缓存中。</p>
<p>除了设置过期时间，我们还需要做更多的措施来<strong>尽量避免</strong>数据库与缓存处于不一致的情况发生。</p>
<h2 id="redis怎么保证和mysql数据一致">Redis怎么保证和Mysql数据一致</h2>
<p>参考 https://www.cnblogs.com/lingqin/p/10279393.html</p>
<p><strong>1.第一种方案：采用延时双删策略</strong></p>
<p>在写库前后都进行redis.del(key)操作，并且设定合理的超时时间。</p>
<p>伪代码如下</p>
<p>public <a href="https://mb.yidianzixun.com/channel/w/void">void</a> write(String key,<a href="https://mb.yidianzixun.com/channel/w/object">Object</a> data){ redis.delKey(key); db.updateData(data); Thread.sleep(500); redis.delKey(key); }</p>
<p><strong>2.具体的步骤就是：</strong></p>
<p>1）先删除缓存</p>
<p>2）再写数据库</p>
<p>3）休眠500毫秒</p>
<p>4）再次删除缓存</p>
<p><strong>那么，这个500毫秒怎么确定的，具体该休眠多久呢？</strong></p>
<p>需要评估自己的项目的读数据业务逻辑的耗时。这么做的目的，就是确保读请求结束，写请求可以删除读请求造成的缓存脏数据。</p>
<p>当然这种策略还要考虑redis和数据库主从同步的耗时。最后的的写数据的休眠时间：则在读数据业务逻辑的耗时基础上，加几百ms即可。比如：休眠1秒。</p>
<p><strong>3.设置缓存过期时间</strong></p>
<p>从理论上来说，给缓存设置过期时间，是保证最终一致性的解决方案。所有的写操作以数据库为准，只要到达缓存过期时间，则后面的读请求自然会从数据库中读取新值然后回填缓存。</p>
<p><strong>4.该方案的弊端</strong></p>
<p>结合双删策略+缓存超时设置，这样最差的情况就是在超时时间内数据存在不一致，而且又增加了写请求的耗时。</p>
<p><strong>2、第二种方案：异步更新缓存(基于订阅binlog的同步机制)</strong></p>
<p><strong>1.技术整体思路：</strong></p>
<p>[MySQL binlog](https://mb.yidianzixun.com/channel/w/mysql binlog)增量订阅消费+消息队列+增量数据更新到redis</p>
<p><strong>1）读Redis</strong>：热数据基本都在Redis</p>
<p><strong>2）写MySQL</strong>:增删改都是操作MySQL</p>
<p><strong>3）更新Redis数据</strong>：MySQ的数据操作binlog，来更新到Redis</p>
<p><strong>2.Redis更新</strong></p>
<p><strong>1）数据操作主要分为两大块：</strong></p>
<ul>
<li>一个是全量(将全部数据一次写入到redis)</li>
<li>一个是增量（实时更新）</li>
</ul>
<p>这里说的是增量,指的是mysql的update、insert、delate变更数据。</p>
<p><strong>2）读取binlog后分析 ，利用消息队列,推送更新各台的redis缓存数据。</strong></p>
<p>这样一旦MySQL中产生了新的写入、更新、删除等操作，就可以把binlog相关的消息推送至Redis，Redis再根据binlog中的记录，对Redis进行更新。</p>
<p>其实这种机制，很类似MySQL的主从备份机制，因为MySQL的主备也是通过binlog来实现的数据一致性。</p>
<p>这里可以结合使用canal(阿里的一款开源框架)，通过该框架可以对MySQL的binlog进行订阅，而canal正是模仿了<a href="https://mb.yidianzixun.com/channel/w/mysql">mysql</a>的slave<a href="https://mb.yidianzixun.com/channel/w/%E6%95%B0%E6%8D%AE%E5%BA%93">数据库</a>的备份请求，使得Redis的数据更新达到了相同的效果。</p>
<p>当然，这里的消息推送工具你也可以采用别的第三方：<a href="https://mb.yidianzixun.com/channel/w/kafka">kafka</a>、<a href="https://mb.yidianzixun.com/channel/w/rabbitmq">rabbitMQ</a>等来实现推送更新<a href="https://mb.yidianzixun.com/channel/w/redis">Redis</a></p>
<figure data-type="image" tabindex="14"><img src="https://img-blog.csdnimg.cn/img_convert/5185e1f165b06e570dcffe57c993a6d3.png" alt="image-20220508181331250" loading="lazy"></figure>
<h2 id="save命令">save命令</h2>
<p>save命令是<a href="">redis</a>手动触发RDB过程的命令。使用该命令后**，服务器阻塞，直到RDB过程完成后终止。该过程占用内存较多**。</p>
<h2 id="bgsave命令">bgsave命令</h2>
<p><strong>bgsave命令不阻塞主进程</strong>（严格意义上也不是完全不阻塞，详看下面过程），该命令fork一个子进程用于执行RDB过程。其具体过程为：</p>
<ol>
<li>判断此时有没有子进程用于RDB，有的话直接返回。</li>
<li><a href="">redis</a>进行fork子进程过程，此时父进程处于阻塞状态。</li>
<li>子进程创建RDB文件，完成后返回给父进程 ·</li>
</ol>
<h2 id="如何实现分布式锁">如何实现分布式锁</h2>
<p>https://www.cnblogs.com/javazhiyin/p/11737403.html</p>
<h2 id="redis常用命令">Redis常用命令</h2>
<p>https://blog.csdn.net/u010191034/article/details/83383448</p>
<h2 id="redis设置过期时间">Redis设置过期时间</h2>
<p><strong>EXPIRE</strong> 接口定义：EXPIRE key &quot;seconds&quot;<br>
　　　　接口描述：设置一个key在当前时间&quot;seconds&quot;(秒)之后过期。返回1代表设置成功，返回0代表key不存在或者无法设置过期时间</p>
<p><strong>PEXPIRE</strong> 接口定义：PEXPIRE key &quot;milliseconds&quot;<br>
　　　　接口描述：设置一个key在当前时间&quot;milliseconds&quot;(毫秒)之后过期。返回1代表设置成功，返回0代表key不存在或者无法设置过期时间。</p>
<p>参考</p>
<h2 id="redis的使用注意点总结">redis的使用注意点总结</h2>
<p>https://blog.csdn.net/WR0309/article/details/122819361</p>
<h3 id="如何使用redis更节省内存">如何使用redis更节省内存</h3>
<p>redis之所以快是因为它是一款内存数据库，但是一台机器内存都是有限且比较珍贵的资源，使用redis的时候需要合理的规划对应的内存优化策略。</p>
<p>1、控制key的长度，当key的量级很大的时候，合理的控制key的长度可以节省很大的空间。</p>
<p>2、避免存储bigkey，除了控制key的长度，value的大小也要关注，string的大小控制在10kb以下，list、hash、set、zset也要控制。</p>
<p>3、合理的选择数据类型</p>
<p>String、Set 在存储 int 数据时，会采用整数编码存储。Hash、ZSet 在元素数量比较少时（可配置），会采用压缩列表（ziplist）存储，在存储比较多的数据时，才会转换为哈希表和跳表。</p>
<p>String、Set：尽可能存储 int 类型数据<br>
Hash、ZSet：存储的元素数量控制在转换阈值之下，以压缩列表存储，节约内存<br>
4、把redis尽可能的当成缓存使用</p>
<p>5、实例设置maxmemory+淘汰策略</p>
<p>虽然使用redis的时候会设置key的过期时间，但是如果业务写入量比较大的话，那么短期内redis的内存依旧会快速增加。需要提前预估业务数据量，然后给实例设置maxmemory控制实例的内存上限，然后需要设置内存过期策略。</p>
<p>volatile-lru / allkeys-lru：优先保留最近访问过的数据<br>
volatile-lfu / allkeys-lfu：优先保留访问次数最频繁的数据（4.0+版本支持）<br>
volatile-ttl ：优先淘汰即将过期的数据<br>
volatile-random / allkeys-random：随机淘汰数据<br>
6、数据压缩后写入redis</p>
<h3 id="如何持续的发挥redis的高性能">如何持续的发挥redis的高性能</h3>
<p>1、避免存储bigkey</p>
<p>redis是单线程的，当写入一个bigkey的时候，redis会用更多的时间消耗在内存分配上，同样删除的时候也会比较耗时，另外就是客户端在读取bigkey的时候，在网络数据传输上比较耗时。</p>
<p>2、开启lazy-free机制</p>
<p>如果无法避免的使用bigkey的时候，可以开启lazy-free机制，当删除bigkey的时候，释放内存的操作会交给后台线程执行，这样可以最大程度上避免对主线程的影响。</p>
<p>3、不适用复杂度过高的命令</p>
<p>4、执行O（N）级别的命令的时候，要关注以下N的大小</p>
<p>对于容器类型（List/Hash/Set/ZSet），在元素数量未知的情况下，一定不要无脑执行 LRANGE key 0 -1 / HGETALL / SMEMBERS / ZRANGE key 0 -1</p>
<p>在查询数据时，你要遵循以下原则：</p>
<p>先查询数据元素的数量（LLEN/HLEN/SCARD/ZCARD）<br>
元素数量较少，可一次性查询全量数据<br>
元素数量非常多，分批查询数据（LRANGE/HASCAN/SSCAN/ZSCAN）<br>
5、关注del的时间复杂度</p>
<p>当你删除的是一个 String 类型 key 时，时间复杂度确实是 O(1)。</p>
<p>但当你要删除的 key 是 List/Hash/Set/ZSet 类型，它的复杂度其实为 O(N)，N 代表元素个数。</p>
<p>也就是说，删除一个 key，其元素数量越多，执行 DEL 也就越慢！</p>
<p>List类型：执行多次 LPOP/RPOP，直到所有元素都删除完成<br>
Hash/Set/ZSet类型：先执行 HSCAN/SSCAN/SCAN 查询元素，再执行 HDEL/SREM/ZREM 依次删除每个元素<br>
6、批量的命令代替单个命令</p>
<p>String / Hash 使用 MGET/MSET 替代 GET/SET，HMGET/HMSET 替代 HGET/HSET<br>
其它数据类型使用 Pipeline，打包一次性发送多个命令到服务端执行<br>
7、避免集中过期key</p>
<p>如果业务中有大量的key集中过期，这个会阻塞主线程，可以在设置过期时间的时候增加一个随机时间，将过期时间打散。</p>
<p>8、使用长链接操作redis，合理配置连接池</p>
<p>尽量避免短链接，因为每次都是tcp，三次握手和四次挥手，这个过程会增加操作消耗。</p>
<p>9、只使用db0</p>
<p>在一个连接上操作多个 db 数据时，每次都需要先执行 SELECT，这会给 Redis 带来额外的压力<br>
使用多个 db 的目的是，按不同业务线存储数据，那为何不拆分多个实例存储呢？拆分多个实例部署，多个业务线不会互相影响，还能提高 Redis 的访问性能<br>
Redis Cluster 只支持 db0，如果后期你想要迁移到 Redis Cluster，迁移成本高<br>
10、使用读写分离+分片集群</p>
<p>如果读业务很大，可以采用部署多个从库的方式，实现读写分离，让从库分担读压力，提升性能。</p>
<p>如果写业务的请求很大，单个redis的实例无法支持大的流量，可以使用分片集群，分担写压力。</p>
<p>11、不开启AOF或AOF配置成每秒刷盘</p>
<p>对于丢失数据不敏感的业务，不建议开启AOF，如果确实需要开启，可以配置成 appendfsync everysec，将持久化放在后台线程中。</p>
<p>12、使用物理机部署redis</p>
<p>redis使用rdb持久化的时候，采用子进程的方式，虚拟机支持fork比较耗时。</p>
<p>13、关闭操作系统内存大页机制</p>
<h3 id="如何保证redis的高可用">如何保证redis的高可用</h3>
<p>redis可靠性也是不难，难点是持续的稳定。</p>
<p>1、按照业务线进行部署实例</p>
<p>不同的业务采用不同的redis的实例，有问题的时候互不干扰。</p>
<p>2、部署主从集群</p>
<p>主库和从库也最好放在不同的机器上。</p>
<p>3、合理的设置主从复制参数</p>
<p>设置合理的 repl-backlog 参数：过小的 repl-backlog 在写流量比较大的场景下，主从复制中断会引发全量复制数据的风险<br>
设置合理的 slave client-output-buffer-limit：当从库复制发生问题时，过小的 buffer 会导致从库缓冲区溢出，从而导致复制中断<br>
4、部署哨兵集群，实现故障自动转移</p>
<p>只部署了主从节点，但故障发生时是无法自动切换的，所以，你还需要部署哨兵集群，实现故障的「自动切换」。</p>
<p>而且，多个哨兵节点需要分布在不同机器上，实例为奇数个，防止哨兵选举失败，影响切换时间。</p>
<p>日常运维redis需要注意什么<br>
1、禁止使用 KEYS/FLUSHALL/FLUSHDB 命令，会阻塞主线程，影响线上业务</p>
<p>SCAN 替换 KEYS<br>
4.0+版本可使用 FLUSHALL/FLUSHDB ASYNC，清空数据的操作放在后台线程执行<br>
2、扫描线上实例时，设置休眠时间</p>
<p>不管你是使用 SCAN 扫描线上实例，还是对实例做 bigkey 统计分析，我建议你在扫描时一定记得设置休眠时间。</p>
<p>防止在扫描过程中，实例 OPS 过高对 Redis 产生性能抖动。</p>
<p>3、慎用monitor命令</p>
<p>4、从库必现设置成slave-read-only，避免从库写入导致数据不一致。</p>
<p>5、合理配置 timeout 和 tcp-keepalive 参数，</p>
<p>如果因为网络原因，导致你的大量客户端连接与 Redis 意外中断，恰好你的 Redis 配置的 maxclients 参数比较小，此时有可能导致客户端无法与服务端建立新的连接（服务端认为超过了 maxclients）。</p>
<p>造成这个问题原因在于，客户端与服务端每建立一个连接，Redis 都会给这个客户端分配了一个 client fd。</p>
<p>当客户端与服务端发生网络问题，服务端不会立即释放client fd。</p>
<p>不要配置过高的 timeout：让服务端尽快把无效的 client fd 清理掉<br>
Redis 开启 tcp-keepalive：这样服务端会定时给客户端发送 TCP 心跳包，检测连接连通性，当网络异常时，可以尽快清理僵尸 client fd<br>
6、调整maxmemory时，注意主从库的调整顺序</p>
<p>Redis 5.0 以下版本存在这样一个问题：从库内存如果超过了 maxmemory，也会触发数据淘汰。</p>
<p>在某些场景下，从库是可能优先主库达到 maxmemory 的（例如在从库执行 MONITOR 命令，输出缓冲区占用大量内存），那么此时从库开始淘汰数据，主从库就会产生不一致。</p>
<p>要想避免此问题，在调整 maxmemory 时，一定要注意主从库的修改顺序：</p>
<p>调大 maxmemory：先修改从库，再修改主库<br>
调小 maxmemory：先修改主库，再修改从库<br>
直到 Redis 5.0，Redis 才增加了一个配置 replica-ignore-maxmemory，默认从库超过 maxmemory 不会淘汰数据，才解决了此问题。</p>
<h3 id="redis安全问题">redis安全问题</h3>
<p>不要把 Redis 部署在公网可访问的服务器上<br>
部署时不使用默认端口 6379<br>
以普通用户启动 Redis 进程，禁止 root 用户启动<br>
限制 Redis 配置文件的目录访问权限<br>
推荐开启密码认证<br>
禁用/重命名危险命令（KEYS/FLUSHALL/FLUSHDB/CONFIG/EVAL）</p>
]]></content>
    </entry>
</feed>