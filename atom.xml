<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://lindamao.cn</id>
    <title>lindamao</title>
    <updated>2023-02-14T08:48:52.212Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://lindamao.cn"/>
    <link rel="self" href="https://lindamao.cn/atom.xml"/>
    <logo>https://lindamao.cn/images/avatar.png</logo>
    <icon>https://lindamao.cn/favicon.ico</icon>
    <rights>All rights reserved 2023, lindamao</rights>
    <entry>
        <title type="html"><![CDATA[Winsdows11跳过联网]]></title>
        <id>https://lindamao.cn/post/winsdows11-tiao-guo-lian-wang/</id>
        <link href="https://lindamao.cn/post/winsdows11-tiao-guo-lian-wang/">
        </link>
        <updated>2023-02-10T06:39:39.000Z</updated>
        <content type="html"><![CDATA[<p>现在新买回来的电脑原厂几乎都是win11系统 如果联网就等于激活了 如果激活后在验机的时候出现问题将不好进行退换 这里提供winsdow11跳过联网的方法<br>
第1步：选国家（地区）<br>
第2步：选输入法，点是<br>
第3步：选第二种输入法，可以“跳过”<br>
第4步：联网界面：按下键盘的Shift+F10或Fn+Shift+F10<br>
（能插网线的电脑先不插网线，过程可能会自动重启电脑）<br>
会弹出管理员框，用键盘输入：taskmgr  再按回车键（Enter）<br>
此时会出现任务管理器 点击详细信息<br>
找到网络连接流，鼠标右键点击——结束任务，即可跳过联网<br>
到这一步 已经跳过联网了 后面的步骤根据自己的电脑的需求进行修改 验完机可以再联网</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[数据库连接超时问题解决]]></title>
        <id>https://lindamao.cn/post/shu-ju-ku-lian-jie-chao-shi-wen-ti-jie-jue/</id>
        <link href="https://lindamao.cn/post/shu-ju-ku-lian-jie-chao-shi-wen-ti-jie-jue/">
        </link>
        <updated>2022-08-16T07:13:08.000Z</updated>
        <content type="html"><![CDATA[<p>今天上班在产线上遇到了这么一个bug<br>
com.mysql.jdbc.exceptions.jdbc4.CommunicationsException: Communications link failure<br>
数据库连接超时是指当服务连接到数据库但不对其做任何操作时等待到一定时间之后，这个链接就会与数据库断开，当再次对数据库进行操作时会报数据库连接超时或者连接关闭异常。mysql的连接默认最长等待时间为28800s也就是8个小时。<br>
根据实施反应在出现这个异常之后的时间里服务是正常的但是对DB的查询无法正常执行<br>
问题排查<br>
1.先检查DB的连接配置 公司用的是mybaits 这里根据自身实际情况再进行排查<br>
查看mysql连接最大超时时间<br>
<code>show global variables like '%timeout%';</code><br>
发现产线上的wait_timeout为1800s 也就是30min 这里开始怀疑是不是事务的执行超过了30min 但是还没有有力证据证明<br>
2.紧接着根据日志排查发现出事情的那天相关任务的执行耗时超过了30min 在线上拿到以往没出事情的日志来看任务的执行时间都是少于30min 也就证实了上述猜想是对的 正常是把wait_timeou参数调大一点就行了<br>
跟组长讨论了以往的情况 了解到以前也出现过类似情况 而解决方法也正如我上述所述<br>
修改完参数大小之后重启服务 之后根据实施反馈上述问题再也没出现过<br>
一般情况下 等待超时timeout为 28800s 也就是8小时 事务的执行完成 一般都是在这个时间段内<br>
注意点：<br>
1.一般情况下谨慎修改产线程参数<br>
2.wait_timeout 和interactive_time需要同时修改才能生效</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Git]]></title>
        <id>https://lindamao.cn/post/git/</id>
        <link href="https://lindamao.cn/post/git/">
        </link>
        <updated>2022-07-12T07:32:32.000Z</updated>
        <content type="html"><![CDATA[<h1 id="技巧1优化配置">技巧1:优化配置</h1>
<p>Git 在全局、用户和本地级别上都是高度可配置的。</p>
<p><a href="https://git-scm.com/docs/git-config">git配置文档</a></p>
<h2 id="查找顺序">查找顺序</h2>
<p>每个设置都可以被覆盖：</p>
<pre><code>本地级别:
项目文件夹/.git/config
用户级别:
用户目录/.config/git
用户目录/.gitconfig
全局级别：
git目录/etc/gitconfig
</code></pre>
<h2 id="修改配置">修改配置</h2>
<pre><code class="language-bash"># 全局设置
git config --global &lt;keypath&gt; &lt;value&gt;
# 本地设置
git config &lt;keypath&gt; &lt;value&gt;
</code></pre>
<h2 id="显示当前设置">显示当前设置</h2>
<pre><code class="language-bash"># 显示当前设置及其来源
git config --list --show-origin
</code></pre>
<h2 id="一些有用的配置">一些有用的配置</h2>
<pre><code class="language-bash"># 设定身份
git config --global user.name&quot;&lt;your name&gt;&quot;
git config --global user.email &lt;your email&gt;
</code></pre>
<h1 id="技巧2别名alias">技巧2:别名(alias)</h1>
<p><a href="%5Bhttps://git-scm.com/book/zh/v2/Git-%E5%9F%BA%E7%A1%80-Git-%E5%88%AB%E5%90%8D%5D(https://git-scm.com/book/zh/v2/Git-%E5%9F%BA%E7%A1%80-Git-%E5%88%AB%E5%90%8D)">Git 别名</a></p>
<p>创建别名来保存常用的git命令：</p>
<pre><code class="language-bash"># 创建别名
git config --global alias.&lt;alias-name&gt; &quot;&lt;git command&gt;&quot;
# 使用别名
git &lt;alias-name&gt; &lt;more optional arguments&gt;
</code></pre>
<h2 id="一些有用的别名">一些有用的别名</h2>
<pre><code class="language-bash"># 撤销上次提交
git config --global alias.undo &quot;reset --soft HEAD^&quot;
# 将暂存区更新修订到上次提交 (不改变提交信息)
git config --global alias.amend &quot;commit --amend --no-edit&quot;
# 压缩的状态输出
git config --global alias.st &quot;status -sb&quot;
# 用 GRAPH 为日志着色
git config --global alias.lg &quot;log --graph --pretty=format:'%Cred%h%Creset -%C(yellow)%d%Creset %s %Cgreen(%cr) %C(bold blue)&lt;%an&gt;%Creset'&quot;
# 删除所有已合并的分支
git config --global alias.rmb &quot;!git branch --merged | grep -v '*' | xargs -n 1 git branch -d&quot;
# 贡献排行
git config --global alias.rank &quot;shortlog -n -s --no-merges&quot;
</code></pre>
<h1 id="技巧-3查找-commits-和更改">技巧 3：查找 Commits 和更改</h1>
<h2 id="通过commits信息查找">通过commits信息查找</h2>
<pre><code class="language-bash"># 通过 commit 信息查找 (所有分支)
git log --all --grep='&lt;search term&gt;'
# 通过 commit 信息查找 (包含 reflog)
git log-g --grep='&lt;search term&gt;'
</code></pre>
<h2 id="通过更改查找">通过更改查找</h2>
<pre><code class="language-bash"># 通过更新的内容查找
git log -S '&lt;search term&gt;'
</code></pre>
<h2 id="通过日期查找">通过日期查找</h2>
<pre><code class="language-bash"># 通过日期范围查找
git log --after='DEC 152019' --until='JAN 102020'
</code></pre>
<h1 id="技巧4添加hunk">技巧4:添加hunk</h1>
<p>git add <filepath> 不仅能添加文件的所有变更， --path / -p 参数还可以交互式暂存区块。</p>
<pre><code class="language-bash"># 补丁命令
y = 暂存区块
n = 不暂存这个区块
q = 退出
a = 暂存当前文件的此区块以及所有剩余区块
d = 不暂存当前文件的此区块以及所有剩余区块
/ = 查找区块 (正则表达式)
s = 划分成更小的区块
e = 手动编辑区块
? = 打印帮助说明
g = 选择要前往的区块
j = 将区块设为未定，查看下一个未定区块
J = 将区块设为未定，查看下一个区块
k = 将区块设为未定，查看上一个未定区块
J = 将区块设为未定，查看下一个区块
</code></pre>
<h1 id="技巧-5-储藏stash更改而不提交">技巧 5： 储藏（stash）更改而不提交</h1>
<p>stash 将当前的更改临时搁置起来。在它的帮助下，可以返回当前状态的索引，并能在稍后应用已储藏的更改。</p>
<p>默认情况下，仅储藏当前跟踪文件中的更改，新文件将被忽略。</p>
<p>我们可以独立地创建和应用多个 stash。</p>
<p><a href="%5Bhttps://git-scm.com/book/zh/v2/Git-%E5%B7%A5%E5%85%B7-%E5%82%A8%E8%97%8F%E4%B8%8E%E6%B8%85%E7%90%86%5D(https://git-scm.com/book/zh/v2/Git-%E5%B7%A5%E5%85%B7-%E5%82%A8%E8%97%8F%E4%B8%8E%E6%B8%85%E7%90%86)">Git 工具 - 储藏与清理</a></p>
<h2 id="创建">创建</h2>
<pre><code class="language-bash"># 创建新的 STASH
git stash
# 创建新的 STASH (包含未追踪的更改)
git stash -u/--include-untracked
# 创建新的 STASH 并命名
git stash save&quot;&lt;stash name&gt;&quot;
# 交互式储藏
git stash -p
</code></pre>
<h2 id="罗列">罗列</h2>
<pre><code class="language-bash"># 列出所有的 STASH (为其他命令提供 &quot;n&quot;)
git stash list
</code></pre>
<h2 id="浏览">浏览</h2>
<pre><code class="language-bash"># 浏览 STASH 内容
git stash show
# 浏览 STASH 差异
git stash show -p
</code></pre>
<h2 id="应用">应用</h2>
<pre><code class="language-bash"># 应用上一个 STASH (删除 stash)
git stash pop
# 应用上一个 STASH (保留 stash)
git stash apply
# 应用特定的 STASH (n = stash 列表序号)
git stash pop/apply stash@{n}
# 从 STASH 创建新的分支 (n = stash 列表序号)
git stash branch &lt;newbranch name&gt; stash@{n}
# 从 STASH 应用单个文件 (n = stash 列表序号)
git checkout stash@{n} -- &lt;filepath&gt;
</code></pre>
<h2 id="清理">清理</h2>
<pre><code class="language-bash"># 删除特定的 STASH (n = stash 列表序号)
git stash drop stash@{n}
# 删除所有的 STASH
git stash clear
</code></pre>
<h1 id="技巧-6空运行dry-run">技巧 6：空运行（Dry Run）</h1>
<p>许多 git 操作可能具有破坏性，例如， git clean -f 将删除所有未跟踪的文件，而且无法恢复。</p>
<p>要避免出现这种灾难性的结果，许多命令都支持 <em>dry-run</em> ，可以在实际产生结果前对其进行检查。不过遗憾的是，使用的选项不完全一致：</p>
<pre><code class="language-bash">git clean -n/--dry-run
git add -n/--dry-run
git rm -n/--dry-run
# GIT MERGE 模拟 DRY-RUN
git merge --no-commit --no-ff &lt;branch&gt;
git diff --cached
git merge --abort
</code></pre>
<h1 id="技巧-7安全强制推送">技巧 7：安全强制推送</h1>
<p>在处理旧的 commit、创建新的 head 等情况时时很容易弄乱分支。 git push --force 可以覆盖远程变更，但不应该这样做！</p>
<p>git push --force 是一种具有破坏性且危险的操作，因为它无条件生效，并且会破坏其他提交者已经推送的所有 commit。这对于其他人的代码仓库来说不一定是致命的，但是改变历史记录并影响其他人并不是一个好主意。</p>
<p>更好的选择是使用 git push --force-with-lease 。</p>
<p>git 不会无条件地覆盖上游的远程仓库，而是检查是否有本地不可用的远程更改。如果有，它会失败并显示一条“stale info”消息，并告诉我们需要先运行 git fetch 。</p>
<p><a href="https://git-scm.com/docs/git-push#Documentation/git-push.txt---force-with-leaseltrefnamegt">git push</a></p>
<h1 id="技巧-8修改-commit-信息">技巧 8：修改 commit 信息</h1>
<p>Commit 是不可变的，且不能更改。不过可以用一条新的 commit 信息修订现有的 commit，这会覆盖原始 commit，因此请勿在已推送的 commit 中使用它。</p>
<pre><code class="language-bash">git commit --amend -m &quot;&lt;new commit message&gt;&quot;
</code></pre>
<h1 id="技巧-9修改历史">技巧 9：修改历史</h1>
<p>修改代码仓库的历史不仅限于修改上次提交信息，使用 git rebase 可以修改多个提交：</p>
<pre><code class="language-bash"># 提交的范围
git rebase -i/--interactive HEAD~&lt;number of commits&gt;
# 该 hash 之后的所有提交
git rebase -i/--interactive &lt;commit hash&gt;
</code></pre>
<p>在配置的编辑器中倒序列出所有的 commit，像这样：</p>
<pre><code class="language-bash">#&lt;command&gt;&lt;commit hash&gt;&lt;commit message&gt;
pick5df8fbc revamped logic
pick ca5154e README typos fixed
pick a104aff added awesome new feature
</code></pre>
<p>通过更改编辑器中的实际内容，可以为 git 提供一个方案，来说明如何进行 rebase：</p>
<pre><code class="language-bash"># p, pick = 使用提交而不更改
# r, reword = 修改提交信息
# e, edit = 编辑提交
# s, squash = 汇合提交
# f, fixup = 类似 &quot;squash&quot;，但是会丢弃提交信息
# x, exec = 运行命令 (其余行)
# d, drop = 移除提交
</code></pre>
<p>保存编辑器后，git 将运行该方案以重写历史记录。</p>
<p>e, edit 会暂停 rebase，就可以编辑代码仓库的当前状态。完成编辑后，运行 git rebase --continue 。</p>
<p>如果过程中出现问题（例如合并冲突），我们需要重新开始，可以使用 git rebase --abort 。</p>
<p><a href="https://git-scm.com/docs/git-rebase">git-rebase</a></p>
<h1 id="技巧-10存档跟踪文件">技巧 10：存档跟踪文件</h1>
<p>可以使用不同格式（ zip 或 tar ）来压缩特定引用的跟踪文件：</p>
<pre><code class="language-bash">git archive --format&lt;format&gt; --output&lt;filename&gt; &lt;ref&gt;
</code></pre>
<p><ref> 可以是一个分支、commit hash 或者一个标签。</p>
<p><a href="https://git-scm.com/docs/git-archive">git-archive</a></p>
<h1 id="额外提醒单破折号">额外提醒：单破折号</h1>
<p>有一个快捷方式可以表示刚用过的分支：一个单破折号 -</p>
<pre><code class="language-bash">git checkout my-branch
# 当前分支：my-branch
&lt;dosome git operations, e.g. adding/commiting&gt;
git checkout develop
# 当前分支：develop
git merge -
# 将 my-branch 合并到 develop
</code></pre>
<p>单破折号等同于 @{-1} 。</p>
<p><a href="https://git-scm.com/docs/git-checkout#Documentation/git-checkout.txt-ltbranchgt">git-checkout</a></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Jrebel配置远程热部署]]></title>
        <id>https://lindamao.cn/post/jrebel-pei-zhi-yuan-cheng-re-bu-shu/</id>
        <link href="https://lindamao.cn/post/jrebel-pei-zhi-yuan-cheng-re-bu-shu/">
        </link>
        <updated>2022-04-08T06:36:11.000Z</updated>
        <content type="html"><![CDATA[<h1 id="jrebel配置远程热部署">Jrebel配置远程热部署</h1>
<ul>
<li><a href="https://www.jrebel.com/products/jrebel/learn">官方教程文档</a></li>
</ul>
<h1 id="安装">安装</h1>
<ul>
<li>
<p>下载Jrebel和Xrebel相应的版本。（<a href="https://www.jrebel.com/products/jrebel/download/prev-releases">Jrebel官网下载</a>、<a href="https://www.jrebel.com/products/xrebel/download">Xrebel官网下载</a>）</p>
</li>
<li>
<p>激活地址：</p>
<ul>
<li><code>http://jrebel.cicoding.cn/{GUID}</code></li>
<li><code>https://www.guidgen.com/{GUID}</code></li>
</ul>
</li>
<li>
<p>上传到服务器上，并解压。</p>
</li>
<li>
<p>激活插件：下面两个命令随便一条都行</p>
<pre><code class="language-shell">./bin/activate.sh http://jrebel.cicoding.cn/{GUID} {用户邮箱}
java -jar jrebel.jar -activate http://jrebel.cicoding.cn/{GUID} {用户邮箱}
</code></pre>
</li>
<li>
<p>设置远程密码：</p>
<pre><code class="language-shell">java -jar jrebel.jar -set-remote-password {要设置的密码}
</code></pre>
</li>
</ul>
<h1 id="idea设置">Idea设置</h1>
<ul>
<li>
<p>Idea安装相关插件，详见：<a href="https://mxecy.cn/post/idea-jrebel/">Jrebel配置</a></p>
</li>
<li>
<p>设置远程服务器：<a href="https://manuals.jrebel.com/jrebel/remoteserver/intellij.html">官网配置教程</a></p>
<pre><code class="language-shell">File -&gt; JRebel &amp; Xrebel -&gt; Jrebel Startup -&gt; 勾选[Run on a remote server or VM]
File -&gt; JRebel &amp; Xrebel -&gt; Jrebel Remote Servers -&gt; 点+添加新服务器
</code></pre>
</li>
</ul>
<h1 id="使用">使用</h1>
<ul>
<li>
<p>使用的时候，只需要添加几个启动参数：</p>
<pre><code class="language-shell">-javaagent:{xrebel路径}\xrebel.jar # 启动Xrebel
-agentpath:{jrebel路径}\lib\libjrebel64.so # 启动jrebel
-Drebel.remoting_plugin=true # 启动远程插件
-Drebel.remoting_port={端口号} # 可选，针对没有http的程序才使用，会添加一个jetty容器提供服务。
</code></pre>
</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[RabbitMq]]></title>
        <id>https://lindamao.cn/post/rabbitmq/</id>
        <link href="https://lindamao.cn/post/rabbitmq/">
        </link>
        <updated>2021-05-22T06:06:58.000Z</updated>
        <content type="html"><![CDATA[<h2 id="1-什么是中间件">1. 什么是中间件</h2>
<blockquote>
<p>什么是中间件</p>
</blockquote>
<p>我国企业从20世纪80年代开始就逐渐进行信息化建设，由于方法和体系的不成熟，以及企业业务的市场需求的不断变化，一个企业可能同时运行着多个不同的业务系统，这些系统可能基于不同的操作系统、不同的数据库、异构的网络环境。现在的问题是，如何把这些信息系统结合成一个有机地协同工作的整体，真正实现企业跨平台、分布式应用。中间件便是解决之道，它用自己的复杂换取了企业应用的简单。</p>
<p>中间件（Middleware）是处于操作系统和应用程序之间的软件，也有人认为它应该属于操作系统中的一部分。人们在使用中间件时，往往是一组中间件集成在一起，构成一个平台（包括开发平台和运行平台），但在这组中间件中必须要有一个通信中间件，即中间件+平台+通信，这个定义也限定了只有用于分布式系统中才能称为中间件，同时还可以把它与支撑软件和使用软件区分开来</p>
<blockquote>
<p>为什么需要使用消息中间件</p>
</blockquote>
<p>具体地说，中间件屏蔽了底层操作系统的复杂性，使程序开发人员面对一个简单而统一的开发环境，减少程序设计的复杂性，将注意力集中在自己的业务上，不必再为程序在不同系统软件上的移植而重复工作，从而大大减少了技术上的负担，中间件带给应用系统的，不只是开发的简便、开发周期的缩短，也减少了系统的维护、运行和管理的工作量，还减少了计算机总体费用的投入。</p>
<blockquote>
<p>中间件特点</p>
</blockquote>
<p>为解决分布异构问题，人们提出了中间件（middleware)的概念。中间件时位于平台（硬件和操作系统）和应用之间的通用服务，如下图所示，这些服务具有标准的程序接口和协议。针对不同的操作系统和硬件平台，它们可以有符合接口的协议规范的多种实现。</p>
<p>也很难给中间件一个严格的定义，但中间件应具有如下的一些特点：</p>
<p>（1）满足大量应用的需要</p>
<p>（2）运行于多种硬件和 OS平台</p>
<p>（3）支持分布计算，提供跨网络、硬件和 OS平台的透明性的应用或服务的交互</p>
<p>（4）支持标准的协议</p>
<p>（5）支持标准的接口</p>
<p>由于标准接口对于可移植性和标准协议对于互操作性的重要性，中间件已成为许多标准化工作的主要部分。对于应用软件开发，中间件远比操作系统和网络服务更为重要，中间件提供的程序接口定义了一个相对稳定的高层应用环境，不管底层的计算机硬件和系统软件怎样更新换代，只要将中间件升级更新，并保持中间件对外的接口定义不变，应用软件几乎不需任何修改，从而保护了企业在应用软件开发和维护中的重大投资。</p>
<p>简单说：中间件有个很大的特点，是脱离于具体设计目标，而具备提供普遍独立功能需求的模块。这使得中间件一定是可替换的。如果一个系统设计中，中间件时不可替代的，不是架构、框架设计有问题，那么就是这个中间件，在别处可能是个中间件，在这个系统内是引擎。</p>
<blockquote>
<p>在项目中什么时候使用中间件技术</p>
</blockquote>
<p>在项目的架构和重构中，使用任何技术和架构的改变我们都需要谨慎斟酌和思考，因为任何技术的融入和变化都可能人员，技术，和成本的增加，中间件的技术一般现在一些互联网公司或者项目中使用比较多，如果你仅仅还只是一个初创公司建议还是使用单体架构，最多加个缓存中间件即可，不要盲目追求新或者所谓的高性能，而追求的背后一定是业务的驱动和项目的驱动，因为一旦追求就意味着你的学习成本，公司的人员结构以及服务器成本，维护和运维的成本都会增加，所以需要谨慎选择和考虑。</p>
<p>但是作为一个开放人员，一定要有学习中间件技术的能力和思维，否则很容易当项目发展到一个阶段在去掌握估计或者在面试中提及，就会给自己带来不小的困扰，在当今这个时代这些技术也并不是什么新鲜的东西，如果去掌握和挖掘最关键的还是自己花时间和经历去探讨和研究。</p>
<h2 id="2-中间件技术及架构的概述">2. 中间件技术及架构的概述</h2>
<blockquote>
<p>学习中间件的方式和技巧</p>
</blockquote>
<ol>
<li>理解中间件在项目架构中的作用，以及各中间件的底层实现</li>
<li>可以使用一些类比的生活概念去理解中间件</li>
<li>使用一些流程图或者脑图的方式去梳理各个中间件在架构中的作用</li>
<li>尝试用 java技术去实现中间件的原理</li>
<li>静下来去思考中间件在项目中设计的和使用的原因</li>
<li>如果找到对应的代替总结方案</li>
<li>尝试编写博文总结类同中间件技术的对比和使用场景</li>
<li>学会查看中间件的源码以及开源项目和博文</li>
</ol>
<blockquote>
<p>什么是消息中间件</p>
</blockquote>
<p>在实际的项目中，大部分的企业项目开发中，在早起都采用的是单体的架构模式</p>
<blockquote>
<p>单体架构</p>
</blockquote>
<p>在企业开发当中，大部分的初期架构都采用的是单体架构的模式进行架构，而这种架构的典型的特点：就是把所有的业务和模块，源代码，静态资源文件等都放在一个工程中，如果其中的一个模块升级或者迭代发生一个很小的变动都会重新编译和重新部署项目。这种这狗存在的问题是：</p>
<ol>
<li>耦合度太高</li>
<li>不易维护</li>
<li>服务器的成本高</li>
<li>以及升级架构的复杂度也会增大</li>
</ol>
<p>这样就有后续的分布式架构系统。如下</p>
<blockquote>
<p>分布式架构</p>
</blockquote>
<p><strong>何谓分布式系统：</strong></p>
<blockquote>
<p>通俗一点：就是一个请求由服务器端的多个服务（服务或者系统）协同处理完成</p>
</blockquote>
<p>和单体架构不同的是，单体架构是一个请求发起 jvm调度线程（确切的是 tomcat线程池）分配线程 Thread来处理请求直到释放，而分布式系统是：一个请求时由多个系统共同来协同完成，jvm和环境都可能是独立。如果生活中的比喻的话，单体架构就像建设一个小房子很快就能够搞定，如果你要建设一个鸟巢或者大型的建筑，你就必须是各个环节的协同和分布，这样目的也是项目发展到后期的时候要去部署和思考的问题。我们也不难看出来：分布式架构系统存在的特点和问题如下：</p>
<p><strong>存在问题：</strong></p>
<ol>
<li>学习成本高，技术栈过多</li>
<li>运维成本和服务器成本增高</li>
<li>人员的成本也会增高</li>
<li>项目的负载度也会上升</li>
<li>面临的错误和容错性也会成倍增加</li>
<li>占用的服务器端口和通讯的选择的成本高</li>
<li>安全性的考虑和因素逼迫可能选择 RMI/MQ相关的服务器端通讯</li>
</ol>
<p><strong>好处：</strong></p>
<ol>
<li>服务系统的独立，占用的服务器资源减少和占用的硬件成本减少，确切的说是：可以合理的分配服务资</li>
<li>源，不造成服务器资源的浪费</li>
<li>系统的独立维护和部署，耦合度降低，可插拔性</li>
<li>系统的架构和技术栈的选择可以变的灵活（而不是单纯地选择 java）</li>
<li>弹性的部署，不会造成平台因部署造成的瘫痪和停服的状态</li>
</ol>
<h2 id="3-基于消息中间件的分布式系统的架构">3. 基于消息中间件的分布式系统的架构</h2>
<ol>
<li>利用可靠的消息传递机制进行系统和系统直接的通讯</li>
<li>通过提供消息传递和消息的派对机制，它可以在分布式系统环境下扩展进程间的通讯</li>
</ol>
<blockquote>
<p>消息中间件应用的场景</p>
</blockquote>
<ol>
<li>跨系统数据传递</li>
<li>高并发的流量削峰</li>
<li>数据的并发和异步处理</li>
<li>大数据分析与传递</li>
<li>分布式事务比如你有一个数据要进行迁移或者请求并发过多的时候，</li>
</ol>
<p>比如你有10 W的并发请求下订单，我们可以在这些订单入库之前，我们可以把订单请求堆积到消息队列中，让它稳健可靠的入库和执行</p>
<blockquote>
<p>常见的消息中间件</p>
</blockquote>
<p>ActiveMQ、RabbitMQ、Kafka、RocketMQ等</p>
<blockquote>
<p>消息中间件的本质及设计</p>
</blockquote>
<p>它是一种接受数据、接受请求、存储数据、发送数据等功能的技术服务</p>
<p>MQ消息队列：负责数据的传接受，存储和传递，所以性能要高于普通服务和技术</p>
<p>谁来生产消息，存储消息和消费消息呢？</p>
<blockquote>
<p>消息中间件的核心组成部分</p>
</blockquote>
<p>消息的协议<br>
消息的持久化机制<br>
消息的分发策略<br>
消息的高可用，高可靠<br>
消息的容错机制</p>
<blockquote>
<p>小结</p>
</blockquote>
<p>其实不论选择单体架构还是分布式架构都是项目开发的一个阶段，在什么阶段选择合适的架构方式，而不能盲目追求，最后造成的后果和问题都需要自己买单。但作为一个开发人员学习和探讨新的技术使我们每个程序开发者都应该去保持和思考的问题。当我们没办法去改变社会和世界的时候，我们为了生活和生存那就必须要迎合企业和市场的需求，发挥你的价值和所学的才能，创造价值和实现自我</p>
<h2 id="4-消息队列协议">4. 消息队列协议</h2>
<blockquote>
<p>什么是协议</p>
</blockquote>
<p>所谓协议是指：</p>
<ol>
<li>计算机底层操作系统和应用程序通讯时共同遵守的一组约定，只有遵循共同的约定和规范，系统和底层操作系统之间才能相互交流</li>
<li>和一般的网络应用程序的不同它主要负责数据的接受和传递，所以性能比较的高</li>
<li>协议对数据格式和计算机之间交换数据都必须严格遵守规范</li>
</ol>
<blockquote>
<p>网络协议的三要素</p>
</blockquote>
<ol>
<li>语法：语法是用户数据与控制信息的结构与格式，以及数据出现的顺序</li>
<li>语义：语义是解释控制信息每个部分的意义，它规定了需要发出何种控制信息，以及完成的动作与做出什么样的响应</li>
<li>时序：时序是对事件发生顺序的详细说明</li>
</ol>
<p>比如我 MQ发送一个信息，是以什么数据格式发送到队列中，然后每个部分的含义是什么，发送完毕以后的执行的动作，以及消费者消费消息的动作，消费完毕的相应结构和反馈是什么，然后按照对应的执行顺序进行处理。如果你还是不理解：大家每天都在接触的 http请求协议：</p>
<ol>
<li>语法：http规定了请求报文和响应报文的格式</li>
<li>语义：客户端主动发起请求称之为请求（这是一种定义，同时你发起的是 post/get请求）</li>
<li>时序：一个请求对应一个响应（一定先有请求在有响应，这个是时序）</li>
</ol>
<p>而消息中间件采用的并不是 http协议，而常见的消息中间件协议有有：OpenWire、AMQP、MQTT、Kafka，OpenMessage协议</p>
<p><strong>面试题：为什么消息中间件不直接使用 http协议</strong></p>
<ol>
<li>因为 http请求报文头和响应报文头是比较复杂的，包含了Cookie，数据的加密解密，窗台吗，响应码等附加的功能，但是对于一个消息而言，我们并不需要这么复杂，也没有这个必要性，它其实就是负责数据传递，存储，分发就行，一定要追求的是高性能。尽量简洁，快速</li>
<li>大部分情况下 http大部分都是短链接，在实际的交互过程中，一个请求到响应都很有可能会中断，中断以后就不会执行持久化，就会造成请求的丢失。这样就不利于消息中间件的业务场景，因为消息中间件可能是一个长期的获取信息的过程，出现问题和故障要对数据或消息执行持久化等，目的是为了保证消息和数据的高可靠和稳健的运行</li>
</ol>
<blockquote>
<p>AMQP协议</p>
</blockquote>
<p>AMQP：（全称：Advanced Message Queuing Protocol）是高级消息队列协议。由摩根大通集团联合其他公司共同设计。是一个提供统一消息服务的应用层标准高级消息队列协议，是应用层协议的一个开放标准，为面向消息的中间件设计。基于此协议的客户端与消息中间件可传递消息，并不受客户端/中间件不同产品，不同的开发语言等条件的限制。Erlang中的实现由 RabbitMQ等</p>
<p>特性：</p>
<ol>
<li>分布式事务支持</li>
<li>消息的持久化支持</li>
<li>高性能和高可靠的消息处理优势</li>
</ol>
<blockquote>
<p>MQTT协议</p>
</blockquote>
<p>MQTT协议（Message Queueing Telemetry Transport）消息队列是 IBM开放的及时通讯协议，物联网系统架构中的重要组成部分</p>
<p>特点：</p>
<ol>
<li>轻量</li>
<li>结构简单</li>
<li>传输快，不支持事务</li>
<li>没有持久化设计</li>
</ol>
<p>应用场景：</p>
<ol>
<li>适用于计算能力有限</li>
<li>低带宽</li>
<li>网络不稳定的场景</li>
</ol>
<p>支持者：</p>
<blockquote>
<p>OpenMessage协议</p>
</blockquote>
<p>是近几年由阿里、雅虎和滴滴出行、Stremalio等公司共同参与创立的分布式信息中间件、流处理等领域的应用开发标准</p>
<p>特点：</p>
<ol>
<li>结构简单</li>
<li>解析速度快</li>
<li>支持事务和持久化设计</li>
</ol>
<blockquote>
<p>Kafka协议</p>
</blockquote>
<p>Kafka协议是基于 TCP/IP的二进制协议。消息内部是 通过长度来分割，由一些基本数据类型组成</p>
<p>特点：</p>
<ol>
<li>结构简单</li>
<li>解析速度快</li>
<li>无事务支持</li>
<li>有持久化设计</li>
</ol>
<blockquote>
<p>小结</p>
</blockquote>
<p>协议：实在 tcp/ip协议基础之上构建的一种约定俗称的规范和机制、它的主要目的可以让客户端（应用程序 java，go）进行沟通和通讯。并且这种写一下规范必须具有持久性，高可用，高可靠的性能</p>
<h2 id="5-消息队列持久化">5. 消息队列持久化</h2>
<blockquote>
<p>持久化</p>
</blockquote>
<p>简单来说就是将数据存入磁盘，而不是存在内存中随服务器重启断开而消失，使数据能够永久保存</p>
<blockquote>
<p>常见的持久化方式</p>
</blockquote>
<h2 id="6-消息的分发策略">6. 消息的分发策略</h2>
<blockquote>
<p>消息的分发策略</p>
</blockquote>
<p>MQ消息 队列有如下几个角色</p>
<ol>
<li>生产者</li>
<li>存储消息</li>
<li>消费者</li>
</ol>
<p>那么生产者生成消息以后，MQ进行存储，消费者是如何获取消息的呢？一般获取数据的方式无外乎推（push）或者拉（pull）两种方式，典型的 git就有推拉机制，我们发送的 http请求就是一种典型的拉取数据库数据返回的过程。而消息队列 MQ是一种推送的过程，而这些推机制会使用到很多的业务场景也有很多对应推机制策略</p>
<blockquote>
<p>场景分析一</p>
</blockquote>
<figure data-type="image" tabindex="1"><img src="E:%5Cnote%5C5-%E4%B8%AD%E9%97%B4%E4%BB%B6%5CRabbitMQ%5Cimage%5C15.jpg" alt="[外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-fQ6t7C7S-1615813808736)(C:\Users\VULCAN\AppData\Roaming\Typora\typora-user-images\image-20210315134437071.png)]" loading="lazy"></figure>
<p>比如我在 APP上下了一个订单，我们的系统和服务很多，我们如何得知这个消息被哪个系统或者哪些服务器或者系统进行消费，那这个时候就需要一个分发的策略。这就需要消费策略。或者称之为消费的方法论</p>
<blockquote>
<p>场景分析二</p>
</blockquote>
<figure data-type="image" tabindex="2"><img src="E:%5Cnote%5C5-%E4%B8%AD%E9%97%B4%E4%BB%B6%5CRabbitMQ%5Cimage%5C16.jpg" alt="[外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-l0CNvOUV-1615813808737)(C:\Users\VULCAN\AppData\Roaming\Typora\typora-user-images\image-20210315134747313.png)]" loading="lazy"></figure>
<p>在发送消息的过程中可能会出现异常，或者网络的抖动，故障等等因为造成消息的无法消费，比如用户在下订单，消费 MQ接受，订单系统出现故障，导致用户支付失败，那么这个时候就需要消息中间件就必须支持消息重试机制策略。也就是支持：出现问题和故障的情况下，消息不丢失还可以进行重发<br>
消息分发策略的机制和对比</p>
<h2 id="7-消息队列高可用和高可靠">7. 消息队列高可用和高可靠</h2>
<blockquote>
<p>什么是高可用机制</p>
</blockquote>
<p>所谓高可用：是指产品在规定的条件和规定的时刻或时间内处于可执行规定功能状态的能力</p>
<p>当业务量增加时，请求也过大，一台消息中间件服务器的会触及硬件（CPU，内存，磁盘）的极限，一台消息服务器你已经无法满足业务的需求，所以消息中间件必须支持集群部署，来达到高可用的目的</p>
<blockquote>
<p>集群模式1 - Master-slave主从共享数据的部署方式</p>
</blockquote>
<blockquote>
<p>集群模式2 - Master-slave主从同步部署方式</p>
</blockquote>
<p>解释：这种模式写入消息同样在 Master主节点上，但是主节点会同步数据到 slave节点形成副本，和 zookeeper或者 redis主从机制很雷同。这样可以达到负载均衡的效果，如果消费者有多个这样就可以去不同的节点进行消费，以为消息的拷贝和同步会占用很大的带宽和网络资源。在后去的 rabbitmq中会有使用</p>
<blockquote>
<p>集群模式3 - 多主集群同步部署模式</p>
</blockquote>
<p>解释：和上面的区别不是特别的大，但是它的写入可以往任意节点去写入</p>
<blockquote>
<p>集群模式4 - 多主集群转发部署模式</p>
</blockquote>
<p>解释：如果你插入的数据是 broker-1中国，元数据信息会存储数据的相关描述和记录存放的位置（队列）。它会对描述信息也就是元数据信息进行同步，如果消费者在 broker-2中进行消费，发现自己节点没有对应的信息，可以从对应的元数据信息中去查询，然后返回对应的消息信息，场景：比如买火车票或者黄牛买演唱会门票，比如第一个黄牛有顾客说要买的演唱会门票，但是没有但是他回去联系其他的黄牛询问，如果有就返回</p>
<blockquote>
<p>集群模式5 Master-slave与 Broker-cluster组合的方案</p>
</blockquote>
<p>解释：实现多主多从的热备机制来完成消息的高可用以及数据的热备机制，在生产规模达到一定的阶段的时候，这种使用的频率比较高</p>
<blockquote>
<p>什么是高可靠机制</p>
</blockquote>
<p>所谓高可靠是指：系统可以无故障低持续运行，比如一个系统突然崩溃，报错，异常等等并不影响线上业务的正常运行，出错的几率极低，就称之为：高可靠</p>
<p>在高并发的业务场景中，如果不能保证系统的高可靠，那造成的隐患和损失是非常严重的</p>
<p>如何保证中间件消息的可靠性呢，可以从两个方面考虑：</p>
<ol>
<li>消息的传输：通过协议来保证系统间数据解析的正确性</li>
<li>消息的存储区可靠：通过持久化来保证消息的可靠性</li>
</ol>
<h1 id="二-入门及安装">二、入门及安装</h1>
<h2 id="1-rabbitmq入门及安装">1. RabbitMQ入门及安装</h2>
<p>https://www.bilibili.com/video/BV1dX4y1V73G?p=27</p>
<h3 id="01-概述">01 概述</h3>
<p>简单概述：</p>
<p>RabbitMQ是一个开源的遵循 AMQP协议实现的基于 Erlang语言编写，支持多种客户端（语言），用于在分布式系统中存储消息，转发消息，具有高可用，高可扩性，易用性等特征</p>
<h3 id="02下载rabbitmq">02下载RabbitMQ</h3>
<ol>
<li>下载地址：https://www.rabbitmq.com/download.html</li>
<li>环境准备：CentOS7.x + /Erlang</li>
</ol>
<p>RabbitMQ是采用 Erlang语言开发的，所以系统环境必须提供 Erlang环境，第一步就是安装 Erlang</p>
<figure data-type="image" tabindex="3"><img src="E:%5Cnote%5C5-%E4%B8%AD%E9%97%B4%E4%BB%B6%5CRabbitMQ%5Cimage%5C24.jpg" alt="[外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-WVkC8e8q-1615876872944)(C:\Users\VULCAN\AppData\Roaming\Typora\typora-user-images\image-20210315164044604.png)]" loading="lazy"></figure>
<h3 id="03-安装erlang">03 安装Erlang</h3>
<blockquote>
<p>查看系统版本号</p>
</blockquote>
<blockquote>
<p>安装下载</p>
</blockquote>
<pre><code>mkdir -p /usr/rabbitmq
ca /usr//rabbitmq
# 将安装包上传到linux系统中
erlang-22.0.7-1.el7.x86_64.rpm
rabbitmq-server-3.7.18-1.el7.noarch.rpm

rpm -Uvh erlang-solutions-2.0-1.noarch.rpm
yum install -y erlang
erl -v
</code></pre>
<h3 id="04-安装socat">04 安装socat</h3>
<blockquote>
<p>安装下载</p>
</blockquote>
<pre><code>yum install -y socat
</code></pre>
<h3 id="05-安装rabbitmq">05 安装rabbitmq</h3>
<figure data-type="image" tabindex="4"><img src="E:%5Cnote%5C5-%E4%B8%AD%E9%97%B4%E4%BB%B6%5CRabbitMQ%5Cimage%5C26.jpg" alt="" loading="lazy"></figure>
<blockquote>
<p>安装下载</p>
</blockquote>
<pre><code>rpm -Uvh rabbitmq-server-3.7.18-1.el7.noarch.rpm
yum install rabbitmq-server -y
</code></pre>
<blockquote>
<p>启动服务</p>
</blockquote>
<pre><code># 启动服务
systemctl start rabbitmq-server
# 查看服务状态，如图
systemctl status rabbitmq-server.service
# 开机自启动
systemctl enable rabbitmq-server
# 停止服务
systemctl stop rabbitmq-server
</code></pre>
<h2 id="2-rabbitmqweb管理界面及授权操作">2. RabbitMQWeb管理界面及授权操作</h2>
<h3 id="01-rabbitmq管理界面">01 RabbitMQ管理界面</h3>
<blockquote>
<p>默认情况下，是没有安装web端的客户端插件，需要安装才可以生效</p>
</blockquote>
<pre><code>rabbitmq-plugins enable rabbitmq_management
</code></pre>
<p>说明：rabbitmq有一个默认账号和密码是：<code>guest</code>默认情况只能在 localhost本计下访问，所以需要添加一个远程登录的用户</p>
<blockquote>
<p>安装完毕以后，重启服务即可</p>
</blockquote>
<pre><code class="language-shell">systemctl restart rabbitmq-server
</code></pre>
<p>一定要记住，在对应服务器（阿里云，腾讯云等）的安全组中开放<code>15672</code>端口</p>
<blockquote>
<p>在浏览器访问</p>
</blockquote>
<figure data-type="image" tabindex="5"><img src="E:%5Cnote%5C5-%E4%B8%AD%E9%97%B4%E4%BB%B6%5CRabbitMQ%5Cimage%5C28.jpg" alt="" loading="lazy"></figure>
<pre><code># 10.关闭防火墙服务
systemctl disable firewalld
Removed symlink /etc/systemd/system/multi-user.target.wants/firewalld.service.
Removed symlink /etc/systemd/system/dbus-org.fedoraproject.FirewallD1.service.
systemctl stop firewalld   
# 11.访问web管理界面
http://10.15.0.8:15672/
</code></pre>
<h3 id="02-授权账号和密码">02 授权账号和密码</h3>
<blockquote>
<p>新增用户</p>
</blockquote>
<pre><code>rabbitmqctl add_user admin admin
</code></pre>
<blockquote>
<p>设置用户分配操作权限</p>
</blockquote>
<pre><code>rabbitmqctl set_user_tags admin administrator
</code></pre>
<p>用户级别：</p>
<ol>
<li>administrator：可以登录控制台、查看所有信息、可以对 rabbitmq进行管理</li>
<li>monitoring：监控者 登录控制台，查看所有信息</li>
<li>policymaker：策略制定者 登录控制台，指定策略</li>
<li>managment 普通管理员 登录控制台</li>
</ol>
<blockquote>
<p>为用户添加资源权限</p>
</blockquote>
<pre><code class="language-shell">rabbitmqctl set_permissions -p / admin &quot;.*&quot;&quot;.*&quot;&quot;.*&quot;
</code></pre>
<blockquote>
<p>网页登录成功</p>
</blockquote>
<h3 id="03小结">03小结：</h3>
<h2 id="3-rabbitmq之docker安装">3. RabbitMQ之Docker安装</h2>
<h3 id="01-dokcer安装rabbitmq">01 Dokcer安装RabbitMQ</h3>
<blockquote>
<p>虚拟化容器技术 - Docker的安装</p>
</blockquote>
<figure data-type="image" tabindex="6"><img src="E:%5Cnote%5C5-%E4%B8%AD%E9%97%B4%E4%BB%B6%5CRabbitMQ%5Cimage%5C31.jpg" alt="" loading="lazy"></figure>
<blockquote>
<p>docker的相关命令</p>
</blockquote>
<figure data-type="image" tabindex="7"><img src="E:%5Cnote%5C5-%E4%B8%AD%E9%97%B4%E4%BB%B6%5CRabbitMQ%5Cimage%5C32.jpg" alt="" loading="lazy"></figure>
<blockquote>
<p>安装rabbitmq</p>
</blockquote>
<figure data-type="image" tabindex="8"><img src="E:%5Cnote%5C5-%E4%B8%AD%E9%97%B4%E4%BB%B6%5CRabbitMQ%5Cimage%5C33.jpg" alt="" loading="lazy"></figure>
<p><code>可以直接走图中代码，不用走下面两项！</code></p>
<blockquote>
<p>获取rabbit镜像</p>
</blockquote>
<pre><code class="language-java">docker pull rabbitmq:management
</code></pre>
<blockquote>
<p>创建并运行容器</p>
</blockquote>
<pre><code class="language-java">docker run -id --name=myrabbit -p 15672:15672 rabbitmq:management
--hostname：指定容器主机名称
--name:指定容器名称
-p：将mq端口号映射到本地
或者运行时设置用户和密码
</code></pre>
<figure data-type="image" tabindex="9"><img src="E:%5Cnote%5C5-%E4%B8%AD%E9%97%B4%E4%BB%B6%5CRabbitMQ%5Cimage%5C34.jpg" alt="[外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-787v1Med-1615876872953)(C:\Users\VULCAN\AppData\Roaming\Typora\typora-user-images\image-20210315173500241.png)]" loading="lazy"></figure>
<blockquote>
<p>启动</p>
</blockquote>
<figure data-type="image" tabindex="10"><img src="E:%5Cnote%5C5-%E4%B8%AD%E9%97%B4%E4%BB%B6%5CRabbitMQ%5Cimage%5C35.jpg" alt="[外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-84RcXU0z-1615876872954)(C:\Users\VULCAN\AppData\Roaming\Typora\typora-user-images\image-20210315173924970.png)]" loading="lazy"></figure>
<p>访问网页，访问成功！</p>
<h2 id="4-rabbitmq的角色分类">4. RabbitMQ的角色分类</h2>
<figure data-type="image" tabindex="11"><img src="E:%5Cnote%5C5-%E4%B8%AD%E9%97%B4%E4%BB%B6%5CRabbitMQ%5Cimage%5C36.jpg" alt="" loading="lazy"></figure>
<figure data-type="image" tabindex="12"><img src="E:%5Cnote%5C5-%E4%B8%AD%E9%97%B4%E4%BB%B6%5CRabbitMQ%5Cimage%5C37.jpg" alt="" loading="lazy"></figure>
<h1 id="三-入门案例">三、入门案例</h1>
<h2 id="1-rabbitmq入门案例-simple-简单模式">1. RabbitMQ入门案例 - Simple 简单模式</h2>
<p>https://www.bilibili.com/video/BV1dX4y1V73G?p=44 实现步骤</p>
<ol>
<li>jdk1.8</li>
<li>构建一个 maven工程</li>
<li>导入 rabbitmq的 maven依赖</li>
<li>启动 rabbitmq-server服务</li>
<li>定义生产者</li>
<li>定义消费者</li>
<li>观察消息的在 rabbitmq-server服务中的进程</li>
</ol>
<h3 id="01-构建一个maven工程">01 构建一个maven工程</h3>
<figure data-type="image" tabindex="13"><img src="E:%5Cnote%5C5-%E4%B8%AD%E9%97%B4%E4%BB%B6%5CRabbitMQ%5Cimage%5C38.jpg" alt="" loading="lazy"></figure>
<h3 id="02-导入依赖">02 导入依赖</h3>
<blockquote>
<p>java原生依赖</p>
</blockquote>
<pre><code class="language-xml">&lt;dependency&gt;
    &lt;groupId&gt;com.rabbitmq&lt;/groupId&gt;
    &lt;artifactId&gt;amqp-client&lt;/artifactId&gt;
    &lt;version&gt;5.10.0&lt;/version&gt;
&lt;/dependency&gt;
</code></pre>
<h3 id="03-第一种模型">03 第一种模型</h3>
<figure data-type="image" tabindex="14"><img src="E:%5Cnote%5C5-%E4%B8%AD%E9%97%B4%E4%BB%B6%5CRabbitMQ%5Cimage%5C39.jpg" alt="" loading="lazy"></figure>
<p>在上图的模型中，有以下概念：</p>
<ol>
<li>生产者，也就是要发送消息的程序</li>
<li>消费者：消息的接受者，会一直等待消息到来。</li>
<li>消息队列：图中红色部分。类似一个邮箱，可以缓存消息；生产者向其中投递消息，消费者从其中取出消息。</li>
</ol>
<blockquote>
<p>生产者</p>
</blockquote>
<pre><code class="language-java">//简单模式
public class Producer{
    //1.创建连接工厂
    ConnectionFactory connectionFactory = new ConnectionFactory();
    connectionFactory.setHost(&quot;10.15.0.9&quot;);
    connectionFactory.setPort(5672);
    connectionFactory.setUsername(&quot;admin&quot;);
    connectionFactory.setPassword(&quot;admin&quot;);
    connectionFactory.setVirtualHost(&quot;/&quot;);
    Connection connection = connectionFactory.newConnection(&quot;生产者&quot;);
    //2.创建通道
    Channel channel = connection.createChannel();
    //3.通过创建交换机，声明队列，绑定关系，路由key，发送消息和接受消息
    /*参数1: 是否持久化，非持久化消息会存盘吗？会存盘，但是会随着重启服务器而丢失
      参数2:是否独占队列 
      参数3:是否自动删除，随着最后一个消费者消息完毕消息以后是否把队列自动删除
        参数4:携带附属属性
    */
    String queueName = &quot;queue1&quot;;
    channel.queueDeclare(queueName,false,false,false,null);
    //4.发送消息给队列queue
    /*参数1: 交换机
      参数2:队列、路由key
      参数3:消息的状态控制
        参数4:消息主题
    */
    //面试题：可以存在没有交换机的队列吗？不可能，虽然没有指定交换机但是一定会存在一个默认的交换机
    String message = &quot;Hello&quot;;
    channel.basicPublish(&quot;&quot;,message, null,message.getBytes());
    //5.关闭
    channel.close();
    connection.close();
}
</code></pre>
<blockquote>
<p>消费者</p>
</blockquote>
<pre><code class="language-java">//简单模式
public class Consumer{
    //1.创建连接工厂
    ConnectionFactory connectionFactory = new ConnectionFactory();
    connectionFactory.setHost(&quot;10.15.0.9&quot;);
    connectionFactory.setPort(5672);
    connectionFactory.setUsername(&quot;admin&quot;);
    connectionFactory.setPassword(&quot;admin&quot;);
    connectionFactory.setVirtualHost(&quot;/&quot;);
    Connection connection = connectionFactory.newConnection(&quot;生产者&quot;);
    //2.创建通道
    Channel channel = connection.createChannel();
    //3.接受内容
    channel.basicConsume(&quot;queue1&quot;,true,new DefaultConsumer(){
        public void handle(String consumerTag, Delivery message) throws IOException {
          System.out.println(new String(&quot;收到消息是&quot; + new String(meassage.getBody()),&quot;UTF-8&quot;));
        },new CancelCallback(){
            public void handle(String consumerTag) throws IOException {
                System.out.println(&quot;接受失败了&quot;);
        }
      });
    //4.关闭
    channel.close();
    connection.close();
}
</code></pre>
<h2 id="2-什么是amqp">2. 什么是AMQP</h2>
<h3 id="01-什么是amqp">01 什么是AMQP</h3>
<p>AMQP全称：Advanced Message Queuing Protocol（高级消息队列协议）。是应用层协议的一个开发标准，为面向消息的中间件设计</p>
<h3 id="02-amqp生产者流转过程">02 AMQP生产者流转过程</h3>
<figure data-type="image" tabindex="15"><img src="E:%5Cnote%5C5-%E4%B8%AD%E9%97%B4%E4%BB%B6%5CRabbitMQ%5Cimage%5C40.jpg" alt="[外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-78cQpQXh-1615906714913)(C:\Users\VULCAN\AppData\Roaming\Typora\typora-user-images\image-20210315201857946.png)]" loading="lazy"></figure>
<h3 id="03-amqp消费者流转过程">03 AMQP消费者流转过程</h3>
<figure data-type="image" tabindex="16"><img src="E:%5Cnote%5C5-%E4%B8%AD%E9%97%B4%E4%BB%B6%5CRabbitMQ%5Cimage%5C41.jpg" alt="" loading="lazy"></figure>
<h2 id="3-rabbitmq的核心组成部分">3. RabbitMQ的核心组成部分</h2>
<h3 id="01-rabbitmq的核心组成部分">01 RabbitMQ的核心组成部分</h3>
<figure data-type="image" tabindex="17"><img src="E:%5Cnote%5C5-%E4%B8%AD%E9%97%B4%E4%BB%B6%5CRabbitMQ%5Cimage%5C43.jpg" alt="" loading="lazy"></figure>
<figure data-type="image" tabindex="18"><img src="E:%5Cnote%5C5-%E4%B8%AD%E9%97%B4%E4%BB%B6%5CRabbitMQ%5Cimage%5C42.jpg" alt="" loading="lazy"></figure>
<h3 id="02-rabbitmq整体架构是什么样子的">02 RabbitMQ整体架构是什么样子的？</h3>
<figure data-type="image" tabindex="19"><img src="E:%5Cnote%5C5-%E4%B8%AD%E9%97%B4%E4%BB%B6%5CRabbitMQ%5Cimage%5C44.jpg" alt="" loading="lazy"></figure>
<h3 id="03-rabbitmq的运行流程">03 RabbitMQ的运行流程</h3>
<figure data-type="image" tabindex="20"><img src="E:%5Cnote%5C5-%E4%B8%AD%E9%97%B4%E4%BB%B6%5CRabbitMQ%5Cimage%5C45.jpg" alt="" loading="lazy"></figure>
<h3 id="04-rabbitmq支持的消息模型">04 RabbitMQ支持的消息模型</h3>
<figure data-type="image" tabindex="21"><img src="E:%5Cnote%5C5-%E4%B8%AD%E9%97%B4%E4%BB%B6%5CRabbitMQ%5Cimage%5C46.jpg" alt="" loading="lazy"></figure>
<figure data-type="image" tabindex="22"><img src="E:%5Cnote%5C5-%E4%B8%AD%E9%97%B4%E4%BB%B6%5CRabbitMQ%5Cimage%5C47.jpg" alt="" loading="lazy"></figure>
<ol>
<li>简单模式 Simple</li>
<li>工作模式 Work</li>
<li>发布订阅模式</li>
<li>路由模式</li>
<li>主题 Topic模式</li>
<li>参数模式</li>
</ol>
<h2 id="4-rabbitmq入门案例-fanout-模式">4. RabbitMQ入门案例 - fanout 模式</h2>
<h3 id="01-rabbitmq的模式之发布订阅模式">01 RabbitMQ的模式之发布订阅模式</h3>
<blockquote>
<p>图解</p>
</blockquote>
<figure data-type="image" tabindex="23"><img src="E:%5Cnote%5C5-%E4%B8%AD%E9%97%B4%E4%BB%B6%5CRabbitMQ%5Cimage%5C48.jpg" alt="" loading="lazy"></figure>
<p><strong>发布订阅模式的具体实现</strong></p>
<ol>
<li>web操作查看视频</li>
<li>类型：fanout</li>
<li>特点：Fanout - 发布与订阅模式，是一种广播机制，它是没有路由 key的模式</li>
</ol>
<blockquote>
<p>生产者</p>
</blockquote>
<pre><code class="language-java">//简单模式
public class Producer{
    //1.创建连接工厂
    ConnectionFactory connectionFactory = new ConnectionFactory();
    connectionFactory.setHost(&quot;10.15.0.9&quot;);
    connectionFactory.setPort(5672);
    connectionFactory.setUsername(&quot;admin&quot;);
    connectionFactory.setPassword(&quot;admin&quot;);
    connectionFactory.setVirtualHost(&quot;/&quot;);
    Connection connection = connectionFactory.newConnection(&quot;生产者&quot;);
    //2.创建通道
    Channel channel = connection.createChannel();
    //3.通过创建交换机，声明队列，绑定关系，路由key，发送消息和接受消息
    /*参数1: 是否持久化，非持久化消息会存盘吗？会存盘，但是会随着重启服务器而丢失
      参数2:是否独占队列 
      参数3:是否自动删除，随着最后一个消费者消息完毕消息以后是否把队列自动删除
        参数4:携带附属属性
    */
    String queueName = &quot;queue1&quot;;
    channel.queueDeclare(queueName,false,false,false,null);
    //4.发送消息给队列queue
    /*参数1: 交换机
      参数2:队列、路由key
      参数3:消息的状态控制
        参数4:消息主题
    */
    //面试题：可以存在没有交换机的队列吗？不可能，虽然没有指定交换机但是一定会存在一个默认的交换机
    String message = &quot;Hello&quot;;
    //5.准备交换机
    String exchangeName = &quot;fanout-exchange&quot;;
    //6.定义路由key
    String routeKey = &quot;&quot;;
    //7.指定交换机的类型
    String type = &quot;fanout&quot;;
    channel.basicPublish(exchangeName,routeKey, null,message.getBytes());
    //8.关闭
    channel.close();
    connection.close();
}
</code></pre>
<blockquote>
<p>消费者</p>
</blockquote>
<p>代码一样，使用线程启动测试而已！</p>
<figure data-type="image" tabindex="24"><img src="E:%5Cnote%5C5-%E4%B8%AD%E9%97%B4%E4%BB%B6%5CRabbitMQ%5Cimage%5C49.jpg" alt="[外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-uud19sfq-1615906714934)(C:\Users\VULCAN\AppData\Roaming\Typora\typora-user-images\image-20210315222738258.png)]" loading="lazy"></figure>
<p>此处没有通过代码去绑定交换机和队列，而是通过可视化界面去绑定的！</p>
<h2 id="5-rabbitmq入门案例-direct-模式">5. RabbitMQ入门案例 - Direct 模式</h2>
<pre><code class="language-java">//6.定义路由key
String routeKey = &quot;email&quot;;
//7.指定交换机的类型
String type = &quot;direct&quot;;
channel.basicPublish(exchangeName,routeKey, null,message.getBytes());
</code></pre>
<h2 id="6-rabbitmq入门案例-topic-模式">6. RabbitMQ入门案例 - Topic 模式</h2>
<figure data-type="image" tabindex="25"><img src="E:%5Cnote%5C5-%E4%B8%AD%E9%97%B4%E4%BB%B6%5CRabbitMQ%5Cimage%5C50.jpg" alt="" loading="lazy"></figure>
<pre><code class="language-java">//6.定义路由key
String routeKey = &quot;com.order.test.xxx&quot;;
//7.指定交换机的类型
String type = &quot;direct&quot;;
channel.basicPublish(exchangeName,routeKey, null,message.getBytes());
</code></pre>
<blockquote>
<p>代码创建及绑定</p>
</blockquote>
<pre><code class="language-java">//5.准备交换机
String exchangeName = &quot;direct_message_exchange&quot;;
String exchangeType = &quot;direct&quot;;
//如果你用界面把queue和exchange的关系先绑定话，代码就不需要在编写这些声明代码可以让代码变得更简洁
//如果用代码的方式去声明，我们要学习一下
//6.声明交换机 所谓的持久化就是指，交换机会不会随着服务器重启造成丢失
channel.exchangeDeclare(exchangeName,exchangeType,true);

//7.声明队列
channel.queueDeclare(&quot;queue5&quot;,true,false,false,null);
channel.queueDeclare(&quot;queue6&quot;,true,false,false,null);
channel.queueDeclare(&quot;queue7&quot;,true,false,false,null);

//8.绑定队列和交换机的关系
channel.queueBind(&quot;queue5&quot;,exchangeName,&quot;order&quot;);
channel.queueBind(&quot;queue6&quot;,exchangeName,&quot;order&quot;);
channel.queueBind(&quot;queue7&quot;,exchangeName,&quot;course&quot;);

channel.basicPublish(exchangeName,course, null,message.getBytes());
</code></pre>
<h2 id="7-rabbitmq入门案例-work模式">7. RabbitMQ入门案例 - Work模式</h2>
<h3 id="01-work模式轮询模式round-robin">01 Work模式轮询模式（Round-Robin）</h3>
<blockquote>
<p>图解</p>
</blockquote>
<p>当有多个消费者时，我们的消息会被哪个消费者消费呢，我们又该如何均衡消费者消费信息的多少呢？</p>
<p>主要有两种模式：</p>
<ol>
<li>轮询模式的分发：一个消费者一条，按均分配</li>
<li>公平分发：根据消费者的消费能力进行公平分发，处理快的处理的多，处理慢的处理的少；按劳分配</li>
</ol>
<blockquote>
<p>生产者</p>
</blockquote>
<p>跟简单模式一样！</p>
<blockquote>
<p>消费者</p>
</blockquote>
<p>创建两个一样的！</p>
<h3 id="02-work模式公平分发模式">02 Work模式公平分发模式</h3>
<blockquote>
<p>生产者</p>
</blockquote>
<p>跟简单模式一样！</p>
<blockquote>
<p>消费者</p>
</blockquote>
<pre><code class="language-java">//简单模式
public class Consumer{
    //3.接受内容
    //指标定义出来
    channel.basicQos(1);
    channel.basicConsume(&quot;queue1&quot;,false,new DefaultConsumer(){
        public void handle(String consumerTag, Delivery message) throws IOException {
          System.out.println(new String(&quot;收到消息是&quot; + new String(meassage.getBody()),&quot;UTF-8&quot;));
          //改成手动应答
          channel.basicAck(delivery.getEnvelope().getDeliveryTag(),false);
        },new CancelCallback(){
            public void handle(String consumerTag) throws IOException {
                System.out.println(&quot;接受失败了&quot;);
        }
      });
    //4.关闭
    channel.close();
    connection.close();
}
</code></pre>
<p>创建两个一样的！</p>
<h2 id="8-rabbitmq使用场景">8. RabbitMQ使用场景</h2>
<h3 id="01-解耦-削峰-异步">01 解耦、削峰、异步</h3>
<blockquote>
<p>同步异步的问题（串行）</p>
</blockquote>
<p>串行方式：将订单信息写入数据库成功后，发送注册邮件，再发送注册短信。以上三个任务全部完成后，返回给客户端</p>
<figure data-type="image" tabindex="26"><img src="E:%5Cnote%5C5-%E4%B8%AD%E9%97%B4%E4%BB%B6%5CRabbitMQ%5Cimage%5C52.jpg" alt="" loading="lazy"></figure>
<pre><code class="language-java">public void makeOrder(){
    //1.发送订单
    //2.发送短信服务
    //3.发送email服务
    //4.发送app服务
}
</code></pre>
<blockquote>
<p>并行方式 异步线程池</p>
</blockquote>
<p>并行方式：将订单信息写入数据库成功后，发送注册邮件的同时，发送注册短信。以上三个任务完成后，返回给客户端。与串行的差别是，并行的方式可以提高处理的时间</p>
<figure data-type="image" tabindex="27"><img src="E:%5Cnote%5C5-%E4%B8%AD%E9%97%B4%E4%BB%B6%5CRabbitMQ%5Cimage%5C53.jpg" alt="" loading="lazy"></figure>
<pre><code class="language-java">public void test(){
    //异步
    theadpool.submit(new Callable&lt;Object&gt;{
        //1.发送短信服务
    })
    //异步
    theadpool.submit(new Callable&lt;Object&gt;{
        //2.
    })
    //异步
    theadpool.submit(new Callable&lt;Object&gt;{
        //3.
    })
    //异步
    theadpool.submit(new Callable&lt;Object&gt;{
        //4.
    })
}
</code></pre>
<p>存在问题</p>
<ol>
<li>耦合度高</li>
<li>需要自己写线程池自己维护成本太高</li>
<li>出现了消息可能会丢失，需要你自己做消息补偿</li>
<li>如何保证消息的可靠性你自己写</li>
<li>如果服务器承载不了，你需要自己去写高可用</li>
</ol>
<blockquote>
<p>异步消息队列的方式</p>
</blockquote>
<figure data-type="image" tabindex="28"><img src="E:%5Cnote%5C5-%E4%B8%AD%E9%97%B4%E4%BB%B6%5CRabbitMQ%5Cimage%5C54.jpg" alt="" loading="lazy"></figure>
<p>好处：</p>
<ol>
<li>完全解耦，用 MQ建立桥接</li>
<li>有独立的线程池和运行模型</li>
<li>出现了消息可能会丢失，MQ有持久化功能</li>
<li>如何保证消息的可靠性，死信队列和消息转移等</li>
<li>如果服务器承载不了，你需要自己去写高可用，HA镜像模型高可用</li>
</ol>
<p>按照以上约定，用户的响应时间相当于是订单信息写入数据库的时间，也就是50毫秒。注册邮件，发送短信写入消息队列后，直接返回，因此写入消息队列的速度很快，基本可以忽略，因此用户的响应时间可能是50毫秒。因此架构改变后，系统的吞吐量提高到每秒20QPS。比串行提高了3倍，比并行提高了两倍</p>
<h3 id="02-高内聚低耦合">02 高内聚，低耦合</h3>
<figure data-type="image" tabindex="29"><img src="E:%5Cnote%5C5-%E4%B8%AD%E9%97%B4%E4%BB%B6%5CRabbitMQ%5Cimage%5C55.jpg" alt="在这里插入图片描述" loading="lazy"></figure>
<p>好处：</p>
<ol>
<li>完全解耦，用 MQ建立桥接</li>
<li>有独立的线程池和运行模型</li>
<li>出现了消息可能会丢失，MQ有持久化功能</li>
<li>如何保证消息的可靠性，死信队列和消息转移等</li>
<li>如果服务器承载不了，你需要自己去写高可用，HA镜像模型高可用</li>
</ol>
<p>按照以上约定，用户的响应时间相当于是订单信息写入数据库的时间，也就是50毫秒。注册邮件，发送短信写入消息队列后，直接返回，因此写入消息队列的速度很快，基本可以忽略，因此用户的响应时间可能是50毫秒。因此架构改变后，系统的吞吐量提高到每秒20QPS。比串行提高了3倍，比并行提高了两倍</p>
<h1 id="四-springboot案例">四、Springboot案例</h1>
<h2 id="1-fanout-模式">1. Fanout 模式</h2>
<p>https://www.bilibili.com/video/BV1dX4y1V73G?p=44</p>
<blockquote>
<p>生产者</p>
</blockquote>
<p><strong>application.yml</strong></p>
<pre><code class="language-yml"># 服务端口
server:
  port: 8080
# 配置rabbitmq服务
spring:
    rabbitmq:
        username: admin
        password: admin
        virtual-host: /
        host: 127.0.0.1
        port: 5672
</code></pre>
<p>OrderService.java</p>
<pre><code class="language-java">public class OrderService{
    @Autowired
    private RabbitTemplate rabbitTemplate;
    //模拟用户下单
    public void makeOrder(String userid,String productid,int num){
        //1.根据商品id查询库存是否足够
        //2.保存订单
        String orderId = UUID.randomUUID().toString();
        sout(&quot;订单生产成功：&quot;+orderId);
        //3.通过MQ来完成消息的分发
        //参数1：交换机 参数2：路由key/queue队列名称 参数3：消息内容
        String exchangeName = &quot;fanout_order_exchange&quot;;
        String routingKey = &quot;&quot;;
        rabbitTemplate.convertAndSend(exchangeName,routingKey,orderId);
    }
}
</code></pre>
<blockquote>
<p>消费者</p>
</blockquote>
<p><strong>application.yml</strong></p>
<pre><code class="language-yml"># 服务端口
server:
  port: 8080
# 配置rabbitmq服务
spring:
    rabbitmq:
        username: admin
        password: admin
        virtual-host: /
        host: 127.0.0.1
        port: 5672
</code></pre>
<p><strong>RabbitMqConfiguration.java</strong></p>
<pre><code class="language-java">@Configuration
public class RabbitMqConfiguration{
    //1.声明注册fanout模式的交换机
    @Bean
    public FanoutExchange fanoutExchange(){
        return new FanoutExchange(&quot;fanout_order_exchange&quot;,true,false);
    }
    //2.声明队列
    @Bean
    public Queue smsQueue(){
        return new Queue(&quot;sms.fanout.queue&quot;,true);
    }
    @Bean
    public Queue duanxinQueue(){
        return new Queue(&quot;duanxin.fanout.queue&quot;,true);
    }
    @Bean
    public Queue emailQueue(){
        return new Queue(&quot;email.fanout.queue&quot;,true);
    }
    //3.完成绑定关系
    @Bean
    public Binding smsBingding(){
        return BindingBuilder.bin(smsQueue()).to(fanoutExchange());
    }
    @Bean
    public Binding duanxinBingding(){
        return BindingBuilder.bin(duanxinQueue()).to(fanoutExchange());
    }
    @Bean
    public Binding emailBingding(){
        return BindingBuilder.bin(emailQueue()).to(fanoutExchange());
    }
}
</code></pre>
<p><strong>FanoutSmsConsumer.java</strong></p>
<pre><code class="language-java">@Component
@RabbitListener(queue = {&quot;sms.direct.queue&quot;})
public class FanoutSmsConsumer{
    @RabbitHandler
    public void reviceMessage(String message){
        sout(&quot;sms接收到了的订单信息是：&quot;+message);
    }
}
</code></pre>
<p><strong>FanoutDuanxinConsumer.java</strong></p>
<pre><code class="language-java">@Component
@RabbitListener(queue = {&quot;duanxin.direct.queue&quot;})
public class FanoutDuanxinConsumer{
    @RabbitHandler
    public void reviceMessage(String message){
        sout(&quot;duanxin接收到了的订单信息是：&quot;+message);
    }
}
</code></pre>
<p><strong>FanoutEmailConsumer.java</strong></p>
<pre><code class="language-java">@Component
@RabbitListener(queue = {&quot;duanxin.direct.queue&quot;})
public class FanoutEmailConsumer{
    @RabbitHandler
    public void reviceMessage(String message){
        sout(&quot;email接收到了的订单信息是：&quot;+message);
    }
}
</code></pre>
<h2 id="2-direct-模式">2. Direct 模式</h2>
<blockquote>
<p>生产者</p>
</blockquote>
<p><strong>OrderService.java</strong></p>
<pre><code class="language-java">public class OrderService{
    @Autowired
    private RabbitTemplate rabbitTemplate;
    //模拟用户下单
    public void makeOrder(String userid,String productid,int num){
        //1.根据商品id查询库存是否足够
        //2.保存订单
        String orderId = UUID.randomUUID().toString();
        sout(&quot;订单生产成功：&quot;+orderId);
        //3.通过MQ来完成消息的分发
        //参数1：交换机 参数2：路由key/queue队列名称 参数3：消息内容
        String exchangeName = &quot;direct_order_exchange&quot;;
        String routingKey = &quot;&quot;;
        rabbitTemplate.convertAndSend(exchangeName,&quot;email&quot;,orderId);
        rabbitTemplate.convertAndSend(exchangeName,&quot;duanxin&quot;,orderId);
    }
}
</code></pre>
<blockquote>
<p>消费者</p>
</blockquote>
<p><strong>RabbitMqConfiguration.java</strong></p>
<pre><code class="language-java">@Configuration
public class RabbitMqConfiguration{
    //1.声明注册fanout模式的交换机
    @Bean
    public DirectExchange directExchange(){
        return new DirectExchange(&quot;direct_order_exchange&quot;,true,false);
    }
    //2.声明队列
    @Bean
    public Queue smsQueue(){
        return new Queue(&quot;sms.direct.queue&quot;,true);
    }
    @Bean
    public Queue duanxinQueue(){
        return new Queue(&quot;duanxin.direct.queue&quot;,true);
    }
    @Bean
    public Queue emailQueue(){
        return new Queue(&quot;email.direct.queue&quot;,true);
    }
    //3.完成绑定关系
    @Bean
    public Binding smsBingding(){
        return BindingBuilder.bin(smsQueue()).to(fanoutExchange()).with(&quot;sms&quot;);
    }
    @Bean
    public Binding duanxinBingding(){
        return BindingBuilder.bin(duanxinQueue()).to(fanoutExchange()).with(&quot;duanxin&quot;);
    }
    @Bean
    public Binding emailBingding(){
        return BindingBuilder.bin(emailQueue()).to(fanoutExchange()).with(&quot;email&quot;);
    }
}
</code></pre>
<h2 id="3-topic-模式">3. Topic 模式</h2>
<blockquote>
<p>生产者</p>
</blockquote>
<pre><code class="language-java">public class OrderService{
    @Autowired
    private RabbitTemplate rabbitTemplate;
    //模拟用户下单
    public void makeOrder(String userid,String productid,int num){
        //1.根据商品id查询库存是否足够
        //2.保存订单
        String orderId = UUID.randomUUID().toString();
        sout(&quot;订单生产成功：&quot;+orderId);
        //3.通过MQ来完成消息的分发
        //参数1：交换机 参数2：路由key/queue队列名称 参数3：消息内容
        String exchangeName = &quot;direct_order_exchange&quot;;
        String routingKey = &quot;com.duanxin&quot;;
        rabbitTemplate.convertAndSend(exchangeName,routingKey,orderId);
    }
}
</code></pre>
<blockquote>
<p>消费者（采用注解）</p>
</blockquote>
<p><strong>FanoutSmsConsumer.java</strong></p>
<pre><code class="language-java">@Component
@RabbitListener(bindings = @QueueBinding(
    value = @Queue(value = &quot;sms.topic.queue&quot;,durable = &quot;true&quot;,antoDelete = &quot;false&quot;),
    exchange = @Exchange(value = &quot;topic_order_exchange&quot;,type = &quot;ExchangeTypes.TOPIC&quot;)
    key = &quot;#.sms.#&quot;
))
public class TopicSmsConsumer{
    @RabbitHandler
    public void reviceMessage(String message){
        sout(&quot;sms接收到了的订单信息是：&quot;+message);
    }
}
</code></pre>
<p><strong>FanoutDuanxinConsumer.java</strong></p>
<pre><code class="language-java">@Component
@RabbitListener(bindings = @QueueBinding(
    value = @Queue(value = &quot;duanxin.topic.queue&quot;,durable = &quot;true&quot;,antoDelete = &quot;false&quot;),
    exchange = @Exchange(value = &quot;topic_order_exchange&quot;,type = &quot;ExchangeTypes.TOPIC&quot;)
    key = &quot;#.duanxin.#&quot;
))
public classTopicDuanxinConsumer{
    @RabbitHandler
    public void reviceMessage(String message){
        sout(&quot;duanxin接收到了的订单信息是：&quot;+message);
    }
}
</code></pre>
<p><strong>FanoutEmailConsumer.java</strong></p>
<pre><code class="language-java">@Component
@RabbitListener(bindings = @QueueBinding(
    value = @Queue(value = &quot;email.topic.queue&quot;,durable = &quot;true&quot;,antoDelete = &quot;false&quot;),
    exchange = @Exchange(value = &quot;topic_order_exchange&quot;,type = &quot;ExchangeTypes.TOPIC&quot;)
    key = &quot;#.email.#&quot;
))
public class TopicEmailConsumer{
    @RabbitHandler
    public void reviceMessage(String message){
        sout(&quot;email接收到了的订单信息是：&quot;+message);
    }
}
</code></pre>
<h1 id="五-rabbitmq高级">五、RabbitMQ高级</h1>
<p>##1.  过期时间TTL</p>
<p>https://www.bilibili.com/video/BV1dX4y1V73G?p=44</p>
<blockquote>
<p>概述</p>
</blockquote>
<p>过期时间 TTl表示可以对消息设置预期的时间，在这个时间内都可以被消费者接收获取；过了之后消息将自动被删除。RabbitMQ可以对消息和队列设置 TTL，目前有两种方法可以设置</p>
<ol>
<li>第一种方法是通过队列属性设置，队列中所有消息都有相同的过期时间</li>
<li>第二种方法是对消息进行单独设置，每条消息 TTL可以不同</li>
</ol>
<p>如果上述两种方法同时使用，则消息的过期时间以两者 TTL较小的那个数值为准。消息在队列的生存时间一旦超过设置的 TTL值，就称为 dead message被投递到死信队列，消费者将无法再收到该消息</p>
<blockquote>
<p>设置队列TTL</p>
</blockquote>
<p><strong>RabbitMqConfiguration.java</strong></p>
<pre><code class="language-java">@Configuration
public class TTLRabbitMQConfiguration{
    //1.声明注册direct模式的交换机
    @Bean
    public DirectExchange ttldirectExchange(){
        return new DirectExchange(&quot;ttl_direct_exchange&quot;,true,false);}
    //2.队列的过期时间
    @Bean
    public Queue directttlQueue(){
        //设置过期时间
        Map&lt;String,Object&gt; args = new HashMap&lt;&gt;();
        args.put(&quot;x-message-ttl&quot;,5000);//这里一定是int类型
        return new Queue(&quot;ttl.direct.queue&quot;,true,false,false,args);}

    @Bean
    public Binding ttlBingding(){
        return BindingBuilder.bin(directttlQueue()).to(ttldirectExchange()).with(&quot;ttl&quot;);
    }
}
</code></pre>
<blockquote>
<p>设置消息TTL</p>
</blockquote>
<pre><code class="language-java">public class OrderService{
    @Autowired
    private RabbitTemplate rabbitTemplate;
    //模拟用户下单
    public void makeOrder(String userid,String productid,int num){
        //1.根据商品id查询库存是否足够
        //2.保存订单
        String orderId = UUID.randomUUID().toString();
        sout(&quot;订单生产成功：&quot;+orderId);
        //3.通过MQ来完成消息的分发
        //参数1：交换机 参数2：路由key/queue队列名称 参数3：消息内容
        String exchangeName = &quot;ttl_order_exchange&quot;;
        String routingKey = &quot;ttlmessage&quot;;
        //给消息设置过期时间
        MessagePostProcessor messagePostProcessor = new MessagePostProcessor(){
            public Message postProcessMessage(Message message){
                //这里就是字符串
                message.getMessageProperties().setExpiration(&quot;5000&quot;);
                message.getMessageProperties().setContentEncoding(&quot;UTF-8&quot;);
                return message;
            }
        }
        rabbitTemplate.convertAndSend(exchangeName,routingKey,orderId,messagePostProcessor);
    }
}
</code></pre>
<p><strong>RabbitMqConfiguration.java</strong></p>
<pre><code class="language-java">@Configuration
public class TTLRabbitMQConfiguration{
    //1.声明注册direct模式的交换机
    @Bean
    public DirectExchange ttldirectExchange(){
        return new DirectExchange(&quot;ttl_direct_exchange&quot;,true,false);}
    //2.队列的过期时间
    @Bean
    public Queue directttlQueue(){
        //设置过期时间
        Map&lt;String,Object&gt; args = new HashMap&lt;&gt;();
        args.put(&quot;x-message-ttl&quot;,5000);//这里一定是int类型
        return new Queue(&quot;ttl.direct.queue&quot;,true,false,false,args);}
    @Bean
    public Queue directttlMessageQueue(){
        return new Queue(&quot;ttlMessage.direct.queue&quot;,true,false,false,args);}

    @Bean
    public Binding ttlBingding(){
        return BindingBuilder.bin(directttlMessageQueue()).to(ttldirectExchange()).with(&quot;ttlmessage&quot;);
    }
}
</code></pre>
<h2 id="2-死信队列">2. 死信队列</h2>
<blockquote>
<p>概述</p>
</blockquote>
<p>DLX，全称 <code>Dead-Letter-Exchange</code>，可以称之为死信交换机，也有人称之为死信邮箱。当消息再一个队列中变成死信之后，它能被重新发送到另一个交换机中，这个交换机就是 DLX，绑定 DLX的队列就称之为死信队列。消息变成死信，可能是由于以下原因：</p>
<ol>
<li>消息被拒绝</li>
<li>消息过期</li>
<li>队列达到最大长度</li>
</ol>
<p>DLX也是一个正常的交换机，和一般的交换机没有区别，它能在任何的队列上被指定，实际上就是设置某一个队列的属性，当这个队列中存在死信时，Rabbitmq就会自动地将这个消息重新发布到设置的 DLX上去，进而被路由到另一个队列，即死信队列。</p>
<p>要想使用死信队列，只需要在定义队列的时候设置队列参数<code>x-dead-letter-exchange</code>指定交换机即可</p>
<blockquote>
<p>代码</p>
</blockquote>
<p><strong>DeadRabbitMqConfiguration.java</strong></p>
<pre><code class="language-java">@Configuration
public class DeadRabbitMqConfiguration{
    //1.声明注册direct模式的交换机
    @Bean
    public DirectExchange deadDirect(){
        return new DirectExchange(&quot;dead_direct_exchange&quot;,true,false);}
    //2.队列的过期时间
    @Bean
    public Queue deadQueue(){
        return new Queue(&quot;dead.direct.queue&quot;,true);}
    @Bean
    public Binding deadbinds(){
        return BindingBuilder.bind(deadDirect()).to(deadQueue()).with(&quot;dead&quot;);
    }
}
</code></pre>
<p><strong>RabbitMqConfiguration.java</strong></p>
<pre><code class="language-java">@Configuration
public class TTLRabbitMQConfiguration{
    //1.声明注册direct模式的交换机
    @Bean
    public DirectExchange ttldirectExchange(){
        return new DirectExchange(&quot;ttl_direct_exchange&quot;,true,false);}
    //2.队列的过期时间
    @Bean
    public Queue directttlQueue(){
        //设置过期时间
        Map&lt;String,Object&gt; args = new HashMap&lt;&gt;();
        //args.put(&quot;x-max-length&quot;,5);
        args.put(&quot;x-message-ttl&quot;,5000);//这里一定是int类型
        args.put(&quot;x-dead-letter-exchange&quot;,&quot;dead_direct_exchange&quot;);
        args.put(&quot;x-dead-letter-routing-key&quot;,&quot;dead&quot;);//fanout不需要配置
        return new Queue(&quot;ttl.direct.queue&quot;,true,false,false,args);}
    @Bean
    public Queue directttlMessageQueue(){
        return new Queue(&quot;ttlMessage.direct.queue&quot;,true,false,false,args);}

    @Bean
    public Binding ttlBingding(){
        return BindingBuilder.bin(directttlMessageQueue()).to(ttldirectExchange()).with(&quot;ttlmessage&quot;);
    }
}
</code></pre>
<figure data-type="image" tabindex="30"><img src="E:%5Cnote%5C5-%E4%B8%AD%E9%97%B4%E4%BB%B6%5CRabbitMQ%5Cimage%5C73.jpg" alt="" loading="lazy"></figure>
<h2 id="3-内存磁盘的监控">3. 内存磁盘的监控</h2>
<h3 id="01-rabbitmq内存警告">01 RabbitMQ内存警告</h3>
<figure data-type="image" tabindex="31"><img src="E:%5Cnote%5C5-%E4%B8%AD%E9%97%B4%E4%BB%B6%5CRabbitMQ%5Cimage%5C74.jpg" alt="" loading="lazy"></figure>
<h3 id="02-rabbitmq的内存控制">02 RabbitMQ的内存控制</h3>
<p>参考帮助文档：<code>http://www.rabbbitmq.com/configure.html</code></p>
<p>当出现警告的时候，可以通过配置去修改和调整</p>
<blockquote>
<p>命令的方式</p>
</blockquote>
<pre><code>rabbitmqctl set_vm_memory_high_watermark &lt;fraction&gt;
rabbitmqctl set_vm_memory_high_watermark absolute 50MB
</code></pre>
<p>fraction/value 为内存阈值。默认情况是：0.4/2GB，代表的含义是：当 RabbitMQ的内存超过40%时，就会产生警告并且会阻塞所有生产者的连接。通过此命令修改阈值在 Broker重启以后将会失效，通过修改配置文件设置的阈值则不会随着重启而消失，但修改了配置文件一样要重启 Broker才会生效</p>
<figure data-type="image" tabindex="32"><img src="E:%5Cnote%5C5-%E4%B8%AD%E9%97%B4%E4%BB%B6%5CRabbitMQ%5Cimage%5C75.jpg" alt="" loading="lazy"></figure>
<blockquote>
<p>配置文件方式 rabbitmq.conf</p>
</blockquote>
<figure data-type="image" tabindex="33"><img src="E:%5Cnote%5C5-%E4%B8%AD%E9%97%B4%E4%BB%B6%5CRabbitMQ%5Cimage%5C76.jpg" alt="" loading="lazy"></figure>
<h3 id="03-rabbitmq的内存换页">03 RabbitMQ的内存换页</h3>
<figure data-type="image" tabindex="34"><img src="E:%5Cnote%5C5-%E4%B8%AD%E9%97%B4%E4%BB%B6%5CRabbitMQ%5Cimage%5C77.jpg" alt="" loading="lazy"></figure>
<h3 id="04-rabbitmq的磁盘预警">04 RabbitMQ的磁盘预警</h3>
<figure data-type="image" tabindex="35"><img src="E:%5Cnote%5C5-%E4%B8%AD%E9%97%B4%E4%BB%B6%5CRabbitMQ%5Cimage%5C78.jpg" alt="" loading="lazy"></figure>
<h2 id="4-集群">4.  集群</h2>
<figure data-type="image" tabindex="36"><img src="E:%5Cnote%5C5-%E4%B8%AD%E9%97%B4%E4%BB%B6%5CRabbitMQ%5Cimage%5C79.jpg" alt="" loading="lazy"></figure>
<h3 id="01-集群搭建">01 集群搭建</h3>
<p>配置的前提是你的 rabbitmq可以运行起来，比如<code>ps aix|grep rebbitmq</code>你能看到相关进程，又比如运行<code>rabbitmqct status</code>你可以看到类似如下信息而不报错：</p>
<figure data-type="image" tabindex="37"><img src="E:%5Cnote%5C5-%E4%B8%AD%E9%97%B4%E4%BB%B6%5CRabbitMQ%5Cimage%5C80.jpg" alt="" loading="lazy"></figure>
<h3 id="02-单机多实例搭建">02 单机多实例搭建</h3>
<figure data-type="image" tabindex="38"><img src="E:%5Cnote%5C5-%E4%B8%AD%E9%97%B4%E4%BB%B6%5CRabbitMQ%5Cimage%5C81.jpg" alt="" loading="lazy"></figure>
<blockquote>
<p>启动第二个节点</p>
</blockquote>
<figure data-type="image" tabindex="39"><img src="E:%5Cnote%5C5-%E4%B8%AD%E9%97%B4%E4%BB%B6%5CRabbitMQ%5Cimage%5C82.jpg" alt="" loading="lazy"></figure>
<blockquote>
<p>验证启动</p>
</blockquote>
<pre><code class="language-shell">ps aux|grep rabbitmq
</code></pre>
<blockquote>
<p>rabbit-1操作作为主节点</p>
</blockquote>
<figure data-type="image" tabindex="40"><img src="E:%5Cnote%5C5-%E4%B8%AD%E9%97%B4%E4%BB%B6%5CRabbitMQ%5Cimage%5C83.jpg" alt="" loading="lazy"></figure>
<blockquote>
<p>rabbit-2操作作为从节点</p>
</blockquote>
<figure data-type="image" tabindex="41"><img src="E:%5Cnote%5C5-%E4%B8%AD%E9%97%B4%E4%BB%B6%5CRabbitMQ%5Cimage%5C84.jpg" alt="" loading="lazy"></figure>
<blockquote>
<p>验证集群状态</p>
</blockquote>
<figure data-type="image" tabindex="42"><img src="E:%5Cnote%5C5-%E4%B8%AD%E9%97%B4%E4%BB%B6%5CRabbitMQ%5Cimage%5C85.jpg" alt="" loading="lazy"></figure>
<blockquote>
<p>Web监控</p>
</blockquote>
<pre><code class="language-shell">rabbitmq-plugins enable rabbitmq_management
</code></pre>
<figure data-type="image" tabindex="43"><img src="E:%5Cnote%5C5-%E4%B8%AD%E9%97%B4%E4%BB%B6%5CRabbitMQ%5Cimage%5C86.jpg" alt="在这里插入图片描述" loading="lazy"></figure>
<blockquote>
<p>小结</p>
</blockquote>
<h2 id="5-分布式事务">5. 分布式事务</h2>
<h3 id="01-简述">01 简述</h3>
<p>分布式事务指事务的操作位于不同的节点上，需要保证事务的ACID特性。</p>
<p>例如在下单场景下，库存和订单如果不在同一个节点上，就涉及分布式事务</p>
<h3 id="02-分布式事务方式">02 分布式事务方式</h3>
<p>在分布式系统中，要实现分布式事务，无外乎哪几种解决方案。</p>
<p>####①两阶段提交（2PC）需要数据库严商</p>
<p>两阶段提交（Two-phase Commit，2PC），通过引协调者（coordinator）来协调参与者的行为，并最终决定这些参与者是否真正要执行事务。</p>
<h5 id="准备阶段">准备阶段</h5>
<p>协调者询问参与事务是否执行成功，参与者发回事务执行结果</p>
<p>#####提交阶段<br>
如果事务在每个参与者上都执行成功，事务协调者发送通知让参与者提交事务;否则，协调者发送通知让参与者回滚事务。<br>
需要注意的是，在准备阶段，参与者执行了事务，但是还未提交。只有在提交阶段接收到协调者发来的通知后，才进行提交或者回滚。</p>
<h5 id="存在的问题">存在的问题</h5>
<ol>
<li>同步阻塞所有事务参与者在等待其它参与者响应的时候都处于同步阻塞状态，无法进行其它操作。</li>
<li>单点问题协调者在2PC中起到非常大的作用，发生故障将会造成很大影响。特别是在阶段二发生故障，所有参与者会—直等待状态，无法完成其它操作。</li>
<li>数据不一致在阶段二，如果协调者只发送了部分Commit 消息，此时网络发生异常，那么只有部分参与者接收到Commit消息，也就是说只有部分参与者提交了事务，使得系统数据不一致。</li>
<li>太过保守任意一个节点失败就会导致整个事务失败，没有完善的容错机制。</li>
</ol>
<p>####②补偿事务（TCC）严选，阿里、蚂蚁金服</p>
<p>TCC 其实就是采用的补偿机制，其核心思想是:针对每个操作，都要注册一个与其对应的确认和补偿（撒销）操作。它分为三个阶段:</p>
<ul>
<li>Try阶段主要是对业务系统做检测及资源预留</li>
<li>Confirm阶段主要是对业务系统做确认提交，Try阶段执行成功并开始执行Confirm阶段时，默认---Confirm阶段是不会出错的。即:只要Try成功,Confirm一定成功。</li>
<li>Cancel阶段主要是在业务执行错误，需要回滚的状态下执行的业务取消，预留资源释放。</li>
</ul>
<p>举个例子，假入Bob要向Smith转账，思路大概是:我们有一个本地方法，里面依次调用</p>
<ol>
<li>首先在Try阶段，要先调用远程接口把Smith 和 Bob 的钱给冻结起来。</li>
<li>在 Confirm阶段，执行远程调用的转账的操作，转账成功进行解冻。</li>
<li>如果第2步执行成功，那么转账成功，如果第二步执行失败，则调用远程冻结接口对应的解冻方法(Cancel)。</li>
</ol>
<p>优点:跟2PC比起来，实现以及流程相对简单了一些，但数据的一致性比2PC也要差一些<br>
缺点:缺点还是比较明显的，在2,3步中都有可能失败。TCC属于应用层的一种补偿方式，所以需要程序员在实现的时候多写很多补偿的代码，在一些场景中，一些业务流程可能用TCC不太好定义及处理。</p>
<p>####③本地消息（异步确保）比如：支付宝、微信支付主动查询支付状态，对账单的形式</p>
<p>本地消息表与业务数据表处于同一个数据库中，这样就能利用本地事务来保证在对这两个表的操作满足事务特性，并且使用了消息队列来保证最终—致性。</p>
<ul>
<li>在分布式事务操作的一方完成写业务数据的操作之后向本地消息表发送一个消息，本地事务能保证这个消息一定会被写入本地消息表中。</li>
<li>之后将本地消息表中的消息转发到Kafka等消息队列中，如果转发成功则将消息从本地消息表中删除，否则继续重新转发。</li>
<li>在分布式事务操作的另一方从消息队列中读取一个消息，并执行消息中的操作。</li>
</ul>
<figure data-type="image" tabindex="44"><img src="E:%5Cnote%5C5-%E4%B8%AD%E9%97%B4%E4%BB%B6%5CRabbitMQ%5Cimage%5C90.jpg" alt="image-20210501231747242" loading="lazy"></figure>
<blockquote>
<p>优点：一种非常经典的实现，避免了分布式事务，实现了最终—致性。<br>
缺点：消息表会耦合到业务系统中，如果没有封装好的解决方案，会有很多杂活需要处理。</p>
</blockquote>
<p>####④MQ事务消息，异步场景，通用性较强，拓展性较高。</p>
<p>有一些第三方的MQ是支持事务消息的，比如RocketMQ，他们支持事务消息的方式也是类似于采用的二阶段提交，但是市面上一些主流的MQ都是不支持事务消息的，比如Kafka不支持。<br>
以阿里的RabbitMQ中间件为例，其思路大致为：</p>
<ul>
<li>第一阶段Prepared消息，会拿到消息的地址。第二阶段执行本地事务，第三阶段通过第一阶段拿到的地址去访问消息，并修改状态。<br>
也就是说在业务方法内要想消息队列提交两次请求，一次发送消息和一次确认消息。如果确认消息发送失败了，RabbitMQ会定期扫描消息集群中的事务消息，这时候发现了Prepared消息，它会向消息发送者确认，所以生产方需要实现一个check接口，RabbitMQ会根据发送端设置的第略来决定是回滚还是继续发送确认消息。这样就保证了消息发送与本地事务同时成功或同时失败。</li>
</ul>
<figure data-type="image" tabindex="45"><img src="E:%5Cnote%5C5-%E4%B8%AD%E9%97%B4%E4%BB%B6%5CRabbitMQ%5Cimage%5C91.jpg" alt="image-20210501232113553" loading="lazy"></figure>
<p>优点：实现了最终一致性，不需要依赖本地数据库事务。<br>
缺点：实现难度大，主流MQ不支持，RocketMQ事务消息部分代码也未开源。</p>
<h4 id="5总结">⑤总结</h4>
<p>通过本文我们总结并对比了几种分布式分解方案的优缺点，分布式事务本身是一个技术难题，是没有一种完美的方案应对所有场景的，具体还是要根据业务场景去抉择吧。阿里RocketMQ去实现的分布式事务，现在也有除了很多分布式事务的协调器，比如LCN等，大家可以多去尝试。</p>
<h3 id="具体实现">具体实现</h3>
<p>分布式事务的完整架构图</p>
<figure data-type="image" tabindex="46"><img src="E:%5Cnote%5C5-%E4%B8%AD%E9%97%B4%E4%BB%B6%5CRabbitMQ%5Cimage%5C92.jpg" alt="" loading="lazy"></figure>
<figure data-type="image" tabindex="47"><img src="E:%5Cnote%5C5-%E4%B8%AD%E9%97%B4%E4%BB%B6%5CRabbitMQ%5Cimage%5C93.jpg" alt="" loading="lazy"></figure>
<p>####①系统与系统之间的分布式事问题</p>
<figure data-type="image" tabindex="48"><img src="E:%5Cnote%5C5-%E4%B8%AD%E9%97%B4%E4%BB%B6%5CRabbitMQ%5Cimage%5C94.jpg" alt="" loading="lazy"></figure>
<p>####②系统间调用过程中事务回滚问题</p>
<pre><code class="language-java">package com.xuexiangban .rabbitmq.service;2.
import com.xuexiangban.rabbitmq.dao.orderDataBaseService;
import com.xuexiangban.rabbitmq.pojo.Order;
import org.springframework.beans.factory .annotation.Autowired;
import org.springframework.http.client.SimpleclientHttpRequestFactory;
import org.springframework.stereotype. Service;
import org.springframework.transaction.annotation.Transactional;
import org.springframework.web.client.RestTemplate;

public class OrderService {
    @Autowired
    private OrderDataBaseService orderDataBaseservice;
    //创建订单
    @Transactional(rollbackFor = Exception.class)//订单创建整个方法添加事务
    public void createOrder(Order orderInfo) throws Exception {
        // 1:订单信息--插入丁订单系统，订单数据库事务orderDataBaseService.saveOrder(orderInfo);
        //2∶通通Http接口发途订单信息到运单系统
        String result = dispatchHttpApi(orderInfo.getorderId());
            if( !&quot;success&quot;.equals(result)) {
            throw new Exception(&quot;订单创建失败,原因是运单接口调用失败!&quot;);
        }
    }
    /**
    * 模拟http请求接口发途，运单系统，将订单号传过去 springcloud
    */
    private String dispatchHttpApi(String orderId){
        SimpleclientHttpRehyuestFactory factory - new SimpleClientHttpRequestFactory();
                //链接超时&gt;3秒
        factory .setConnectTimeout ( 300e) ;
        //处理超时&gt;2秒
         factory .setReadTimeout ( 2000) ;
                //发送http请求
        String url = &quot;http: / /localhost:9000/dispatch/order?orderId=&quot;+orderId;
                RestTemplate restTemplate = new RestTemplate(factory);//异常
        String result = restTemplate.getForobject(url，string.class);
                return result;
    }
}
</code></pre>
<p>####③基于MQ的分布式事务整体设计思路</p>
<figure data-type="image" tabindex="49"><img src="E:%5Cnote%5C5-%E4%B8%AD%E9%97%B4%E4%BB%B6%5CRabbitMQ%5Cimage%5C95.jpg" alt="" loading="lazy"></figure>
<p>####④基于MQ的分布式事务消息的可靠生产问题-定时重发</p>
<p>如果这个时候MQ服务器出现了异常和故障，那么消息是无法获取到回执信息。怎么解决呢?</p>
<p>####⑤基于MQ的分布式事务消息的可靠消费</p>
<p>####⑥基于MQ的分布式事务消息的消息重发</p>
<p>解决消息重试的集中方案</p>
<ol>
<li>控制重发的次数</li>
<li>try+catch+手动ack</li>
<li>try+catch+手动ack +死信队列处理</li>
</ol>
<p>####⑦基于MQ的分布式事务消息的死信队列消息转移+人工处理</p>
<p>如果死信队列报错就进行人工处理</p>
<p>####⑧基于MQ的分布式事务消息的死信队列消息重试注意事项</p>
<p>####⑨基于MQ的分布式事务消息的定式重发</p>
<h3 id="总结">总结</h3>
<p>####①基于MQ的分布式事务解决方案优点：</p>
<ol>
<li>通用性强</li>
<li>拓展方便</li>
<li>耦合度低,方案也比较成熟</li>
</ol>
<p>####②基于MQ的分布式事务解决方案缺点：</p>
<ol>
<li>基于消息中间件,只适合异步场景</li>
<li>消息会延迟处理，需要业务上能够容忍</li>
</ol>
<p>####③建议</p>
<ol>
<li>尽量去避免分布式事务</li>
<li>尽量将非核心业务做成异步</li>
</ol>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Redis]]></title>
        <id>https://lindamao.cn/post/redis/</id>
        <link href="https://lindamao.cn/post/redis/">
        </link>
        <updated>2021-03-11T06:13:43.000Z</updated>
        <content type="html"><![CDATA[<h2 id="介绍一下-redis">介绍⼀下 Redis</h2>
<p>简单来说 <strong>Redis 就是⼀个使⽤ C 语⾔开发的数据库</strong>，不过与传统数据库不同的是 <strong>Redis 的数据</strong>是存在内存中的 ，也就是它是内存数据库，所以读写速度⾮常快，因此 Redis 被⼴泛应⽤于缓存⽅向。</p>
<p>另外，<strong>Redis 除了做缓存之外，Redis 也经常⽤来做分布式锁，甚⾄是消息队列</strong>。</p>
<p><strong>Redis 提供了多种数据类型来⽀持不同的业务场景。Redis 还⽀持事务 、持久化、Lua 脚本、多种集群⽅案。</strong></p>
<h2 id="分布式缓存常的技术选型方案有哪些">分布式缓存常⻅的技术选型⽅案有哪些？</h2>
<p>分布式缓存的话，使⽤的比较多的主要是 Memcached 和 Redis。不过，现在基本没有看过还有项⽬使⽤ Memcached 来做缓存，都是直接⽤ Redis。</p>
<p>Memcached 是分布式缓存最开始兴起的那会，比较常⽤的。后来，随着 Redis 的发展，⼤家慢慢都转⽽使⽤更加强⼤的 Redis 了。</p>
<p>分布式缓存主要解决的是单机缓存的容量受服务器限制并且⽆法保存通⽤的信息。因为，本地缓存只在当前服务⾥有效，⽐如你部署了两个相同的服务，他们两者之间的缓存数据是⽆法共同的。</p>
<h2 id="说一下-redis-和-memcached-的区别和共同点">说⼀下 Redis 和 Memcached 的区别和共同点</h2>
<p>现在公司⼀般都是⽤ Redis 来实现缓存，⽽且 Redis ⾃身也越来越强⼤了！不过，了解 Redis 和<br>
Memcached 的区别和共同点，有助于我们在做相应的技术选型的时候，能够做到有理有据！<br>
<strong>共同点 ：</strong></p>
<ol>
<li>都是基于内存的数据库，⼀般都⽤来当做缓存使⽤。</li>
<li>都有过期策略。</li>
<li>两者的性能都⾮常⾼。</li>
</ol>
<p><strong>区别 ：</strong></p>
<ol>
<li>Redis ⽀持更丰富的数据类型（<strong>⽀持更复杂的应⽤场景</strong>）。Redis 不仅仅⽀持简单的 k/v 类型的数据，同时还提供 list，set，zset，hash 等数据结构的存储。Memcached 只⽀持最简单的 k/v 数据类型。</li>
<li><strong>Redis ⽀持数据的持久化</strong>，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进⾏使⽤,⽽ Memecache 把数据全部存在内存之中。</li>
<li>Redis <strong>有灾难恢复机制</strong>。 因为可以把缓存中的数据持久化到磁盘上。</li>
<li>Redis 在服务器内存使⽤完之后，可以将不⽤的数据放到磁盘上。但是，Memcached 在服务器内存使⽤完之后，就会直接报异常。</li>
<li>Memcached 没有原⽣的集群模式，需要依靠客户端来实现往集群中分⽚写⼊数据；但是Redis ⽬前是<strong>原⽣⽀持 cluster 模式</strong>的.</li>
<li>Memcached 是<strong>多线程，⾮阻塞 IO 复⽤的⽹络模型</strong>；Redis 使⽤<strong>单线程的多路 IO 复⽤模型</strong>。 （Redis 6.0 引⼊了多线程 IO ）</li>
<li>Redis <strong>⽀持发布订阅模型、Lua 脚本、事务</strong>等功能，⽽ Memcached 不⽀持。并且，Redis⽀持更多的编程语⾔。</li>
<li>Memcached过期数据的删除策略只⽤了惰性删除，⽽ Redis 同时使⽤了<strong>惰性删除与定期删除</strong>。</li>
</ol>
<p><strong>更推荐Redis作为分布式的缓存</strong></p>
<h2 id="缓存数据的处理流程是怎样的">缓存数据的处理流程是怎样的？</h2>
<p>流程图：</p>
<ol>
<li>如果⽤户请求的数据在缓存中就直接返回。</li>
<li>缓存中不存在的话就看数据库中是否存在。</li>
<li>数据库中存在的话就更新缓存中的数据。</li>
<li>数据库中不存在的话就返回空数</li>
</ol>
<figure data-type="image" tabindex="1"><img src="D:%5Cnote%5C%E9%9D%A2%E8%AF%95%5C%E9%9D%A2%E8%AF%95.assets%5Cimage-20230203111116721.png" alt="image-20230203111116721" loading="lazy"></figure>
<h2 id="为什么要用-redis为什么要用缓存">为什么要⽤ Redis/为什么要⽤缓存？</h2>
<figure data-type="image" tabindex="2"><img src="D:%5Cnote%5C%E9%9D%A2%E8%AF%95%5C%E9%9D%A2%E8%AF%95.assets%5Cimage-20230203111135947.png" alt="image-20230203111135947" loading="lazy"></figure>
<p><strong>针对高性能和高并发出发</strong></p>
<p><strong>⾼性能 ：</strong></p>
<p>假如⽤户第⼀次访问数据库中的某些数据的话，这个过程是⽐᫾慢，毕竟是从硬盘中读取的。但是，如果说，⽤户访问的数据属于⾼频数据并且不会经常改变的话，那么我们就可以很放⼼地将该⽤户访问的数据存在缓存中。<strong>这样有什么好处</strong>呢？ 那就是保证⽤户下⼀次再访问这些数据的时候就可以直接从缓存中获取了。</p>
<p>操作缓存就是<strong>直接操作内存，所以速度相当快</strong>。</p>
<p>不过，要保持数据库和缓存中的数据的⼀致性。 如果数据库中的对应数据改变的之后，<strong>同步改变缓存中相应的数据即可</strong>！</p>
<p><strong>⾼并发：</strong></p>
<p>⼀般像 MySQL 这类的数据库的 QPS ⼤概都在 1w 左右（4 核 8g） ，但是使⽤ Redis 缓存之后很容易达到 10w+，甚⾄最⾼能达到 30w+（就单机 redis 的情况，redis 集群的话会更⾼）。</p>
<p><strong>QPS（Query Per Second）：服务器每秒可以执⾏的查询次数</strong></p>
<p>所以，直接操作缓存能够承受的数据库请求数量是远远⼤于直接访问数据库的，所以我们可以考虑把数据库中的部分数据转移到缓存中去，这样⽤户的⼀部分请求会直接到缓存这⾥⽽不⽤经过数据库进⽽我们也就提⾼的系统整体的</p>
<h2 id="io模型">IO模型</h2>
<p>https://zhuanlan.zhihu.com/p/115912936</p>
<h2 id="io多路复用机制">IO多路复用机制</h2>
<p>https://blog.csdn.net/sehanlingfeng/article/details/78920423</p>
<h2 id="bionioaio-有什么区别"><strong>BIO,NIO,AIO 有什么区别?</strong></h2>
<p><strong>BIO (Blocking I/O): 同步阻塞 I/O 模式</strong>，<strong>数据的读取写⼊必须阻塞在⼀个线程内等待其完成</strong>。在活动连接数不是特别⾼（⼩于单机 1000）的情况下，这种模型是比较不错的，可以让每⼀个连接专注于⾃⼰的 I/O 并且编程模型简单，也不⽤过多考虑系统的过载、限流等问题。线程池本身就是⼀个天然的漏⽃，可以缓冲⼀些系统处理不了的连接或请求。但是，当⾯对⼗万甚⾄百万级连接的时候，传统的 BIO 模型是⽆能为⼒的。因此，我们需要⼀种更⾼效的 I/O 处理模型来应对更⾼的并发量。</p>
<p><strong>NIO (Non-blocking/New I/O): NIO 是⼀种同步⾮阻塞的 I/O 模型</strong>，在 Java 1.4 中引⼊了NIO 框架，对应 java.nio 包，提供了 <strong>Channel</strong> , <strong>Selector</strong>，Buffer 等抽象。NIO 中的 N 可以理解为 Non-blocking，不单纯是 New。它⽀持<strong>⾯向缓冲</strong>的，基于通道的 I/O 操作⽅法。</p>
<p>NIO 提供了与传统 BIO 模型中的 Socket 和 ServerSocket 相对应的 SocketChannel 和ServerSocketChannel 两种不同的套接字通道实现,两种通道都⽀持阻塞和⾮阻塞两种模式。阻塞模式使⽤就像传统中的⽀持⼀样，比较简单，但是性能和可靠性都不好；⾮阻塞模式正好与之相反。对于低负载、低并发的应⽤程序，可以使⽤同步阻塞 I/O 来提升开发速率和更好的维护性；对于⾼负载、⾼并发的（⽹络）应⽤，应使⽤ NIO 的⾮阻塞模式来开发</p>
<p><strong>AIO (Asynchronous I/O): AIO 也就是 NIO 2</strong>。在 Java 7 中引⼊了 NIO 的改进版 NIO 2,它是<strong>异步⾮阻塞的 IO 模型</strong>。异步 IO 是<strong>基于事件和回调机制实现</strong>的，也就是应⽤操作之后会直接返回，不会堵塞在那⾥，当后台处理完成，操作系统会通知相应的线程进⾏后续的操作。<br>
AIO 是异步 IO 的缩写，<strong>虽然 NIO 在⽹络操作中，提供了⾮阻塞的⽅法，但是 NIO 的 IO ⾏为还是同步的</strong>。对于 NIO 来说，我们的业务线程是在 IO 操作准备好时，得到通知，接着就由这个线程⾃⾏进⾏ IO 操作，IO 操作本身是同步的。查阅⽹上相关资料，我发现就⽬前来说 AIO 的应⽤还不是很⼴泛，Netty 之前也尝试使⽤过 AIO，不过⼜放弃了</p>
<p><strong>NIO与BIO区别</strong></p>
<ul>
<li>通讯方式：NIO 通过<strong>Channel（通道）</strong> 进行读写，通道是<strong>双向</strong>的，可读也可写。而BIO使用的<strong>流读写是单向</strong>的。</li>
<li>BIO流是阻塞的，NIO流是不阻塞的。</li>
<li><strong>BIO 面向流(Stream oriented)</strong>，<strong>而 NIO 面向缓冲区(Buffer oriented)</strong>。
<ol>
<li>在面向流的I/O中·可以将数据直接写入或者将数据直接读到 Stream 对象中。<strong>虽然 Stream 中也有 Buffer 开头的扩展类，但只是流的包装类，还是从流读到缓冲区</strong>，而 NIO 却是<strong>直接读到 Buffer 中进行操作</strong>。</li>
<li>在NIO厍中，所有数据都是用缓冲区处理的。在读取数据时，它是直接读到缓冲区中的; 在写入数据时，写入到缓冲区中。<strong>任何时候访问NIO中的数据，都是通过缓冲区进行操作</strong>。</li>
</ol>
</li>
</ul>
<p>NIO 带来了什么</p>
<ul>
<li><strong>避免多线程</strong></li>
<li><strong>非阻塞I/O，I/O读写不再阻塞，而是返回0</strong></li>
<li>单线程处理多任务</li>
<li>基于block的传输，通常比基于流的传输更高效</li>
<li>更高级的IO函数，zero-copy</li>
<li><strong>事件驱动模型</strong></li>
<li><strong>IO多路复用大大提高了Java网络应用的可伸缩性和实用性</strong></li>
</ul>
<h2 id="redis-常数据结构以及使用场景分析">Redis 常⻅数据结构以及使⽤场景分析</h2>
<h3 id="string"><strong>String</strong></h3>
<p>​	1.<strong>介绍</strong> ：string 数据结构是简单的 key-value 类型。虽然 Redis 是⽤ C 语⾔写的，但是 Redis并没有使⽤ C 的字符串表示，⽽是⾃⼰构建了⼀种 简单动态字符串（simple dynamicstring，SDS）。相⽐于 C 的原⽣字符串，Redis 的 SDS 不光可以保存⽂本数据还可以保存<br>
⼆进制数据，并且获取字符串⻓度复杂度为 O(1)（C 字符串为 O(N)）,除此之外,Redis 的SDS API 是安全的，不会造成缓冲区溢出。</p>
<ol start="2">
<li><strong>常⽤命令</strong>: set,get,strlen,exists,dect,incr,setex 等等。</li>
<li><strong>应⽤场景</strong> ：⼀般常⽤在需要<strong>计数的场景</strong>，⽐如⽤户的访问次数、热点⽂章的点赞转发数量等，共享用户session。<br>
等。</li>
<li>.redis 的 string 类型存储的限制为<strong>512M</strong></li>
</ol>
<h3 id="list">list</h3>
<ol>
<li><strong>介绍</strong> ：list 即是 链表。链表是⼀种⾮常常⻅的数据结构，特点是易于数据元素的插⼊和删除并且且可以灵活调整链表⻓度，但是链表的随机访问困难。许多⾼级编程语⾔都内置了链表的实现⽐如 Java 中的 <strong>LinkedList</strong>，但是 C 语⾔并没有实现链表，所以 Redis 实现了⾃⼰的链表数据结构。Redis 的 list 的实现为⼀个 <strong>双向链表</strong>，即可以⽀持<strong>反向查找和遍历</strong>，更⽅便操作，不过带来了部分额外的内存开销。</li>
<li><strong>常⽤命令</strong>: rpush,lpop,lpush,rpop,lrange.llen 等。</li>
<li><strong>应⽤场景</strong>: <strong>发布与订阅或者说消息队列、慢查询</strong>。</li>
</ol>
<h3 id="hash">hash</h3>
<ol>
<li><strong>介绍</strong> ：hash 类似于 JDK1.8 前的 HashMap，内部实现也差不多(数组 + 链表)。不过，Redis 的 hash 做了更多优化。另外，<strong>hash 是⼀个 string 类型的 field 和 value 的映射表，特别适合⽤于存储对象，后续操作的时候，你可以直接仅仅修改这个对象中的某个字段的值。</strong> ⽐如我们可以 hash 数据结构来存储<strong>⽤户信息，商品信息</strong>等等。</li>
<li><strong>常⽤命令</strong>： hset,hmset,hexists,hget,hgetall,hkeys,hvals 等。</li>
<li><strong>应⽤场景:</strong> 系统中对象数据的存储。</li>
</ol>
<h3 id="set">set</h3>
<ol>
<li><strong>介绍</strong> ： set 类似于 Java 中的 HashSet 。Redis 中的 set 类型是⼀种⽆序集合，集合中的元素没有先后顺序。当你需要存储⼀个列表数据，⼜不希望出现重复数据时，set 是⼀个很好的选择，并且 set 提供了判断某个成员是否在⼀个 set 集合内的重要接⼝，这个也是 list 所不能提供的。可以基于 set 轻易实现交集、并集、差集的操作。</li>
<li>⽐如：你可以将⼀个⽤户所有的关注⼈存在⼀个集合中，将其所有粉丝存在⼀个集合。Redis 可以⾮常⽅便的实现如共同关注、共同粉丝、共同喜好等功能。这个过程也就是求交集的过程。</li>
<li><strong>常⽤命令</strong>： sadd,spop,smembers,sismember,scard,sinterstore,sunion 等。<br>
3. <strong>应⽤场景:</strong> 需要存放的数据不能重复以及需要获取多个数据源交集和并集等场景 例如：在微博应⽤中，可以将⼀个⽤户所有的关注⼈存在⼀个集合中，将其所有粉丝存在⼀个集合。Redis可以⾮常⽅便的实现如<strong>共同关注、共同粉丝、共同喜好</strong>等功能。这个过程也就是求交集的过程，</li>
</ol>
<h3 id="sorted-set">sorted set</h3>
<ol>
<li><strong>介绍</strong>： 和 set 相⽐，sorted set 增加了⼀个权重参数 score，使得集合中的元素能够按 score进⾏有序排列，还可以通过 score 的范围来获取元素的列表。有点像是 Java 中 HashMap和 TreeSet 的结合体。</li>
<li><strong>常⽤命令</strong>： zadd,zcard,zscore,zrange,zrevrange,zrem 等。</li>
<li><strong>应⽤场景：</strong> 需要对数据根据某个权重进⾏排序的场景，比如微博热搜，做带权重的队列⽐如在直播系统中，实时排⾏信息包含直播间<strong>在线⽤户列表，各种礼物排⾏榜，弹幕消息</strong>（可以理解为按消息维度的消息排⾏榜）等信息 。</li>
</ol>
<h2 id="redis线程">Redis线程</h2>
<h3 id="redis单线程原理">Redis单线程原理</h3>
<p>首先必须明确，Redis单线程指的是网络请求模块使用了一个线程（，其他模块仍用了多个线程。并不是一个线程完成了所有功能。原理上，其采用了利用epoll的多路复用特性，因此可以采用单线程处理其网络请求。</p>
<h3 id="redis-单线程模型详解">Redis 单线程模型详解</h3>
<p><strong>Redis 基于 Reactor 模式来设计开发了⾃⼰的⼀套⾼效的事件处理模型</strong> （Netty 的线程模型也基于 Reactor 模式，Reactor 模式不愧是⾼性能 IO 的基⽯），这套事件处理模型对应的是 Redis中的<strong>⽂件事件处理器</strong>（file event handler）。由于⽂件事件处理器（file event handler）是单线程⽅式运⾏的，所以我们⼀般都说 Redis 是单线程模型。</p>
<p><strong>既然是单线程，那怎么监听⼤量的客户端连接呢？</strong></p>
<p>Redis 通过<strong>IO 多路复⽤程序</strong> 来监听来⾃客户端的⼤量连接（或者说是监听多个 socket），它会将感兴趣的事件及类型(读、写）注册到内核中并监听每个事件是否发⽣。</p>
<p>这样的好处⾮常明显： <strong>I/O 多路复⽤技术的使⽤让 Redis 不需要额外创建多余的线程来监听客户端的⼤量连接，降低了资源的消耗</strong>（和 NIO 中的 Selector 组件很像）。</p>
<p>另外， Redis 服务器是⼀个事件驱动程序，服务器需要处理两类事件： 1. ⽂件事件; 2. 时间事件。</p>
<p>时间事件不需要多花时间了解，我们接触最多的还是 ⽂件事件（<strong>客户端进⾏读取写⼊等操作，涉及⼀系列⽹络通信</strong>）。</p>
<pre><code>Redis 基于 Reactor 模式开发了⾃⼰的⽹络事件处理器：这个处理器被称为⽂件事件处理器（file event handler）。⽂件事件处理器使⽤ I/O 多路复⽤（multiplexing）程序来同时监听多个套接字，并根据 套接字⽬前执⾏的任务来为套接字关联不同的事件处理器。当被监听的套接字准备好执⾏连接应答（accept）、读取（read）、写⼊（write）、关 闭（close）等操作时，与操作相对应的⽂件事件就会产⽣，这时⽂件事件处理器就会调⽤套接字之前关联好的事件处理器来处理这些事件。虽然⽂件事件处理器以单线程⽅式运⾏，但通过使⽤ I/O 多路复⽤程序来监听多个套接字，⽂件事件处理器既实现了⾼性能的⽹络通信模型，⼜可以很好地与 Redis 服务器中其他同样以单线程⽅式运⾏的模块进⾏对接，这保持了 Redis 内部单线程设计的简单性。
</code></pre>
<p>可以看出，⽂件事件处理器（file event handler）主要是包含 4 个部分：</p>
<ul>
<li>
<p>多个 socket（客户端连接）</p>
</li>
<li>
<p>IO 多路复⽤程序（⽀持多个客户端连接的关键）</p>
</li>
<li>
<p>⽂件事件分派器（将 socket 关联到相应的事件处理器）</p>
</li>
<li>
<p>事件处理器（连接应答处理器、命令请求处理器、命令回复处理器）</p>
<figure data-type="image" tabindex="3"><img src="D:%5Cnote%5C%E9%9D%A2%E8%AF%95%5C%E9%9D%A2%E8%AF%95.assets%5Cimage-20230203111214293.png" alt="image-20230203111214293" loading="lazy"></figure>
</li>
</ul>
<h3 id="redis-没有使用多线程为什么不使用多线程">Redis 没有使⽤多线程？为什么不使⽤多线程</h3>
<p>虽然说 Redis 是单线程模型，但是， 实际上，Redis 在 4.0 之后的版本中就已经加⼊了对多线程的支持</p>
<p>不过，Redis 4.0 增加的多线程主要是针对⼀些⼤键值对的删除操作的命令，使⽤这些命令就会使⽤主处理之外的其他线程来“异步处理”。<br>
⼤体上来说，Redis 6.0 之前主要还是**单线程处理。**那，Redis6.0 之前 为什么不使⽤多线程？<br>
主要原因：</p>
<ol>
<li>单线程编程容易并且更<strong>容易维护</strong>；</li>
<li>Redis的性能瓶颈不在 <strong>CPU</strong> ，主要在<strong>内存和⽹络</strong>；</li>
<li>多线程就会存在<strong>死锁、线程上下⽂切换</strong>等问题，甚⾄<strong>会影响性能</strong>。</li>
</ol>
<h3 id="redis60-之后为何引入了多线程">Redis6.0 之后为何引⼊了多线程？</h3>
<p>Redis6.0 引⼊多线程主要是为了提⾼⽹络 IO 读写性能，因为这个算是 Redis 中的⼀个性能瓶颈（Redis 的瓶颈主要受限于内存和⽹络）。</p>
<p>虽然，Redis6.0 引⼊了多线程，但是 Redis 的<strong>多线程只是在⽹络数据的读写</strong>这类耗时操作上使⽤了， <strong>执⾏命令仍然是单线程顺序执⾏</strong>。因此，你也不需要担⼼线程安全问题。</p>
<p>Redis6.0 的<strong>多线程默认是禁⽤的</strong>，只使⽤主线程。如需开启需要修改 <strong>redis</strong> 配置⽂件 <strong>redis.conf</strong></p>
<figure data-type="image" tabindex="4"><img src="D:%5Cnote%5C%E9%9D%A2%E8%AF%95%5C%E9%9D%A2%E8%AF%95.assets%5Cimage-20230203111239352.png" alt="image-20230203111239352" loading="lazy"></figure>
<p>开启多线程后还需要设置线程数否则是不⽣效的。同样需要修改 redis 配置⽂件 <strong>redis.conf :</strong></p>
<figure data-type="image" tabindex="5"><img src="D:%5Cnote%5C%E9%9D%A2%E8%AF%95%5C%E9%9D%A2%E8%AF%95.assets%5Cimage-20230203111247809.png" alt="image-20230203111247809" loading="lazy"></figure>
<p>参考连接：https://mp.weixin.qq.com/s/FZu3acwK6zrCBZQ_3HoUgw</p>
<p>​				   https://draveness.me/whys-the-design-redis-single-thread/</p>
<h2 id="redis多线程">Redis多线程</h2>
<p>https://blog.csdn.net/lizhengze1117/article/details/108032406</p>
<h2 id="什么情况下使用redis">什么情况下使用redis</h2>
<p>https://blog.csdn.net/qq_35190492/article/details/103105780</p>
<ol>
<li>针对热点数据进行缓存</li>
<li>对于特定限时数据的存放</li>
<li>针对带热点权值数据的<a href="https://www.nowcoder.com/jump/super-jump/word?word=%E6%8E%92%E5%BA%8F">排序</a>list</li>
<li>分布式锁</li>
</ol>
<h2 id="为什么要给redis缓存数据设置过期时间">为什么要给Redis缓存数据设置过期时间</h2>
<p>因为内存是有限的，如果缓存中的所有数据都是⼀直保存的话，分分钟直接**Out of memory。**Redis ⾃带了给缓存数据设置过期时间的功能，⽐如：</p>
<figure data-type="image" tabindex="6"><img src="D:%5Cnote%5C%E9%9D%A2%E8%AF%95%5C%E9%9D%A2%E8%AF%95.assets%5Cimage-20230203111259581.png" alt="image-20230203111259581" loading="lazy"></figure>
<p>注意：Redis中除了字符串类型有⾃⼰独有设置过期时间的命令 <strong>setex</strong> 外，其他⽅法都需要依靠<strong>expire</strong> 命令来设置过期时间 。另外， persist 命令可以移除⼀个键的过期时间<br>
<strong>过期时间除了有助于缓解内存的消耗，还有什么其他⽤么？</strong></p>
<p><strong>验证码有效时间 token有效时间</strong></p>
<p>很多时候，我们的业务场景就是需要某个数据只在某⼀时间段内存在，⽐如我们的短信验证码可能只在1分钟内有效，⽤户登录的 token 可能只在 1 天内有效。如果使⽤传统的数据库来处理的话，⼀般都是⾃⼰判断过期，这样更麻烦并且<strong>性能</strong>要差很多。</p>
<p><strong>避免数据库和缓存的不一致</strong></p>
<p><strong>设置缓存过期时间当缓存当中的值失效了之后就会到数据库当中去更新数据</strong></p>
<h2 id="redis是如何判断数据是否过期">Redis是如何判断数据是否过期</h2>
<p>Redis 通过⼀个叫做<strong>过期字典</strong>（可以看作是hash表）来保存数据过期的时间。过期字典的键指向<br>
Redis数据库中的某个key(键)，过期字典的值是⼀个long long类型的整数，这个整数保存了key所<br>
指向的数据库键的过期时间（毫秒精度的UNIX时间戳）。</p>
<figure data-type="image" tabindex="7"><img src="D:%5Cnote%5C%E9%9D%A2%E8%AF%95%5C%E9%9D%A2%E8%AF%95.assets%5Cimage-20230203111310626.png" alt="image-20230203111310626" loading="lazy"></figure>
<p><strong>过期字典</strong>是存储在redisDb这个结构⾥的：</p>
<figure data-type="image" tabindex="8"><img src="D:%5Cnote%5C%E9%9D%A2%E8%AF%95%5C%E9%9D%A2%E8%AF%95.assets%5Cimage-20230203111320481.png" alt="image-20230203111320481" loading="lazy"></figure>
<h2 id="过期的数据的删除策略">过期的数据的删除策略</h2>
<p>如果假设你设置了⼀批 key 只能存活 1 分钟，那么 1 分钟后，Redis 是怎么对这批 key 进⾏删除的呢？<br>
常⽤的过期数据的删除策略就两个（重要！⾃⼰造缓存轮⼦的时候需要格外考虑的东⻄）：</p>
<ol>
<li>
<p><strong>惰性删除</strong> ：只会在取出key的时候才对数据进⾏过期检查。这样对CPU最友好，但是可能会造成太多过期 key 没有被删除。</p>
</li>
<li>
<p><strong>定期删除</strong> ： 每隔⼀段时间抽取⼀批 key 执⾏删除过期key操作。并且，Redis 底层会通过限制删除操作执⾏的时⻓和频率来减少删除操作对CPU时间的影响。<br>
定期删除对内存更加友好，惰性删除对CPU更加友好。两者各有千秋，所以Redis 采⽤的是 定期删除+惰性/懒汉式删除 。<br>
但是，仅仅通过给 key 设置过期时间还是有问题的。因为还是可能存在定期删除和惰性删除漏掉了很多过期 key 的情况。这样就导致⼤量过期 key 堆积在内存⾥，然后就Out of memory了。</p>
<p>怎么解决这个问题呢？答案就是： <strong>Redis 内存淘汰机制。</strong></p>
</li>
</ol>
<h2 id="redis-内存淘汰机制">Redis 内存淘汰机制</h2>
<p><strong>相关问题</strong>：MySQL ⾥有 2000w 数据，Redis 中只存 20w 的数据，如何保证 Redis 中的数据都是热点数据?</p>
<p><strong>Redis 提供 6 种数据淘汰策略：</strong></p>
<ol>
<li>volatile-lru（least recently used）：从已设置过期时间的数据集（server.db[i].expires）中挑选<strong>最近最少使⽤</strong>的数据淘汰</li>
<li>volatile-ttl：从已设置过期时间的数据集（server.db[i].expires）中挑选<strong>将要过期</strong>的数据淘汰</li>
<li>volatile-random：从已设置过期时间的数据集（server.db[i].expires）中<strong>任意选择数据淘汰</strong></li>
<li>allkeys-lru（least recently used）：当内存不⾜以容纳新写⼊数据时，在键空间中，移除<br>
最近最少使⽤的 key（这个是最常⽤的）</li>
<li>allkeys-random：从数据集（server.db[i].dict）中任意选择数据淘汰</li>
<li>no-eviction：禁⽌驱逐数据，也就是说当内存不⾜以容纳新写⼊数据时，新写⼊操作会报错。这个应该没⼈使⽤吧！<br>
4.0 版本后增加以下两种：</li>
<li>volatile-lfu（least frequently used）：<strong>从已设置过期时间的数据集(server.db[i].expires)中挑选最不经常使⽤的数据淘汰</strong></li>
<li>allkeys-lfu（least frequently used）：<strong>当内存不⾜以容纳新写⼊数据时，在键空间中，移除最不经常使⽤的 key</strong></li>
</ol>
<h2 id="redis-持久化机制">Redis 持久化机制</h2>
<p><strong>(怎么保证 Redis 挂掉之后再重启数据可以进⾏恢复)</strong></p>
<p>很多时候我们需要持久化数据也就是将内存中的数据写⼊到硬盘⾥⾯，⼤部分原因是为了之后重⽤数据（⽐如重启机器、机器故障之后恢复数据），或者是为了防⽌系统故障⽽将数据备份到个远程位置。Redis 不同于 Memcached 的很重要⼀点就是，Redis ⽀持持久化，⽽且⽀持两种不同的持久化操作。Redis 的⼀种持久化⽅式叫快照（snapshotting，<strong>RDB</strong>），另⼀种⽅式是只追加⽂件append-only file, （<strong>AOF</strong>）。这两种⽅法各有千秋，下⾯我会详细这两种持久化⽅法是什么，么⽤，如何选择适合⾃⼰的持久化⽅法。<br>
<strong>快照（snapshotting）持久化（RDB)</strong><br>
Redis 可以通过创建快照来获得存储在内存⾥⾯的数据在某个时间点上的副本。Redis 创建快照之后，可以对快照进⾏备份，可以将快照复制到其他服务器从⽽创建具有相同数据的服务器副本（<strong>Redis 主从结构，主要⽤来提⾼ Redis 性能</strong>），还可以将快照留在原地以便重启服务器的时候使⽤。</p>
<p>快照持久化RDB是 **Redis 默认采⽤的持久化⽅式，**在 Redis.conf 配置⽂件中默认有此下配置：</p>
<figure data-type="image" tabindex="9"><img src="D:%5Cnote%5C%E9%9D%A2%E8%AF%95%5C%E9%9D%A2%E8%AF%95.assets%5Cimage-20230203111331829.png" alt="image-20230203111331829" loading="lazy"></figure>
<p><strong>AOF（append-only file）持久化</strong></p>
<p>与快照持久化相⽐，AOF 持久化 的<strong>实时性</strong>更好，因此已成为主流的持久化⽅案。默认情况下Redis 没有开启 AOF（append only file）⽅式的持久化，可以通过 appendonly 参数开启：</p>
<figure data-type="image" tabindex="10"><img src="D:%5Cnote%5C%E9%9D%A2%E8%AF%95%5C%E9%9D%A2%E8%AF%95.assets%5Cimage-20230203111338949.png" alt="image-20230203111338949" loading="lazy"></figure>
<p>开启 AOF 持久化后每执⾏⼀条会更改 Redis 中的数据的命令，Redis 就会将该命令写⼊硬盘中的 AOF ⽂件。AOF ⽂件的保存位置和 RDB ⽂件的位置相同，都是通过 dir 参数设置的，默认的<br>
⽂件名是 **appendonly.aof。**在 Redis 的配置⽂件中存在三种不同的 AOF 持久化⽅式，它们分别是：</p>
<figure data-type="image" tabindex="11"><img src="D:%5Cnote%5C%E9%9D%A2%E8%AF%95%5C%E9%9D%A2%E8%AF%95.assets%5Cimage-20230203111346448.png" alt="image-20230203111346448" loading="lazy"></figure>
<p>为了兼顾数据和写⼊性能，⽤户可以考虑 <strong>appendfsync everyse</strong>c 选项 ，让 Redis 每秒同步⼀次AOF ⽂件，Redis 性能⼏乎没受到任何影响。⽽且这样即使出现系统崩溃，⽤户最多只会丢失⼀秒之内产⽣的数据。当硬盘忙于执⾏写⼊操作的时候，Redis 还会优雅的放慢⾃⼰的速度以便适应硬盘的最⼤写⼊速度。</p>
<p><strong>补充内容：AOF 重写</strong></p>
<p>AOF 重写可以产⽣⼀个新的 AOF ⽂件，这个新的 AOF ⽂件和原有的 AOF ⽂件所保存的数据库状态⼀样，但体积更⼩。</p>
<p>AOF 重写是⼀个有歧义的名字，该功能是通过读取数据库中的键值对来实现的，程序⽆须对现有AOF ⽂件进⾏任何读⼊、分析或者写⼊操作。</p>
<p>在执⾏ BGREWRITEAOF 命令时，Redis 服务器会维护⼀个 AOF 重写缓冲区，该缓冲区会在⼦进程创建新 AOF ⽂件期间，记录服务器执⾏的所有写命令。当⼦进程完成创建新 AOF ⽂件的⼯作之后，服务器会将重写缓冲区中的所有内容追加到新 AOF ⽂件的末尾，使得新旧两个 AOF ⽂件所保存的数据库状态⼀致。最后，服务器⽤新的 AOF ⽂件替换旧的 AOF ⽂件，以此来完成AOF ⽂件重写操作</p>
<h3 id="rdb">RDB</h3>
<p>RDB即将当前数据生成快照，并保存于硬盘中。可以通过手动命令，也可以设置自动触发。</p>
<h3 id="简述redis的aof">简述Redis的AOF</h3>
<p><strong>AOF通过日志</strong>，对数据的写入修改操作进行记录。这种持久化方式实时性更好。通过配置文件打开AOF。</p>
<h3 id="简述aof的持久化策略">简述AOF的持久化策略</h3>
<ol>
<li>always。每执行一次数据修改命令就将其命令写入到磁盘日志文件上。</li>
<li>everysec。每秒将命令写入到磁盘日志文件上。</li>
<li>no。不主动设置，由操作系统决定什么时候写入到磁盘日志文件上。</li>
</ol>
<h3 id="简述aof的重写">简述AOF的重写</h3>
<p>随着<a href="">客户端</a>不断进行操作，AOF对应的文件也越来越大。<a href="">redis</a>提供了<strong>bgrewriteaof函数</strong>，针对目前数据库中数据，在不读取原有AOF文件的基础上，重写了一个新的AOF文件，减少文件大小。</p>
<h3 id="rdb与aof优缺点比较">RDB与AOF优缺点比较</h3>
<p>AOF占用的文件体积比RDB大。一般来说利用AOF备份对系统的消耗比RDB低。对于备份时出现系统故障，RDB数据可能会全丢，但AOF只会损失一部分。RDB恢复速度比AOF低。</p>
<h3 id="redis自动触发rdb机制">Redis自动触发RDB机制</h3>
<ol>
<li>通过<strong>配置文件</strong>，设置<strong>一定时间后自动执行RDB</strong></li>
<li>如采用<strong>主从复制过程</strong>，会<strong>自动执行RDB</strong></li>
<li>Redis执行shutdown时，在未开启AOF后会执行RDB</li>
</ol>
<h2 id="redis-事务">Redis 事务</h2>
<p>Redis 可以通过 <strong>MULTI，EXEC，DISCARD 和 WATCH</strong> 等命令来实现事务(transaction)功能。</p>
<figure data-type="image" tabindex="12"><img src="D:%5Cnote%5C%E9%9D%A2%E8%AF%95%5C%E9%9D%A2%E8%AF%95.assets%5Cimage-20230203111358081.png" alt="image-20230203111358081" loading="lazy"></figure>
<p>使⽤ <strong>MULTI</strong>命令后可以输⼊多个命令。Redis不会⽴即执⾏这些命令，⽽是将它们放到队列，当调⽤了<strong>EXEC</strong>命令将执⾏所有命令。</p>
<p>但是Redis 的事务和我们平时理解的关系型数据库的事务不同于我们知道事务具有四大特性</p>
<p><strong>Redis 是不⽀持 roll back 的因⽽不满⾜原⼦性的（⽽且不满⾜持久性）</strong></p>
<p>Redis官⽹也解释了⾃⼰为啥不⽀持回滚。简单来说就是Redis开发者们觉得没必要⽀持回滚，这样更简单便捷并且性能更好。<strong>Redis开发者觉得即使命令执⾏错误也应该在开发过程中就被发现⽽不是⽣产过程中</strong></p>
<p>你可以将Redis中的事务就理解为 ：<strong>Redis事务提供了⼀种将多个命令请求打包的功能 ，将这些任务放到队列里面就不会出现被打断的现象 并且任务会按照顺序执行</strong>。</p>
<p>多数事务失败是由语法错误或者数据结构类型错误导致的，语法错误说明在命令入队前就进行检测的，而类型错误是在执行时检测的，Redis为提升性能而采用这种简单的事务，这是不同于关系型数据库的，特别要注意区分</p>
<h2 id="缓存穿透">缓存穿透</h2>
<h3 id="什么是缓存穿透">什么是缓存穿透</h3>
<p>缓存穿透说简单点就是⼤量请求的 key 根本<strong>不存在于缓存中</strong>，导致请求直接到了数据库上，根本没有经过缓存这⼀层。举个例⼦：某个⿊客故意制造我们缓存中不存在的 key 发起⼤量请求，导致⼤量请求落到数据库。</p>
<h3 id="缓冲穿透情况的处理流程">缓冲穿透情况的处理流程</h3>
<figure data-type="image" tabindex="13"><img src="D:%5Cnote%5C%E9%9D%A2%E8%AF%95%5C%E9%9D%A2%E8%AF%95.assets%5Cimage-20230203111412798.png" alt="image-20230203111412798" loading="lazy"></figure>
<h3 id="解决缓存穿透的方法">解决缓存穿透的方法</h3>
<ul>
<li>解决方案：
<ul>
<li><strong>对参数进行校验。错误的参数直接过滤</strong>。</li>
<li><strong>缓存无效key</strong>，<strong>并设置过期时间</strong>。
<ul>
<li>缺点：会导致大量的无效缓存</li>
</ul>
</li>
<li><strong>布隆过滤器</strong>：把所有可能存在的请求的值都存放在布隆过滤器中,当用户请求过来,先判断用户发来的请求的值是否存在于布隆过滤器中。不存在的话,直接返回请求参数错误信息给客户端,存在的话才会走下面的流程。
<ul>
<li>缺点：可能会导致误判</li>
<li>布隆过滤器通过哈希函数计算key的哈系值然后获取相应的位置。并把位置的值置为1。由于会存在哈希冲突，所以布隆过滤器说某个元素存在，小概率会误判。布隆过滤器说某个元素不在，那么这个元素一定不在。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="缓存雪崩">缓存雪崩</h2>
<h3 id="什么是缓存雪崩">什么是缓存雪崩</h3>
<p>缓存在同⼀时间⼤⾯积的失效，后⾯的请求都直接落到了数据库上，造成数据库短时间内承受⼤量请求。 这就好⽐雪崩⼀样，摧枯拉朽之势数据库的压⼒可想⽽知，可能直接就被这么多请求弄宕机了。</p>
<p>举个例⼦：系统的缓存模块出了问题⽐如宕机导致不可⽤。造成系统的所有访问，都要⾛数据库。</p>
<p><strong>还有⼀种缓存雪崩的场景</strong>是：有⼀些被⼤量访问数据（热点缓存）在某⼀时刻⼤⾯积失效，导致对应的请求直接落到了数据库上。 这样的情况，有下⾯⼏种解决办法：举个例⼦ ：秒杀开始 12 个⼩时之前，我们统⼀存放了⼀批商品到 Redis 中，设置的缓存过期时间也是 12 个⼩时，那么秒杀开始的时候，这些秒杀的商品的访问直接就失效了。导致的情况就是，相应的请求直接就落到了数据库上，就像雪崩⼀样可怕。</p>
<h3 id="解决方法">解决方法</h3>
<ul>
<li>解决方案：
<ul>
<li>加锁：如果缓存失效的话，则对操作进行加锁，然后获取数据。</li>
<li>Redis集群：使用redis集群并设置不同的失效时间比如随机设置缓存的失效时间。</li>
<li>随机指数退避算法：如果发现缓存失效，则随机一个很短的时间，并sleep，再次查询，如果失败再执行更新。</li>
<li>双缓存：我们有两个缓存，缓存A和缓存B。缓存A的失效时间为20分钟，缓存B不设失效时间。自己做缓存预热操作。然后细分以下几个小点：
<ul>
<li>从缓存A读数据，有则直接返回</li>
<li>A没有数据，直接从B读数据，直接返回，并且异步启动一个更新线程。</li>
<li>更新线程同时更新缓存A和缓存B。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="缓存击穿">缓存击穿</h2>
<ul>
<li>key对应的数据存在，但在redis中过期，此时若有大量并发请求过来，这些请求发现缓存过期一般都会从后端DB加载数据并回设到缓存，这个时候大并发的请求可能会瞬间把后端DB压垮。</li>
<li>解决方案：
<ul>
<li>热点数据设置永不过期</li>
<li>加锁：如果缓存失效的话，则对操作进行加锁，然后获取数据。</li>
<li>Redis集群：使用redis集群并设置不同的失效时间比如随机设置缓存的失效时间。</li>
<li>随机指数退避算法：如果发现缓存失效，则随机一个很短的时间，并sleep，再次查询，如果失败再执行更新。</li>
</ul>
</li>
</ul>
<h2 id="如何保证缓存和数据库数据的一致性">如何保证缓存和数据库数据的⼀致性</h2>
<p>https://blog.csdn.net/v123411739/article/details/124237900</p>
<p>https://blog.csdn.net/lans_g/article/details/124652284</p>
<h2 id="redis集群策略">Redis集群策略</h2>
<p><strong>主从复制</strong></p>
<ul>
<li><strong>主数据库可以进行读写操作</strong>，当读写操作导致数据变化时会自动将数据同步给从数据库</li>
<li><strong>slave从数据库一般都是只读</strong>的，并且接收主数据库同步过来的数据</li>
<li>一个master可以拥有多个slave，但是一个slave只能对应一个master</li>
</ul>
<p><strong>哨兵模式</strong></p>
<ul>
<li>监控主从数据库是否正常运行</li>
<li>master出现故障时，自动将slave转化为master</li>
<li>多哨兵配置的时候，哨兵之间也会自动监控</li>
<li>多个哨兵可以监控同一个redis</li>
</ul>
<p><strong>集群模式</strong></p>
<ul>
<li>Redis的集群部署可以将数据划分为多个子集存在不同的节点上，每个节点负责自己整个数据的一部分。</li>
<li>Redis Cluster采用哈希分区规则中的虚拟槽分区。虚拟槽分区巧妙地使用了哈希空间，使用分散度良好的哈希函数把所有的数据映射到一个固定范围内的整数集合，整数定义为槽（slot）。Redis的槽的范围是（0 - 16383，2^14-1）。槽是集群内数据管理和迁移的基本单位。所有的键根据哈希函数映射到哈希槽，每个节点负责维护一部分的槽和其映射的键值数据。</li>
<li>计算规则为：key = CRC16 % 16384</li>
<li>哈希槽让在集群中添加和移除节点非常容易。例如，如果我想添加一个新节点 D ，我需要从节点 A 、B、C 移动一些哈希槽到节点 D。同样地，如果我想从集群中移除节点 A ，我只需要移动 A 的哈希槽到 B 和 C。当节点 A 变成空的以后，我就可以从集群中彻底删除它。因为从一个节点向另一个节点移动哈希槽并不需要停止操作，所以添加和移除节点，或者改变节点持有的哈希槽百分比，都不需要任何停机时间（downtime）。</li>
</ul>
<h2 id="主从同步">主从同步</h2>
<ul>
<li>全量同步：
<ul>
<li>流程：
<ul>
<li>从服务器连接主服务器，发送SYNC命令</li>
<li>主服务器收到SYNC命令，开始执行BGSAVE命令，生成RDB文件，并使用缓冲区记录备份过程中执行的所有命令。</li>
<li>主服务器BGSAVE完成后，向所有从服务器发送快照文件，并在发送期间继续记录被执行的写命令。</li>
<li>从服务器收到快照文件后丢弃所有旧数据，载入收到的快照</li>
<li>主服务器快照发送完毕后向从服务器发送写命令，将BGSAVE期间收到的命令发送给从服务器</li>
</ul>
</li>
</ul>
</li>
<li>增量同步：
<ul>
<li>主服务器执行一个写命令，并且向从服务器发送相同的写命令，从服务器收到后就会执行收到的写命令</li>
</ul>
</li>
</ul>
<h2 id="redis高并发和快速的原因">Redis高并发和快速的原因</h2>
<p>参考https://www.cnblogs.com/angelyan/p/10450885.html</p>
<p>1.redis是基于<strong>内存</strong>的，内存的读写速度非常快；</p>
<p>2.redis是<strong>单线程</strong>的，省去了很多上下文切换线程的时间；</p>
<p>3.redis使用<strong>多路复用技术，可以处理并发的连接</strong>。非阻塞IO 内部实现采用epoll，采用了epoll+自己实现的简单的事件框架。epoll中的读、写、关闭、连接都转化成了事件，然后利用epoll的多路复用特性，绝不在io上浪费一点时间。</p>
<h2 id="什么情况下使用redis-2">什么情况下使用<a href="https://www.nowcoder.com/jump/super-jump/word?word=redis">redis</a></h2>
<ol>
<li>针对热点数据进行缓存</li>
<li>对于特定限时数据的存放</li>
<li>针对带热点权值数据的<a href="https://www.nowcoder.com/jump/super-jump/word?word=%E6%8E%92%E5%BA%8F">排序</a>list</li>
<li>分布式锁</li>
</ol>
<h2 id="什么是缓存与数据库双写一致问题">什么是缓存与数据库双写一致问题？</h2>
<p>如果仅仅查询的话，缓存的数据和数据库的数据是没问题的。但是，当我们要<strong>更新</strong>时候呢？各种情况很可能就<strong>造成数据库和缓存的数据不一致</strong>了。</p>
<ul>
<li>这里不一致指的是：<strong>数据库的数据跟缓存的数据不一致</strong></li>
</ul>
<p><img src="https://mmbiz.qpic.cn/mmbiz_png/2BGWl1qPxib2l33BGMSoKYvGQ9LHw02ZOqNExlaAAtCUfWtuYW3qEPnv3wOs7Raz11wy7jlGhu9HJzplBaia72pw/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy">数据库和缓存的数据不一致</p>
<p>从理论上说，只要我们设置了<strong>键的过期时间</strong>，我们就能保证缓存和数据库的数据<strong>最终是一致</strong>的。因为只要缓存数据过期了，就会被删除。随后读的时候，因为缓存里没有，就可以查数据库的数据，然后将数据库查出来的数据写入到缓存中。</p>
<p>除了设置过期时间，我们还需要做更多的措施来<strong>尽量避免</strong>数据库与缓存处于不一致的情况发生。</p>
<h2 id="redis怎么保证和mysql数据一致">Redis怎么保证和Mysql数据一致</h2>
<p>参考 https://www.cnblogs.com/lingqin/p/10279393.html</p>
<p><strong>1.第一种方案：采用延时双删策略</strong></p>
<p>在写库前后都进行redis.del(key)操作，并且设定合理的超时时间。</p>
<p>伪代码如下</p>
<p>public <a href="https://mb.yidianzixun.com/channel/w/void">void</a> write(String key,<a href="https://mb.yidianzixun.com/channel/w/object">Object</a> data){ redis.delKey(key); db.updateData(data); Thread.sleep(500); redis.delKey(key); }</p>
<p><strong>2.具体的步骤就是：</strong></p>
<p>1）先删除缓存</p>
<p>2）再写数据库</p>
<p>3）休眠500毫秒</p>
<p>4）再次删除缓存</p>
<p><strong>那么，这个500毫秒怎么确定的，具体该休眠多久呢？</strong></p>
<p>需要评估自己的项目的读数据业务逻辑的耗时。这么做的目的，就是确保读请求结束，写请求可以删除读请求造成的缓存脏数据。</p>
<p>当然这种策略还要考虑redis和数据库主从同步的耗时。最后的的写数据的休眠时间：则在读数据业务逻辑的耗时基础上，加几百ms即可。比如：休眠1秒。</p>
<p><strong>3.设置缓存过期时间</strong></p>
<p>从理论上来说，给缓存设置过期时间，是保证最终一致性的解决方案。所有的写操作以数据库为准，只要到达缓存过期时间，则后面的读请求自然会从数据库中读取新值然后回填缓存。</p>
<p><strong>4.该方案的弊端</strong></p>
<p>结合双删策略+缓存超时设置，这样最差的情况就是在超时时间内数据存在不一致，而且又增加了写请求的耗时。</p>
<p><strong>2、第二种方案：异步更新缓存(基于订阅binlog的同步机制)</strong></p>
<p><strong>1.技术整体思路：</strong></p>
<p>[MySQL binlog](https://mb.yidianzixun.com/channel/w/mysql binlog)增量订阅消费+消息队列+增量数据更新到redis</p>
<p><strong>1）读Redis</strong>：热数据基本都在Redis</p>
<p><strong>2）写MySQL</strong>:增删改都是操作MySQL</p>
<p><strong>3）更新Redis数据</strong>：MySQ的数据操作binlog，来更新到Redis</p>
<p><strong>2.Redis更新</strong></p>
<p><strong>1）数据操作主要分为两大块：</strong></p>
<ul>
<li>一个是全量(将全部数据一次写入到redis)</li>
<li>一个是增量（实时更新）</li>
</ul>
<p>这里说的是增量,指的是mysql的update、insert、delate变更数据。</p>
<p><strong>2）读取binlog后分析 ，利用消息队列,推送更新各台的redis缓存数据。</strong></p>
<p>这样一旦MySQL中产生了新的写入、更新、删除等操作，就可以把binlog相关的消息推送至Redis，Redis再根据binlog中的记录，对Redis进行更新。</p>
<p>其实这种机制，很类似MySQL的主从备份机制，因为MySQL的主备也是通过binlog来实现的数据一致性。</p>
<p>这里可以结合使用canal(阿里的一款开源框架)，通过该框架可以对MySQL的binlog进行订阅，而canal正是模仿了<a href="https://mb.yidianzixun.com/channel/w/mysql">mysql</a>的slave<a href="https://mb.yidianzixun.com/channel/w/%E6%95%B0%E6%8D%AE%E5%BA%93">数据库</a>的备份请求，使得Redis的数据更新达到了相同的效果。</p>
<p>当然，这里的消息推送工具你也可以采用别的第三方：<a href="https://mb.yidianzixun.com/channel/w/kafka">kafka</a>、<a href="https://mb.yidianzixun.com/channel/w/rabbitmq">rabbitMQ</a>等来实现推送更新<a href="https://mb.yidianzixun.com/channel/w/redis">Redis</a></p>
<figure data-type="image" tabindex="14"><img src="https://img-blog.csdnimg.cn/img_convert/5185e1f165b06e570dcffe57c993a6d3.png" alt="image-20220508181331250" loading="lazy"></figure>
<h2 id="save命令">save命令</h2>
<p>save命令是<a href="">redis</a>手动触发RDB过程的命令。使用该命令后**，服务器阻塞，直到RDB过程完成后终止。该过程占用内存较多**。</p>
<h2 id="bgsave命令">bgsave命令</h2>
<p><strong>bgsave命令不阻塞主进程</strong>（严格意义上也不是完全不阻塞，详看下面过程），该命令fork一个子进程用于执行RDB过程。其具体过程为：</p>
<ol>
<li>判断此时有没有子进程用于RDB，有的话直接返回。</li>
<li><a href="">redis</a>进行fork子进程过程，此时父进程处于阻塞状态。</li>
<li>子进程创建RDB文件，完成后返回给父进程 ·</li>
</ol>
<h2 id="如何实现分布式锁">如何实现分布式锁</h2>
<p>https://www.cnblogs.com/javazhiyin/p/11737403.html</p>
<h2 id="redis常用命令">Redis常用命令</h2>
<p>https://blog.csdn.net/u010191034/article/details/83383448</p>
<h2 id="redis设置过期时间">Redis设置过期时间</h2>
<p><strong>EXPIRE</strong> 接口定义：EXPIRE key &quot;seconds&quot;<br>
　　　　接口描述：设置一个key在当前时间&quot;seconds&quot;(秒)之后过期。返回1代表设置成功，返回0代表key不存在或者无法设置过期时间</p>
<p><strong>PEXPIRE</strong> 接口定义：PEXPIRE key &quot;milliseconds&quot;<br>
　　　　接口描述：设置一个key在当前时间&quot;milliseconds&quot;(毫秒)之后过期。返回1代表设置成功，返回0代表key不存在或者无法设置过期时间。</p>
<p>参考</p>
<h2 id="redis的使用注意点总结">redis的使用注意点总结</h2>
<p>https://blog.csdn.net/WR0309/article/details/122819361</p>
<h3 id="如何使用redis更节省内存">如何使用redis更节省内存</h3>
<p>redis之所以快是因为它是一款内存数据库，但是一台机器内存都是有限且比较珍贵的资源，使用redis的时候需要合理的规划对应的内存优化策略。</p>
<p>1、控制key的长度，当key的量级很大的时候，合理的控制key的长度可以节省很大的空间。</p>
<p>2、避免存储bigkey，除了控制key的长度，value的大小也要关注，string的大小控制在10kb以下，list、hash、set、zset也要控制。</p>
<p>3、合理的选择数据类型</p>
<p>String、Set 在存储 int 数据时，会采用整数编码存储。Hash、ZSet 在元素数量比较少时（可配置），会采用压缩列表（ziplist）存储，在存储比较多的数据时，才会转换为哈希表和跳表。</p>
<p>String、Set：尽可能存储 int 类型数据<br>
Hash、ZSet：存储的元素数量控制在转换阈值之下，以压缩列表存储，节约内存<br>
4、把redis尽可能的当成缓存使用</p>
<p>5、实例设置maxmemory+淘汰策略</p>
<p>虽然使用redis的时候会设置key的过期时间，但是如果业务写入量比较大的话，那么短期内redis的内存依旧会快速增加。需要提前预估业务数据量，然后给实例设置maxmemory控制实例的内存上限，然后需要设置内存过期策略。</p>
<p>volatile-lru / allkeys-lru：优先保留最近访问过的数据<br>
volatile-lfu / allkeys-lfu：优先保留访问次数最频繁的数据（4.0+版本支持）<br>
volatile-ttl ：优先淘汰即将过期的数据<br>
volatile-random / allkeys-random：随机淘汰数据<br>
6、数据压缩后写入redis</p>
<h3 id="如何持续的发挥redis的高性能">如何持续的发挥redis的高性能</h3>
<p>1、避免存储bigkey</p>
<p>redis是单线程的，当写入一个bigkey的时候，redis会用更多的时间消耗在内存分配上，同样删除的时候也会比较耗时，另外就是客户端在读取bigkey的时候，在网络数据传输上比较耗时。</p>
<p>2、开启lazy-free机制</p>
<p>如果无法避免的使用bigkey的时候，可以开启lazy-free机制，当删除bigkey的时候，释放内存的操作会交给后台线程执行，这样可以最大程度上避免对主线程的影响。</p>
<p>3、不适用复杂度过高的命令</p>
<p>4、执行O（N）级别的命令的时候，要关注以下N的大小</p>
<p>对于容器类型（List/Hash/Set/ZSet），在元素数量未知的情况下，一定不要无脑执行 LRANGE key 0 -1 / HGETALL / SMEMBERS / ZRANGE key 0 -1</p>
<p>在查询数据时，你要遵循以下原则：</p>
<p>先查询数据元素的数量（LLEN/HLEN/SCARD/ZCARD）<br>
元素数量较少，可一次性查询全量数据<br>
元素数量非常多，分批查询数据（LRANGE/HASCAN/SSCAN/ZSCAN）<br>
5、关注del的时间复杂度</p>
<p>当你删除的是一个 String 类型 key 时，时间复杂度确实是 O(1)。</p>
<p>但当你要删除的 key 是 List/Hash/Set/ZSet 类型，它的复杂度其实为 O(N)，N 代表元素个数。</p>
<p>也就是说，删除一个 key，其元素数量越多，执行 DEL 也就越慢！</p>
<p>List类型：执行多次 LPOP/RPOP，直到所有元素都删除完成<br>
Hash/Set/ZSet类型：先执行 HSCAN/SSCAN/SCAN 查询元素，再执行 HDEL/SREM/ZREM 依次删除每个元素<br>
6、批量的命令代替单个命令</p>
<p>String / Hash 使用 MGET/MSET 替代 GET/SET，HMGET/HMSET 替代 HGET/HSET<br>
其它数据类型使用 Pipeline，打包一次性发送多个命令到服务端执行<br>
7、避免集中过期key</p>
<p>如果业务中有大量的key集中过期，这个会阻塞主线程，可以在设置过期时间的时候增加一个随机时间，将过期时间打散。</p>
<p>8、使用长链接操作redis，合理配置连接池</p>
<p>尽量避免短链接，因为每次都是tcp，三次握手和四次挥手，这个过程会增加操作消耗。</p>
<p>9、只使用db0</p>
<p>在一个连接上操作多个 db 数据时，每次都需要先执行 SELECT，这会给 Redis 带来额外的压力<br>
使用多个 db 的目的是，按不同业务线存储数据，那为何不拆分多个实例存储呢？拆分多个实例部署，多个业务线不会互相影响，还能提高 Redis 的访问性能<br>
Redis Cluster 只支持 db0，如果后期你想要迁移到 Redis Cluster，迁移成本高<br>
10、使用读写分离+分片集群</p>
<p>如果读业务很大，可以采用部署多个从库的方式，实现读写分离，让从库分担读压力，提升性能。</p>
<p>如果写业务的请求很大，单个redis的实例无法支持大的流量，可以使用分片集群，分担写压力。</p>
<p>11、不开启AOF或AOF配置成每秒刷盘</p>
<p>对于丢失数据不敏感的业务，不建议开启AOF，如果确实需要开启，可以配置成 appendfsync everysec，将持久化放在后台线程中。</p>
<p>12、使用物理机部署redis</p>
<p>redis使用rdb持久化的时候，采用子进程的方式，虚拟机支持fork比较耗时。</p>
<p>13、关闭操作系统内存大页机制</p>
<h3 id="如何保证redis的高可用">如何保证redis的高可用</h3>
<p>redis可靠性也是不难，难点是持续的稳定。</p>
<p>1、按照业务线进行部署实例</p>
<p>不同的业务采用不同的redis的实例，有问题的时候互不干扰。</p>
<p>2、部署主从集群</p>
<p>主库和从库也最好放在不同的机器上。</p>
<p>3、合理的设置主从复制参数</p>
<p>设置合理的 repl-backlog 参数：过小的 repl-backlog 在写流量比较大的场景下，主从复制中断会引发全量复制数据的风险<br>
设置合理的 slave client-output-buffer-limit：当从库复制发生问题时，过小的 buffer 会导致从库缓冲区溢出，从而导致复制中断<br>
4、部署哨兵集群，实现故障自动转移</p>
<p>只部署了主从节点，但故障发生时是无法自动切换的，所以，你还需要部署哨兵集群，实现故障的「自动切换」。</p>
<p>而且，多个哨兵节点需要分布在不同机器上，实例为奇数个，防止哨兵选举失败，影响切换时间。</p>
<p>日常运维redis需要注意什么<br>
1、禁止使用 KEYS/FLUSHALL/FLUSHDB 命令，会阻塞主线程，影响线上业务</p>
<p>SCAN 替换 KEYS<br>
4.0+版本可使用 FLUSHALL/FLUSHDB ASYNC，清空数据的操作放在后台线程执行<br>
2、扫描线上实例时，设置休眠时间</p>
<p>不管你是使用 SCAN 扫描线上实例，还是对实例做 bigkey 统计分析，我建议你在扫描时一定记得设置休眠时间。</p>
<p>防止在扫描过程中，实例 OPS 过高对 Redis 产生性能抖动。</p>
<p>3、慎用monitor命令</p>
<p>4、从库必现设置成slave-read-only，避免从库写入导致数据不一致。</p>
<p>5、合理配置 timeout 和 tcp-keepalive 参数，</p>
<p>如果因为网络原因，导致你的大量客户端连接与 Redis 意外中断，恰好你的 Redis 配置的 maxclients 参数比较小，此时有可能导致客户端无法与服务端建立新的连接（服务端认为超过了 maxclients）。</p>
<p>造成这个问题原因在于，客户端与服务端每建立一个连接，Redis 都会给这个客户端分配了一个 client fd。</p>
<p>当客户端与服务端发生网络问题，服务端不会立即释放client fd。</p>
<p>不要配置过高的 timeout：让服务端尽快把无效的 client fd 清理掉<br>
Redis 开启 tcp-keepalive：这样服务端会定时给客户端发送 TCP 心跳包，检测连接连通性，当网络异常时，可以尽快清理僵尸 client fd<br>
6、调整maxmemory时，注意主从库的调整顺序</p>
<p>Redis 5.0 以下版本存在这样一个问题：从库内存如果超过了 maxmemory，也会触发数据淘汰。</p>
<p>在某些场景下，从库是可能优先主库达到 maxmemory 的（例如在从库执行 MONITOR 命令，输出缓冲区占用大量内存），那么此时从库开始淘汰数据，主从库就会产生不一致。</p>
<p>要想避免此问题，在调整 maxmemory 时，一定要注意主从库的修改顺序：</p>
<p>调大 maxmemory：先修改从库，再修改主库<br>
调小 maxmemory：先修改主库，再修改从库<br>
直到 Redis 5.0，Redis 才增加了一个配置 replica-ignore-maxmemory，默认从库超过 maxmemory 不会淘汰数据，才解决了此问题。</p>
<h3 id="redis安全问题">redis安全问题</h3>
<p>不要把 Redis 部署在公网可访问的服务器上<br>
部署时不使用默认端口 6379<br>
以普通用户启动 Redis 进程，禁止 root 用户启动<br>
限制 Redis 配置文件的目录访问权限<br>
推荐开启密码认证<br>
禁用/重命名危险命令（KEYS/FLUSHALL/FLUSHDB/CONFIG/EVAL）</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[SpringBoot]]></title>
        <id>https://lindamao.cn/post/springboot/</id>
        <link href="https://lindamao.cn/post/springboot/">
        </link>
        <updated>2021-01-17T06:25:33.000Z</updated>
        <content type="html"><![CDATA[<h2 id="springboot启动流程">springboot启动流程</h2>
<p>SpringBoot启动的时候，会构造一个SpringApplication的实例，然后调用这个实例的run方法，在run方法调用之前，也就是构造SpringApplication的时候会进行初始化的工作，初始化的时候会做以下几件事：</p>
<p>(1)把参数sources设置到SpringApplication属性中，这个sources可以是任何类型的参数.<br>
(2)判断是否是web程序，并设置到webEnvironment的boolean属性中.<br>
(3)创建并初始化ApplicationInitializer，设置到initializers属性中 。<br>
(4)创建并初始化ApplicationListener，设置到listeners属性中 。<br>
(5)初始化主类mainApplicatioClass。</p>
<h2 id="springboot的自动装配原理">SpringBoot的自动装配原理</h2>
<p>Spring Boot关于自动配置的源码在spring-boot-autoconfigure-x.x.x.x.jar中</p>
<p>Spring Boot的启动类上有一个@<strong>SpringBootApplication</strong>注解，这个注解是Spring Boot项目必不可少的注解。那么自动配置原理一定和这个注解有着千丝万缕的联系！</p>
<p>其关键点是注解@EnableAutoConfiguration当中的导入import的<strong>AutoConfigurationImportSelector</strong>中的selectImports方法 通过<strong>SpringFactoriesLoader.loadFactoryNames()<strong>扫描所有具有</strong>META-INF/spring.factories</strong>的jar包</p>
<p>在spring-boot-autoconfigure-x.x.x.x.jar里就有一个这样的spring.factories文件。</p>
<p>这个spring.factories文件也是一组一组的key=value的形式，其中一个key是EnableAutoConfiguration类的全类名，而它的value是一个xxxxAutoConfiguration的类名的列表，这些类名以逗号分隔</p>
<p>类似于下图</p>
<figure data-type="image" tabindex="1"><img src="https://i.imgtg.com/2023/02/14/dqf9l.png" alt="dqf9l.png" loading="lazy"></figure>
<p>这个@EnableAutoConfiguration注解通过@SpringBootApplication被间接的标记在了Spring Boot的启动类上。在SpringApplication.run(...)的内部就会执行selectImports()方法，找到所有JavaConfig自动配置类的全限定名对应的class，然后将所有自动配置类加载到Spring容器中。</p>
<p><strong>总结：</strong></p>
<p>Spring Boot启动的时候会通过@EnableAutoConfiguration注解找到META-INF/spring.factories配置文件中的所有自动配置类，并对其进行加载，而这些自动配置类都是以AutoConfiguration结尾来命名的，它实际上就是一个JavaConfig形式的Spring容器配置类，它能通过以Properties结尾命名的类中取得在全局配置文件中配置的属性如：server.port，而XxxxProperties类是通过@ConfigurationProperties注解与全局配置文件中对应的属性进行绑定的。</p>
<p>https://blog.csdn.net/u014745069/article/details/83820511</p>
<h2 id="简单介绍一下-spring有啥缺点">简单介绍⼀下 Spring?有啥缺点?</h2>
<p>缺点是集成度较高，使用过程中不太容易了解底层。</p>
<p><strong>ioc和aop配置复杂</strong></p>
<h2 id="说出使用-spring-boot-的主要优点">说出使⽤ Spring Boot 的主要优点</h2>
<p>(1)简化配置，不需要编写太多的xml配置文件；</p>
<p>(2)基于Spring构建，使开发者快速入门，门槛很低；</p>
<p>(3)SpringBoot可以创建独立运行的应用而不需要依赖于容器；</p>
<p>(4)内置tomcat服务器，不需要打包成war包，可以直接放到tomcat中运行；</p>
<p>(5)提供maven极简配置，以及可视化的相关监控功能，比如性能监控，应用的健康程度等；</p>
<p>(6)为微服务SpringCloud奠定了基础，使得微服务的构建变得简单；</p>
<p>(7)Spring可以整合很多各式各样的框架，并能很好的集成；</p>
<p>(8)活跃的社区与论坛，以及丰富的开发文档；</p>
<h2 id="什么是-spring-boot-starters">什么是 Spring Boot Starters?</h2>
<p>starter是SpringBoot中的一个新发明，它有效的降低了项目开发过程的复杂程度，对于简化开发操作有着非常好的效果。</p>
<p>参考连接：https://stackoverflow.com/questions/28273543/what-are-spring-boot-starter-jars/28273660#28273660</p>
<h2 id="spring-boot-支持哪些内嵌-servlet-容器">Spring Boot ⽀持哪些内嵌 Servlet 容器？</h2>
<p>Spring Boot支持Tomcat、Jetty和Undertow三种Servlet容器嵌入到Web应用程序中，开发者使用starter即可方便嵌入，默认情况下，嵌入服务器的访问端口为8080。</p>
<h2 id="如何在-spring-boot-应用程序中使用-jetty-而不是-tomcat">如何在 Spring Boot 应⽤程序中使⽤ Jetty ⽽不是 Tomcat?</h2>
<p>就是在pom.xml文件中，在引用的spring-boot-starter-web排除Tomcat的依赖包，然后再引入Jetty容器的依赖包，如下：</p>
<pre><code class="language-xml">&lt;dependencies&gt;          &lt;dependency&gt;              &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;              &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;              &lt;exclusions&gt;                  &lt;exclusion&gt;                      &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;                      &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt;                  &lt;/exclusion&gt;              &lt;/exclusions&gt;          &lt;/dependency&gt;            &lt;!-- Jetty适合长连接应用，就是聊天类的长连接 --&gt;          &lt;!-- 使用Jetty，需要在spring-boot-starter-web排除spring-boot-starter-tomcat，因为SpringBoot默认使用tomcat --&gt;          &lt;dependency&gt;              &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;              &lt;artifactId&gt;spring-boot-starter-jetty&lt;/artifactId&gt;          &lt;/dependency&gt;          &lt;dependency&gt;              &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;              &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;              &lt;scope&gt;test&lt;/scope&gt;          &lt;/dependency&gt;  &lt;/dependencies&gt;  
</code></pre>
<p><strong>把容器修改为undertow</strong></p>
<pre><code class="language-xml">&lt;dependencies&gt;          &lt;dependency&gt;              &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;              &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;              &lt;exclusions&gt;                  &lt;exclusion&gt;                      &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;                      &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt;                  &lt;/exclusion&gt;              &lt;/exclusions&gt;          &lt;/dependency&gt;                    &lt;!-- undertow不支持jsp --&gt;          &lt;!-- 使用undertow，需要在spring-boot-starter-web排除spring-boot-starter-tomcat，因为SpringBoot默认使用tomcat --&gt;          &lt;dependency&gt;              &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;              &lt;artifactId&gt;spring-boot-starter-undertow&lt;/artifactId&gt;          &lt;/dependency&gt;                    &lt;dependency&gt;              &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;              &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;              &lt;scope&gt;test&lt;/scope&gt;          &lt;/dependency&gt;  &lt;/dependencies&gt;  
</code></pre>
<p>参考:</p>
<p>https://www.cnblogs.com/fanshuyao/p/8668059.html</p>
<h2 id="介绍一下springbootapplication-注解">介绍⼀下@SpringBootApplication 注解</h2>
<p>@SpringBootApplication注解包含三个注解：</p>
<ul>
<li>@ComponentScan扫描当前包和子包中的组件，自动注册到ioc中</li>
<li>@SpringBootConfiguration，它其实也是一个configuration，说明启动类也是一个配置类</li>
<li>@EnableAutoConfiguration，这个注解是实现自动配置的最主要的注解。这个注解里包含**@AutoConfigurationPackage自动配置包**还有@import一个AutoConfigurationImportSelector.class。这个类中通过loadFactoryNames读取meta-inf中的spring。factories文件中自动装配的类。而这些类是pom文件中导入了start之后才能生效。这些类都是XXXautoconfiguration，中还绑定了有属性的xxx.properties，这些properties有一些默认的属性。我们也可以在配置文件yml或者properties中修改这些属性。<br>
SpringApplication.run一共做了两件事</li>
</ul>
<ol>
<li>创建SpringApplication对象；在对象初始化时保存事件监听器，容器初始化类以及判断是否为web应用，保存包含main方法的主配置类。</li>
<li>调用run方法；准备spring的上下文，完成容器的初始化，创建，加载等。会在不同的时机触发监听器的不同事件。</li>
</ol>
<h2 id="spring-boot-的自动配置是如何实现的">Spring Boot 的⾃动配置是如何实现的?</h2>
<p>参考：https://blog.csdn.net/u014534808/article/details/105961992/</p>
<h2 id="开发-restful-web-服务常用的注解有哪些">开发 RESTful Web 服务常⽤的注解有哪些？</h2>
<ul>
<li>@GetMapping，处理 Get 请求</li>
<li>@PostMapping，处理 Post 请求</li>
<li>@PutMapping，⽤用于更新资源</li>
<li>@DeleteMapping，处理删除请求</li>
<li>@PatchMapping，用于更新部分资源</li>
</ul>
<h2 id="spirng-boot-常用的两种配置文件">Spirng Boot 常⽤的两种配置⽂件</h2>
<p><strong>properties</strong></p>
<p><strong>yaml</strong></p>
<h2 id="什么是-yamlyaml-配置的优势在哪里">什么是 YAML？YAML 配置的优势在哪⾥ ?</h2>
<p>YAML是一种人类可读的数据序列化语言。它通常用于配置文件。与属性文件相比，如果我们想要在配置文件中添加复杂的属性，YAML文件就更加结构化，而且更少混淆。可以看出YAML具有分层配置数据。</p>
<ul>
<li>配置有序，在一些特殊的场景下，配置有序很关键</li>
<li>支持数组，数组中的元素可以是基本数据类型也可以是对象 简洁 相比 properties</li>
<li>相比properties配置文件，YAML还有一个缺点，就是不支持@PropertySource注解导入自定义的YAML配置。</li>
</ul>
<h2 id="spring-boot-常用的读取配置文件的方法有哪些">Spring Boot 常⽤的读取配置⽂件的⽅法有哪些？</h2>
<ol>
<li>通过<strong>获取环境变量</strong>来获取配置参数</li>
<li>通过<strong>注解获取配置</strong>文件信息</li>
</ol>
<p><a href="https://blog.csdn.net/github_35169934/article/details/78233421?utm_medium=distribute.pc_relevant.none-task-blog-2~default~BlogCommendFromMachineLearnPai2~default-1.control&amp;dist_request_id=&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2~default~BlogCommendFromMachineLearnPai2~default-1.control">参考链接</a></p>
<h2 id="spring-boot-加载配置文件的优先级了解么">Spring Boot 加载配置⽂件的优先级了解么？</h2>
<ol>
<li>
<p>file:/config/</p>
</li>
<li>
<p>file:/</p>
</li>
<li>
<p>classpath:/config/</p>
</li>
<li>
<p>classpath:/</p>
</li>
</ol>
<h2 id="常用的-bean-映射工具有哪些">常⽤的 Bean 映射⼯具有哪些？</h2>
<p>BeanUtils---先用 jdk 的 java.beans.Introspector类的getBeanInfo()方法获取对象的属性信息及属性get/set方法，接着使用反射（Method的invoke(Object obj, Object… args)）方法进行赋值</p>
<p>BeanCopier---直接使用ASM的MethodVisitor直接编写各属性的get/set方法</p>
<p>mybatis</p>
<h2 id="spring-boot-如何监控系统实际运行状况">Spring Boot 如何监控系统实际运⾏状况？</h2>
<p>组件 Spring Boot Actuator 负责监控应⽤的各项静态和动态的变量</p>
<h2 id="spring-boot-如何做请求参数校验">Spring Boot 如何做请求参数校验？</h2>
<p><strong>spring-boot-starter-validation</strong></p>
<h2 id="如何使用-spring-boot-实现全局异常处理">如何使⽤ Spring Boot 实现全局异常处理？</h2>
<p>使⽤ <strong>@ControllerAdvice</strong> 定义统⼀的异常处理类，⽽不是在每个Controller中逐个定义</p>
<p>@ExceptionHandler ⽤来定义函数针对的异常类型</p>
<h2 id="spring-boot-中如何实现定时任务">Spring Boot 中如何实现定时任务 ?</h2>
<p>一种是使用 Spring 自带的定时任务处理器 @Scheduled 注解，另一种就是使用第三方框架 Quartz</p>
<p><a href="https://www.cnblogs.com/lenve/p/10728897.html">参考链接</a></p>
<h2 id="分布式系统session一致性问题">分布式系统session一致性问题</h2>
<ul>
<li><strong>session同步法</strong>：多台web-server相互同步数据</li>
<li>**客户端存储法：**一个用户只存储自己的数据</li>
<li>**反向代理hash一致性：**四层hash和七层hash都可以做，保证一个用户的请求落在一台web-server上</li>
<li>**后端统一存储：**web-server重启和扩容，session也不会丢失</li>
</ul>
<p><a href="https://www.cnblogs.com/study-everyday/p/7853145.html">参考</a></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Spring]]></title>
        <id>https://lindamao.cn/post/spring/</id>
        <link href="https://lindamao.cn/post/spring/">
        </link>
        <updated>2020-12-12T06:17:03.000Z</updated>
        <content type="html"><![CDATA[<h2 id="maven中package和install的区别">Maven中Package和Install的区别</h2>
<p>​	Package是打包，打成Jar或War</p>
<p>​	Install表示将Jar或War安装到本地仓库中</p>
<h2 id="什么是spring框架">什么是spring框架</h2>
<p>Spring 是⼀种轻量级开发框架，旨在提⾼开发⼈员的开发效率以及系统的可维护性。Spring 官⽹：https://spring.io/。</p>
<p>我们⼀般说 Spring 框架指的都是 Spring Framework，它是很多模块的集合，使⽤这些模块可以很⽅便地协助我们进⾏开发。</p>
<p>这些模块是：核⼼容器、数据访问/集成,、Web、AOP（⾯向切⾯编程）、⼯具、消息和测试模块。⽐如：Core Container 中的 Core 组件是Spring 所有组件的核⼼，Beans 组件和 Context 组件是实现IOC和依赖注⼊的基础，AOP组件⽤来实现⾯向切⾯编程。</p>
<p><strong>Spring 官⽹列出的 Spring 的 6 个特征:</strong></p>
<p>核⼼技术 ：依赖注⼊(DI)，AOP，事件(events)，资源，i18n，验证，数据绑定，类型转换，SpEL。</p>
<ul>
<li>测试 ：模拟对象，TestContext框架，Spring MVC 测试，WebTestClient。</li>
<li>数据访问 ：事务，DAO⽀持，JDBC，ORM，编组XML。</li>
<li>Web⽀持 : Spring MVC和Spring WebFlux Web框架</li>
<li>集成 ：远程处理，JMS，JCA，JMX，电⼦邮件，任务，调度，缓存。</li>
<li>语⾔ ：Kotlin，Groovy，动态语⾔。</li>
</ul>
<h2 id="列举一些重要的spring模块">列举⼀些重要的Spring模块？</h2>
<ul>
<li>Spring Core： 基础,可以说 Spring 其他所有的功能都需要依赖于该类库。主要提供 IoC 依<br>
赖注⼊功能。</li>
<li>Spring Aspects ： 该模块为与AspectJ的集成提供⽀持。</li>
<li>Spring AOP ：提供了⾯向切⾯的编程实现。</li>
<li>Spring JDBC : Java数据库连接。</li>
<li>Spring JMS ：Java消息服务。</li>
<li>Spring ORM : ⽤于⽀持Hibernate等ORM⼯具。</li>
<li>Spring Web : 为创建Web应⽤程序提供⽀持。</li>
<li>Spring Test : 提供了对 JUnit 和 TestNG 测试的⽀持。</li>
</ul>
<h2 id="restcontroller-vs-controller">@RestController vs @Controller</h2>
<p><strong>Controller 返回⼀个⻚⾯</strong><br>
单独使⽤ @Controller 不加 @ResponseBody 的话⼀般使⽤在要返回⼀个视图的情况，这种情况属于⽐᫾传统的Spring MVC 的应⽤，对应于前后端不分离的情况</p>
<p><strong>@RestController 返回JSON 或 XML 形式数据</strong><br>
但 @RestController 只返回对象，对象数据直接以 JSON 或 XML 形式写⼊ HTTP 响应(Response)中，这种情况属于 RESTful Web服务，这也是⽬前⽇常开发所接触的最常⽤的情况（前后端分离）</p>
<p><strong>@Controller +@ResponseBody 返回JSON 或 XML 形式数据</strong><br>
如果你需要在Spring4之前开发 RESTful Web服务的话，你需要使⽤ @Controller 并结合 @ResponseBody 注解，也就是说 @Controller + @ResponseBody = @RestController （Spring 4）之后新加的注解</p>
<p><strong>@ResponseBody 注解</strong>的作⽤是将 Controller 的⽅法返回的对象通过适当的转换器转换为指定的格式之后，写⼊到HTTP 响应(Response)对象的 body 中，通常⽤来返回 JSON 或者XML 数据，返回 JSON 数据的情况比较多。</p>
<h2 id="常用注解">常用注解</h2>
<h2 id="spring依赖注入的方式">Spring依赖注入的方式</h2>
<p>非注解方式注入：</p>
<ol>
<li>Set方法注入</li>
<li>构造器注入</li>
<li>静态工厂的方法注入</li>
<li>实例工厂的方法注入</li>
</ol>
<p>注解方式注入：</p>
<p>1.@Autowired是自动注入，自动从spring的上下文找到合适的bean来注入 @Autowired(required=true)表示必须找到匹配的Bean，否则将报异常。</p>
<p><strong>@Autowired默认按类型匹配注入Bean</strong></p>
<p><strong>在Spring中，@Autowired注入的类型可以是接口</strong></p>
<p>比如，在Service层中注入Dao，如下示：</p>
<pre><code>@Autowired
private UserDao userDao;
</code></pre>
<p>2.@Resource要求提供一个Bean名称的属性，如果属性为空，自动采用标注处的变量名和方法名作为Bean的名称 。</p>
<p><strong>@Resource默认按名称匹配注入Bean</strong></p>
<p>比如，在Controller层中注入Service，名称为Service的实现类，如下示</p>
<pre><code>@Resource(name = &quot;userServiceImpl&quot;)
 private UserService userService;
</code></pre>
<p>另外要注意，@Resource是java自带的注解，不是Spring中的注解。@Resource注解完整的包路径为import  javax.annotation.Resource;</p>
<p>3.<strong>@Qualifier 指定注入bean的名称</strong></p>
<p>比如，在Controller层中注入Service，名称为Service的实现类，如下示</p>
<pre><code> @Autowired
 @Qualifier(&quot;userServiceImp&quot;)
 private UserSerevice userService;
4.@Service，@Controller，@Repository分别标记类是Service层，Controller层，Dao层的类，spring扫描注解配置时，会标记这些类要生成bean。
</code></pre>
<p>@Repository用于标注数据访问组件，即DAO组件</p>
<p><strong>@Service，@Controller 这些注解要放在接口的实现类上，而不是接口上面。</strong><br>
5.@Component是一种泛指，标记类是组件，spring扫描注解配置时，会标记这些类要生成bean。</p>
<p>6.@<strong>Scope</strong>用于指定Bean的作用范围</p>
<p>7.@Autowired和@Resource是用来修饰字段，构造函数，或者设置方法，并做注入的。</p>
<p>而@Service，@Controller，@Repository，@Component则是用来修饰类，标记这些类要生成bean。</p>
<h2 id="spring-ioc-aop">Spring IOC &amp; AOP</h2>
<p>IOC参考：</p>
<p>AOP参考：https://www.cnblogs.com/joy99/p/10941543.html</p>
<h3 id="谈谈自己对于-spring-ioc-和-aop-的理解">谈谈⾃⼰对于 Spring IoC 和 AOP 的理解</h3>
<p><strong>IoC</strong><br>
IoC（Inverse of Control:控制反转）是⼀种设计思想，就是 将原本在程序中⼿动创建对象的控制权，交由Spring框架来管理。 IoC 在其他语⾔中也有应⽤，并⾮ Spring 特有。 IoC 容器是Spring ⽤来实现 IoC 的载体， IoC 容器实际上就是个Map（key，value）,Map 中存放的是各种对象。</p>
<p><strong>AOP(Aspect-Oriented Programming:⾯向切⾯编程)</strong></p>
<p>能够将那些与业务⽆关，却为业务模块所共同调⽤的逻辑或责任（例如事务处理、⽇志管理、权限控制等）封装起来，便于减少系统的重复代码，降低模块间的耦合度，并有利于未来的可拓展性和可维护性。</p>
<p>相关概念：</p>
<ul>
<li>切面（aspect） ： 类是对物体特征的抽象，切面就是对横切关注点的抽象</li>
<li>横切关注点： 对哪些方法进行拦截，拦截后怎么处理，这些关注点称之为横切关注点。</li>
<li>连接点（joinpoint） ： 被拦截到的点，具体要拦截的东西，因为 Spring 只支持方法类型的连接点，所以在 Spring中连接点指的就是被拦截到的方法，实际上连接点还可以是字段或者构造器。</li>
<li>切入点（pointcut） ： 对连接点进行拦截的定义</li>
<li>通知（advice） ： 所谓通知指的就是指拦截到连接点之后要执行的代码， 通知分为前置、后置、异常、最终、环绕通知五类。</li>
<li>目标对象： 代理的目标对象</li>
<li>织入（weave） ： 将切面应用到目标对象并导致代理对象创建的过程</li>
<li>引入（introduction） ： 在不修改代码的前提下，引入可以在运行期为类动态地添加一些方法或字段</li>
</ul>
<h3 id="spring-aop-和-aspectj-aop-有什么区别">Spring AOP 和 AspectJ AOP 有什么区别？</h3>
<p><strong>Spring AOP 属于运⾏时增强，⽽ AspectJ 是编译时增强</strong>。 Spring AOP 基于代理(Proxying)，⽽ AspectJ 基于字节码操作(Bytecode Manipulation)。</p>
<p><strong>注</strong>：Spring中的AspectJ不是真正的使用了AspectJ，只是使用了AspectJ的指示器作为标识创建代理的方式而已，实际上实现AOP还是通过Cglib或JDK来实现的</p>
<p>两者区别：</p>
<table>
<thead>
<tr>
<th>Spring AOP</th>
<th>AspectJ</th>
</tr>
</thead>
<tbody>
<tr>
<td>在纯 Java 中实现</td>
<td>使用 Java 编程语言的扩展实现</td>
</tr>
<tr>
<td>不需要单独的编译过程</td>
<td>除非设置 LTW，否则需要 AspectJ 编译器 (ajc)</td>
</tr>
<tr>
<td>只能使用运行时织入</td>
<td>运行时织入不可用。支持编译时、编译后和加载时织入</td>
</tr>
<tr>
<td>功能不强-仅支持方法级编织</td>
<td>更强大 - 可以编织字段、方法、构造函数、静态初始值设定项、最终类/方法等......。</td>
</tr>
<tr>
<td>只能在由 Spring 容器管理的 bean 上实现</td>
<td>可以在所有域对象上实现</td>
</tr>
<tr>
<td>仅支持方法执行切入点</td>
<td>支持所有切入点</td>
</tr>
<tr>
<td>代理是由目标对象创建的, 并且切面应用在这些代理上</td>
<td>在执行应用程序之前 (在运行时) 前, 各方面直接在代码中进行织入</td>
</tr>
<tr>
<td>比 AspectJ 慢多了</td>
<td>更好的性能</td>
</tr>
<tr>
<td>易于学习和应用</td>
<td>相对于 Spring AOP 来说更复杂</td>
</tr>
</tbody>
</table>
<h3 id="spring-aop-实现原理">Spring AOP 实现原理</h3>
<p>AOP技术利用一种称为“横切”的技术，剖解开封装的对象内部，并将那些影响了多个类的公共行为封装到一个可重用模块，并将其名为“Aspect”，即方面。</p>
<p>实现AOP的技术，主要分为两大类：一是采用动态代理技术，利用截取消息的方式，对该消息进行装饰，以取代原有对象行为的执行；</p>
<p>二是采用静态织入的方式，引入特定的语法创建“方面”，从而使得编译器可以在编译期间织入有关“方面”的代码。</p>
<h3 id="aop使用场景">AOP使用场景</h3>
<p>日志记录、监控优化<br>
2） 权限控制<br>
3） 事务管理<br>
4） 缓存<br>
5） 持久化</p>
<h3 id="spring的ioc是单例模式的么">Spring的IOC是单例模式的么？</h3>
<p>IOC默认使用单例模式创建Bean，默认在spring容器启动时会自动创建对象。</p>
<p>但是也可以通过注解的方式实现多例模式，使用@Scope(value=&quot;prototype&quot;)</p>
<p>使用多例模式，在容器启动时不会创建bean，而在使用bean时才会去创建。</p>
<h3 id="aop代理可以是jdk动态代理或者cglib代理">AOP代理可以是JDK动态代理或者CGLIB代理。</h3>
<p>参考：https://blog.csdn.net/moreevan/article/details/11977115/</p>
<h3 id="cglib和jdk动态代理区别有哪些">cglib和jdk动态代理区别有哪些</h3>
<p>1、Jdk动态代理：利用拦截器（必须实现InvocationHandler）加上反射机制生成一个代理接口的匿名类，在调用具体方法前调用InvokeHandler来处理</p>
<p>2、 Cglib动态代理：利用ASM框架，对代理对象类生成的class文件加载进来，通过修改其字节码生成子类来处理</p>
<p>什么时候用cglib什么时候用jdk动态代理？</p>
<p>1、目标对象生成了接口 默认用JDK动态代理</p>
<p>2、如果目标对象使用了接口，可以强制使用cglib</p>
<p>3、如果目标对象没有实现接口，必须采用cglib库，Spring会自动在JDK动态代理和cglib之间转换</p>
<p>JDK动态代理和cglib字节码生成的区别？</p>
<p>1、JDK动态代理只能对实现了接口的类生成代理，而不能针对类</p>
<p>2、Cglib是针对类实现代理，主要是对指定的类生成一个子类，覆盖其中的方法，并覆盖其中方法的增强，但是因为采用的是继承，所以该类或方法最好不要生成final，对于final类或方法，是无法继承的</p>
<p>Cglib比JDK快？</p>
<p>1、cglib底层是ASM字节码生成框架，但是字节码技术生成代理类，在JDL1.6之前比使用java反射的效率要高</p>
<p>2、在jdk6之后逐步对JDK动态代理进行了优化，在调用次数比较少时效率高于cglib代理效率</p>
<p>3、只有在大量调用的时候cglib的效率高，但是在1.8的时候JDK的效率已高于cglib</p>
<p>4、Cglib不能对声明final的方法进行代理，因为cglib是动态生成代理对象，final关键字修饰的类不可变只能被引用不能被修改</p>
<h2 id="spring-bean">Spring bean</h2>
<h3 id="spring-中的-bean-的作用域有哪些">Spring 中的 bean 的作⽤域有哪些?</h3>
<ul>
<li>singleton : 唯⼀ bean 实例，Spring 中的 bean 默认都是单例的。</li>
<li>prototype : 每次请求都会创建⼀个新的 bean 实例。</li>
<li>request : 每⼀次HTTP请求都会产⽣⼀个新的bean，该bean仅在当前HTTP request内有效。</li>
<li>session : 每⼀次HTTP请求都会产⽣⼀个新的 bean，该bean仅在当前 HTTP session 内有效。</li>
<li>global-session： 全局session作⽤域，仅仅在基于portlet的web应⽤中才有意义，Spring5已经没有了。Portlet是能够⽣成语义代码(例如：HTML)⽚段的⼩型Java Web插件。它们基于portlet容器，可以像servlet⼀样处理HTTP请求。但是，与 servlet 不同，每个 portlet 都有不同的会话</li>
</ul>
<h3 id="spring-中的单例-bean-的线程安全问题了解吗">Spring 中的单例 bean 的线程安全问题了解吗？</h3>
<p>⼤部分时候我们并没有在系统中使⽤多线程，所以很少有⼈会关注这个问题。单例 bean 存在线程问题，主要是因为当多个线程操作同⼀个对象的时候，对这个对象的⾮静态成员变量的写操作会存在线程安全问题。<br>
<strong>常⻅的有两种解决办法：</strong></p>
<p>​	1. 在Bean对象中尽量避免定义可变的成员变量（不太现实）。</p>
<ol>
<li>在类中定义⼀个ThreadLocal成员变量，将需要的可变成员变量保存在 ThreadLocal 中（推荐的⼀种⽅式）。</li>
</ol>
<h3 id="component-和-bean-的区别是什么">@Component 和 @Bean 的区别是什么？</h3>
<ol>
<li>作⽤对象不同: @<strong>Component 注解作⽤于类</strong>，⽽ @<strong>Bean 注解作⽤于⽅法</strong>。</li>
<li>@Component 通常是通过类路径扫描来⾃动侦测以及⾃动装配到Spring容器中（我们可以使⽤ @ComponentScan 注解定义要扫描的路径从中找出标识了需要装配的类⾃动装配到Spring 的 bean 容器中）。 @Bean 注解通常是我们在标有该注解的⽅法中定义产⽣这个bean, @Bean 告诉了Spring这是某个类的示例，当我需要⽤它的时候还给我。</li>
<li>@Bean 注解⽐ Component 注解的⾃定义性更强，⽽且很多地⽅我们只能通过 @Bean 注解来注册bean。⽐如当我们引⽤第三⽅库中的类需要装配到 Spring 容器时，则只能通过@Bean 来实现。</li>
</ol>
<h3 id="将一个类声明为spring的-bean-的注解有哪些">将⼀个类声明为Spring的 bean 的注解有哪些?</h3>
<p>我们⼀般使⽤ @Autowired 注解⾃动装配 bean，要想把类标识成可⽤于 @Autowired 注解⾃动装配的 bean 的类,采⽤以下注解可实现：</p>
<ul>
<li>@Component ：通⽤的注解，可标注任意类为 Spring 组件。如果⼀个Bean不知道属于哪个层，可以使⽤ @Component 注解标注。</li>
<li>@Repository : 对应<strong>持久层</strong>即 <strong>Dao</strong> 层，主要⽤于数据库相关操作。</li>
<li>@Service : 对应<strong>服务层</strong>，主要涉及⼀些复杂的逻辑，需要⽤到 Dao层。</li>
<li>@Controller : 对应 <strong>Spring MVC 控制层</strong>，主要⽤户接受⽤户请求并调⽤ Service 层返回数据给前端⻚⾯。</li>
</ul>
<h2 id="spring-中的-bean-生命周期">Spring 中的 bean ⽣命周期</h2>
<figure data-type="image" tabindex="1"><img src="https://i.imgtg.com/2023/02/14/dqSOI.png" alt="dqSOI.png" loading="lazy"></figure>
<figure data-type="image" tabindex="2"><img src="https://i.imgtg.com/2023/02/14/dq0ND.png" alt="dq0ND.png" loading="lazy"></figure>
<ul>
<li>
<p>Bean 容器找到配置⽂件中 Spring Bean 的定义。</p>
</li>
<li>
<p>Bean 容器利⽤ Java Reflection API 创建⼀个Bean的实例。</p>
</li>
<li>
<p>如果涉及到⼀些属性值 利⽤ set() ⽅法设置⼀些属性值</p>
</li>
<li>
<p>如果 Bean 实现了 BeanNameAware 接⼝，调⽤ setBeanName() ⽅法，传⼊Bean的名字。</p>
</li>
<li>
<p>如果 Bean 实现了 BeanClassLoaderAware 接⼝，调⽤ setBeanClassLoader() ⽅法，传<br>
ClassLoader 对象的实例。</p>
</li>
<li>
<p>与上⾯的类似，如果实现了其他 *.Aware 接⼝，就调⽤相应的⽅法。</p>
</li>
<li>
<p>如果有和加载这个 Bean 的 Spring 容器相关的 BeanPostProcessor 对象，执<br>
⾏ postProcessBeforeInitialization() ⽅法</p>
</li>
<li>
<p>如果Bean实现了 InitializingBean 接⼝，执⾏ afterPropertiesSet() ⽅法。</p>
</li>
<li>
<p>如果 Bean 在配置⽂件中的定义包含 init-method 属性，执⾏指定的⽅法</p>
</li>
<li>
<p>如果有和加载这个 Bean的 Spring 容器相关的 BeanPostProcessor 对象，执<br>
⾏ postProcessAfterInitialization() ⽅法</p>
</li>
<li>
<p>当要销毁 Bean 的时候，如果 Bean 实现了 DisposableBean 接⼝，执⾏ destroy() ⽅法。</p>
</li>
<li>
<p>当要销毁 Bean 的时候，如果 Bean 在配置⽂件中的定义包含 destroy-method 属性，执⾏指<br>
定的⽅法。</p>
</li>
</ul>
<p>Spring Bean的生命周期分为<code>四个阶段</code>和<code>多个扩展点</code>。扩展点又可以分为<code>影响多个Bean</code>和<code>影响单个Bean</code>。整理如下：<br>
四个阶段</p>
<ul>
<li>实例化 Instantiation</li>
<li>属性赋值 Populate</li>
<li>初始化 Initialization</li>
<li>销毁 Destruction</li>
</ul>
<p>多个扩展点</p>
<ul>
<li>影响多个Bean
<ul>
<li>BeanPostProcessor</li>
<li>InstantiationAwareBeanPostProcessor</li>
</ul>
</li>
<li>影响单个Bean
<ul>
<li>Aware
<ul>
<li>Aware Group1
<ul>
<li>BeanNameAware</li>
<li>BeanClassLoaderAware</li>
<li>BeanFactoryAware</li>
</ul>
</li>
<li>Aware Group2
<ul>
<li>EnvironmentAware</li>
<li>EmbeddedValueResolverAware</li>
<li>ApplicationContextAware(ResourceLoaderAware\ApplicationEventPublisherAware\MessageSourceAware)</li>
</ul>
</li>
</ul>
</li>
<li>生命周期
<ul>
<li>InitializingBean</li>
<li>DisposableBean</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><strong>主要过程</strong></p>
<ol>
<li>实例化 Instantiation</li>
<li>属性赋值 Populate</li>
<li>初始化 Initialization</li>
<li>销毁 Destruction</li>
</ol>
<p><strong>实例化 -&gt; 属性赋值 -&gt; 初始化 -&gt; 销毁</strong></p>
<p>主要逻辑都在doCreate()方法中，逻辑很清晰，就是顺序调用以下三个方法，这三个方法与三个生命周期阶段一一对应</p>
<ol>
<li>createBeanInstance() -&gt; 实例化</li>
<li>populateBean() -&gt; 属性赋值</li>
<li>initializeBean() -&gt; 初始化</li>
</ol>
<p>InstantiationAwareBeanPostProcessor作用于<strong>实例化</strong>阶段的前后，BeanPostProcessor作用于<strong>初始化</strong>阶段的前后。正好和第一、第三个生命周期阶段对应。通过图能更好理解：</p>
<figure data-type="image" tabindex="3"><img src="https://i.imgtg.com/2023/02/14/dqcEF.png" alt="dqcEF.png" loading="lazy"></figure>
<p>InstantiationAwareBeanPostProcessor<strong>实际上继 承了</strong>BeanPostProcessor接口</p>
<p>InstantiationAwareBeanPostProcessor方法分析</p>
<p>在InstantiationAwareBeanPostProcessor当中 postProcess<strong>Before</strong>Instantiation方法	在<strong>doCreateBean之前</strong>调用，也就是在bean实例化之前调用的，英文源码注释解释道该方法的返回值会替换原本的Bean作为代理，这也是<strong>Aop</strong>等功能实现的关键点。</p>
<p>之后执行<strong>populateBean</strong> 也就是赋值阶段 continueWithPropertyPopulation 初始的boolean值为true</p>
<p>postProcessAfterInstantiation方法在属性赋值方法内，但是在真正执行赋值操作之前。其返回值为boolean，返回false时可以阻断属性赋值阶段 也就是说当实例化阶段之后还没完成的情况下是不能继续执行属性赋值</p>
<p>注意点：</p>
<p>spring aop替换对象的时候并不在postProcessBefore<strong>Instantiation</strong>替换对象，而是在 postProcess<strong>AfterInitialization</strong>处理的</p>
<p>一般情况下是在postProcessAfterInitialization替换代理类，自定义了TargetSource的情况下在postProcessBeforeInstantiation替换代理类。具体逻辑在AbstractAutoProxyCreator类中。</p>
<p><strong>Aware接口</strong></p>
<p>Aware类型的接口的作用就是让我们能够拿到Spring容器中的一些资源。基本都能够见名知意，Aware之前的名字就是可以拿到什么资源，例如<code>BeanNameAware</code>可以拿到BeanName，以此类推。调用时机需要注意：所有的Aware方法都是在<strong>初始化阶段之前调用</strong>的！</p>
<p>在<strong>initializeBean</strong>方法中有一个<strong>invokeAwareMethods</strong>方法 这个方法是在初始化bean的阶段之前完成的</p>
<p>但是不是所有的Aware接口都使用同样的方式调用。Bean××Aware都是在代码中直接调用的，而ApplicationContext相关的Aware都是通过BeanPostProcessor#postProcessBeforeInitialization()实现的。</p>
<p>之后BeanPostProcessor的调用机制就开始体现出来了 通过<strong>invokeInitMethod</strong>方法的实现在 applyBeanPostProcessors<strong>BeforeInitialization</strong> 和 applyBeanPostProcessors<strong>AfterInitialization</strong> 之间进行完成</p>
<p>参考连接：</p>
<p>https://www.jianshu.com/p/1dec08d290c1</p>
<h2 id="applicationcontext和beanfactory的区别">ApplicationContext和BeanFactory的区别</h2>
<p><strong>BeanFactory：</strong></p>
<p>是Spring里面最低层的接口，提供了最简单的容器的功能，只提供了实例化对象和拿对象的功能；</p>
<p><strong>ApplicationContext：</strong></p>
<p>应用上下文，继承BeanFactory接口，它是Spring的一各更高级的容器，提供了更多的有用的功能；</p>
<ol>
<li>
<p>国际化（MessageSource）</p>
</li>
<li>
<p>访问资源，如URL和文件（ResourceLoader）</p>
</li>
<li>
<p>载入多个（有继承关系）上下文 ，使得每一个上下文都专注于一个特定的层次，比如应用的web层</p>
</li>
<li>
<p>消息发送、响应机制（ApplicationEventPublisher）</p>
</li>
<li>
<p>AOP（拦截器）</p>
</li>
</ol>
<p><strong>两者装载bean的区别</strong></p>
<p><strong>BeanFactory：</strong></p>
<p>BeanFactory在启动的时候不会去实例化Bean，中有从容器中拿Bean的时候才会去实例化；</p>
<p><strong>ApplicationContext：</strong></p>
<p>ApplicationContext在启动的时候就把所有的Bean全部实例化了。它还可以为Bean配置lazy-init=true来让Bean延迟实例化；</p>
<p><strong>我们该用BeanFactory还是ApplicationContent</strong></p>
<p>延迟实例化的优点：（<strong>BeanFactory</strong>）</p>
<p>应用启动的时候占用资源很少；对资源要求较高的应用，比较有优势；</p>
<p>不延迟实例化的优点： （<strong>ApplicationContext</strong>）</p>
<ol>
<li>所有的Bean在启动的时候都加载，系统运行的速度快；</li>
<li>在启动的时候所有的Bean都加载了，我们就能在系统启动的时候，尽早的发现系统中的配置问题</li>
<li>建议web应用，在启动的时候就把所有的Bean都加载了。（把费时的操作放到系统启动中完成）</li>
</ol>
<p>https://blog.csdn.net/pythias_/article/details/82752881</p>
<h2 id="spring如何解决循环依赖问题">spring如何解决循环依赖问题</h2>
<p>简言之，两个池子：一个成品池子，一个半成品池子。能解决循环依赖的前提是：spring开启了allowCircularReferences，那么一个正在被创建的bean才会被放在半成品池子里。在注入bean，向容器获取bean的时候，优先向成品池子要，要不到，再去向半成品池子要。</p>
<p>出现循环依赖一定是你的业务设计有问题。高层业务和底层业务的划分不够清晰，一般，业务的依赖方向一定是无环的，有环的业务，在后续的维护和拓展一定非常鸡肋</p>
<p>参考连接：</p>
<ol>
<li>
<p>https://blog.csdn.net/qq_41630866/article/details/104332517</p>
<p>https://blog.csdn.net/chaitoudaren/article/details/105060882</p>
<p>https://blog.csdn.net/likun557/article/details/113977261</p>
<p>https://cloud.tencent.com/developer/article/1497692</p>
<figure data-type="image" tabindex="4"><img src="https://note.mxecy.cn/docs/%E5%9B%BE%E7%89%87/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6%EF%BC%88%E9%9D%A2%E8%AF%95%E7%89%88%EF%BC%89/Spring%E8%A7%A3%E5%86%B3%E5%BE%AA%E7%8E%AF%E4%BE%9D%E8%B5%96.png" alt="img" loading="lazy"></figure>
<figure data-type="image" tabindex="5"><img src="https://note.mxecy.cn/docs/%E5%9B%BE%E7%89%87/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6%EF%BC%88%E9%9D%A2%E8%AF%95%E7%89%88%EF%BC%89/Spring%E5%BE%AA%E7%8E%AF%E4%BE%9D%E8%B5%96.png" alt="img" loading="lazy"></figure>
<ul>
<li>
<p>Spring使用了三级缓存 + 提前暴露对象的方式来解决循环依赖的问题。</p>
</li>
<li>
<p>Spring解决循环依赖的条件：</p>
<ul>
<li>出现循环依赖的Bean必须是单例的。</li>
<li>依赖注入的方式不能全是构造器注入的方式。</li>
</ul>
</li>
<li>
<p>相关的重要属性：位于<code>DefaultSingletonBeanRegistry</code>类中</p>
<ul>
<li>
<p>Spring内部维护了三个Map，所谓的三重缓存。</p>
<ul>
<li>
<pre><code>Map&lt;String, Object&gt; singletonObjects
</code></pre>
<p>：单例池容器，用于缓存单例Bean的地方。一级缓存。</p>
<ul>
<li>这里的bean是已经创建完成的，该bean经历过实例化-&gt;属性填充-&gt;初始化以及各类的后置处理。因此，一旦需要获取bean时，我们第一时间就会寻找一级缓存</li>
</ul>
</li>
<li>
<pre><code>Map&lt;String, Object&gt; earlySingletonObjects
</code></pre>
<p>：早期的单例Bean。二级缓存。</p>
<ul>
<li>这里跟一级缓存的区别在于，该缓存所获取到的bean是提前曝光出来的，是还没创建完成的。也就是说获取到的bean只能确保已经进行了实例化，但是属性填充跟初始化肯定还没有做完，因此该bean还没创建完成，仅仅能作为指针提前曝光，被其他bean所引用</li>
</ul>
</li>
<li>
<pre><code>Map&lt;String, ObjectFactory&lt;?&gt;&gt; singletonFactories
</code></pre>
<p>：创建中单例Bean的原始工厂。三级缓存。</p>
<ul>
<li>在bean实例化完之后，属性填充以及初始化之前，如果允许提前曝光，spring会将实例化后的bean提前曝光，也就是把该bean转换成beanFactory并加入到三级缓存。在需要引用提前曝光对象时再通过singletonFactory.getObject()获取。</li>
<li>当其他的bean从三级缓存中获取了Bean后，<strong>当前的Bean就会从三级缓存中放入到二级缓存</strong>。并且从三级缓存中取出的时候会调用<code>SmartInstantiationAwareBeanPostProcessor#getEarlyBeanReference</code>方法。</li>
</ul>
</li>
</ul>
</li>
<li>
<p><code>Set&lt;String&gt; singletonsCurrentlyInCreation</code>：保存了当前正在创建的单例对象的名称。</p>
</li>
<li>
<p><code>Map&lt;String, Set&lt;String&gt;&gt; dependentBeanMap</code>：保存了一个bean对其他的bean的依赖。</p>
</li>
</ul>
</li>
<li>
<p><strong>注意：</strong></p>
<ul>
<li>第一级缓存（singletonObjects）是用来缓存创建好的单例Bean的</li>
<li>第二级缓存（earlySingletonObjects）是用来发现在当前Bean被暴露的时间里，有没有被其他Bean引用，如果被其他Bean引用，其他Bean又是引用的一个错误版本，就抛出一个异常。</li>
<li>第三级缓存（singletonFactories），这个才是SP真正用来解决循环依赖的，并且可以延迟代理的时机。</li>
</ul>
<pre><code class="language-java">// AbstractAutowireCapableBeanFactory#doCreateBean
/*忽略部分代码*/
// 创建实例包装
if (instanceWrapper == null) {
    instanceWrapper = createBeanInstance(beanName, mbd, args);
}
// 从实例包装后获取Bean
Object bean = instanceWrapper.getWrappedInstance();
/*忽略部分代码*/
if (earlySingletonExposure) {
    /*忽略部分代码*/
    // 如果允许暴露，则将其加入二级缓存。在调用被取出来的时候会调用SmartInstantiationAwareBeanPostProcessor#getEarlyBeanReference方法，默认实现只有AbstractAutoProxyCreator，创建代理。因此，如果在被暴露的过程中，有其他Bean调用getSingleton(当前对象)，则当前对象会被代理（如果有的话），然后放入二级缓存。
    addSingletonFactory(beanName, () -&gt; getEarlyBeanReference(beanName, mbd, bean));
}
/*忽略部分代码*/
Object exposedObject = bean;
try {
    // 填充属性
    populateBean(beanName, mbd, instanceWrapper);
    // 实例化Bean，请注意这里，实例化Bean的时候可能会导致exposedObject的改变！！！
    exposedObject = initializeBean(beanName, exposedObject, mbd);
}
catch (Throwable ex) {
    /*忽略部分代码*/
}

if (earlySingletonExposure) {
    // 直接从二级缓存或一级缓存中获取Bean，注意，这里如果不为null，只有一种可能，在暴露出去的时间里，在其他Bean的初始化过程中调用了getSingleton(当前Bean)。
    Object earlySingletonReference = getSingleton(beanName, false);
    if (earlySingletonReference != null) {
        // 判断exposedObject在经过initializeBean后是否和原来的Bean是一个对象。
        if (exposedObject == bean) {
            // 如果bean没有在initializeBean改变，那么将当前Bean替换为代理后（如果有代理过的话）的Bean。
            exposedObject = earlySingletonReference;
        }
        else if (!this.allowRawInjectionDespiteWrapping &amp;&amp; hasDependentBean(beanName)) {
            /*忽略部分代码*/
            // 注意：到了这里，说明了一种情况，当前暴露出去的Bean（可能被代理过后）被其他Bean引用了，但是在实例化Bean的时候，Bean和暴露出去的Bean已经不是一个Bean的，即其他Bean引用的Bean是一个错误的Bean。因此如果有其他的Bean实际引用了当前Bean，则应该抛出一个异常。为什么是实际引用呢？因为这里可能其他Bean只是实现了Aware之类的接口，并在里面调用了getSingleton(当前Bean)，并没有实际引用。
        }
    }
}Copy to clipboardErrorCopied
</code></pre>
</li>
<li>
<p>问题：</p>
<ul>
<li>
<p>如何解决循环依赖的：</p>
<ul>
<li>通过提前曝光解决循环依赖，当AB循环依赖的时候，先将A的半成品曝光出去，让B先完成初始化，然后在使得初始化完成后的B注入到A中。</li>
</ul>
</li>
<li>
<p>为什么要三级缓存：（<strong>以下为自己理解，不一定准确，事实上，添加三级缓存的地方的注释也标注了三级缓存是用来解决潜在的循环依赖的。</strong>）</p>
<ul>
<li>
<p>很多博文说三级缓存是为了解决AOP的循环依赖，但事实上不是这样的，即使没有三级缓存，Spring也可以通过提前暴露代理对象的方法来解决AOP的循环依赖。</p>
</li>
<li>
<p>所以三级缓存的作用主要是：延迟对实例化阶段生成的对象的代理，只有真正发生循环依赖的时候，才去提前生成代理对象，否则只会创建一个工厂并将其放入到三级缓存中，但是不会去通过这个工厂去真正创建对象。</p>
</li>
<li>
<p>对于代理过的对象，如果在被暴露出去的时候被其他的Bean所引用了，就会在从三级缓存中移除的时候创建代理；如果没有被引用的话，则在初始化Bean的时候创建代理。</p>
</li>
<li>
<p>三级缓存作用：（三级缓存并非非要不可）</p>
<ul>
<li>通过<code>SmartInstantiationAwareBeanPostProcessor</code>对Bean进行扩展。</li>
<li>尽量可能的延迟AOP的初始化。</li>
</ul>
</li>
<li>
<figure data-type="image" tabindex="6"><img src="https://note.mxecy.cn/docs/%E5%9B%BE%E7%89%87/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6%EF%BC%88%E9%9D%A2%E8%AF%95%E7%89%88%EF%BC%89/%E5%9C%A8InstantiationBean%E4%B8%AD%E6%94%B9%E5%8F%98%E4%BA%86Bean.png" alt="img" loading="lazy"></figure>
<pre><code class="language-java">// AbstractAutowireCapableBeanFactory#doCreateBean
// 忽略部分代码
if (earlySingletonExposure) {
    if (logger.isTraceEnabled()) {
        logger.trace(&quot;Eagerly caching bean '&quot; + beanName +
                     &quot;' to allow for resolving potential circular references&quot;);
    }
    // 添加三级缓存
    addSingletonFactory(beanName, () -&gt; getEarlyBeanReference(beanName, mbd, bean));
}
// 忽略部分代码

// AbstractAutowireCapableBeanFactory#getEarlyBeanReference
protected Object getEarlyBeanReference(String beanName, RootBeanDefinition mbd, Object bean) {
    Object exposedObject = bean;
    if (!mbd.isSynthetic() &amp;&amp; hasInstantiationAwareBeanPostProcessors()) {
        for (SmartInstantiationAwareBeanPostProcessor bp : getBeanPostProcessorCache().smartInstantiationAware) {
            // 这里实现了getEarlyBeanReference的只有一个AbstractAutoProxyCreator.java
            exposedObject = bp.getEarlyBeanReference(exposedObject, beanName);
        }
    }
    return exposedObject;
}
</code></pre>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ol>
<h2 id="spring-mvc">Spring MVC</h2>
<h3 id="说说自己对于-spring-mvc-了解">说说⾃⼰对于 Spring MVC 了解?</h3>
<p>谈到这个问题，我们不得不提提之前 Model1 和 Model2 这两个没有 Spring MVC 的时代。</p>
<ul>
<li>Model1 时代 : 很多学 Java 后端⽐᫾晚的朋友可能并没有接触过 Model1 模式下的JavaWeb 应⽤开发。在 Model1 模式下，整个 Web 应⽤⼏乎全部⽤ JSP ⻚⾯组成，只⽤少量的 JavaBean 来处理数据库连接、访问等操作。这个模式下 JSP 即是控制层⼜是表现层。显⽽易⻅，这种模式存在很多问题。⽐如①将控制逻辑和表现逻辑混杂在⼀起，导致代码重⽤率极低；②前端和后端相互依赖，难以进⾏测试并且开发效率极低；</li>
<li>Model2 时代 ：学过 Servlet 并做过相关 Demo 的朋友应该了解“Java Bean(Model)+JSP（View,）+Servlet（Controller） ”这种开发模式,这就是早期的 JavaWeb MVC 开发模式。Model:系统涉及的数据，也就是 dao 和 bean。View：展示模型中的数据，只是⽤来展。Controller：处理⽤户请求都发送给 ，返回数据给 JSP 并展示给⽤户。</li>
</ul>
<p>Model2 模式下还存在很多问题，Model2的抽象和封装程度还远远不够，使⽤Model2进⾏开发时不可避免地会重复造轮⼦，这就⼤⼤降低了程序的可维护性和复⽤性。于是很多JavaWeb开发相关的 MVC 框架应运⽽⽣⽐如Struts2，但是 Struts2 ⽐᫾笨重。随着 Spring 轻量级开发框架的流⾏，Spring ⽣态圈出现了 Spring MVC 框架， Spring MVC 是当前最优秀的 MVC 框架。相⽐于Struts2 ， Spring MVC 使⽤更加简单和⽅便，开发效率更⾼，并且 Spring MVC 运⾏速度更快。MVC 是⼀种设计模式,Spring MVC 是⼀款很优秀的 MVC 框架。Spring MVC 可以帮助我们进⾏更简洁的Web层的开发，并且它天⽣与 Spring 框架集成。Spring MVC 下我们⼀般把后端项⽬分为 Service层（处理业务）、Dao层（数据库操作）、Entity层（实体类）、Controller层(控制层，返回数据给前台⻚⾯)。</p>
<p>SpringMVC ⼯作原理了解吗?</p>
<figure data-type="image" tabindex="7"><img src="https://i.imgtg.com/2023/02/14/dqdu6.png" alt="dqdu6.png" loading="lazy"></figure>
<p>流<strong>程：</strong></p>
<ol>
<li>客户端（浏览器）发送请求，直接请求到 <strong>DispatcherServlet</strong> 。</li>
<li>DispatcherServlet 根据请求信息调⽤ <strong>HandlerMapping</strong> ，解析请求对应的 <strong>Handler</strong> 。</li>
<li>解析到对应的 <strong>Handler</strong> （也就是我们平常说的 <strong>Controller</strong> 控制器）后，开始<strong>HandlerAdapter</strong> 适配器处理。</li>
<li>HandlerAdapter 会根据 Handler 来调⽤真正的处理器开处理请求，并处理相应的业务逻辑。</li>
<li>处理器处理完业务后，会返回⼀个 ModelAndView 对象， Model 是返回的数据对象， View 是个逻辑上的 View 。</li>
<li><strong>ViewResolver</strong> 会根据逻辑 View 查找实际的 View 。</li>
<li><strong>DispaterServlet</strong> 把返回的 Model 传给 View （视图渲染）。</li>
<li>把 View 返回给请求者（浏览器）</li>
</ol>
<h2 id="spring-springmvc和springboot区别">Spring SpringMVC和SpringBoot区别</h2>
<h3 id="一-概念">一、概念</h3>
<p><strong>1、Spring</strong></p>
<p>Spring是一个开源容器框架，可以接管web层，业务层，dao层，持久层的组件，并且可以配置各种bean,和维护bean与bean之间的关系。其核心就是控制反转(IOC),和面向切面(AOP),简单的说就是一个分层的轻量级开源框架。</p>
<p><strong>2、SpringMVC</strong></p>
<p>Spring MVC属于SpringFrameWork的后续产品，已经融合在Spring Web Flow里面。SpringMVC是一种web层mvc框架，用于替代servlet（处理|响应请求，获取表单参数，表单校验等。SpringMVC是一个MVC的开源框架，SpringMVC=struts2+spring，springMVC就相当于是Struts2加上Spring的整合。</p>
<p><strong>3、SpringBoot</strong></p>
<p>Springboot是一个微服务框架，延续了spring框架的核心思想IOC和AOP，简化了应用的开发和部署。Spring Boot是为了简化Spring应用的创建、运行、调试、部署等而出现的，使用它可以做到专注于Spring应用的开发，而无需过多关注XML的配置。提供了一堆依赖打包，并已经按照使用习惯解决了依赖问题—&gt;习惯大于约定。</p>
<h3 id="二区别与总结">二区别与总结</h3>
<p><strong>1.简单理解为：Spring包含了SpringMVC，而SpringBoot又包含了Spring或者说是在Spring的基础上做得一个扩展。</strong></p>
<p><img src="https://img-blog.csdnimg.cn/20200920140600599.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L20wXzQ1MjcwNjY3,size_1,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" loading="lazy"><br>
<strong>2、关系大概就是这样：</strong></p>
<p>spring mvc &lt; spring &lt; springboot</p>
<h2 id="spring-框架中用到了哪些设计模式">Spring 框架中⽤到了哪些设计模式</h2>
<p>1.<strong>工厂设计模式</strong>：Spring使用工厂模式通过BeanFactory和ApplicationContext创建bean对象。</p>
<p>2.<strong>代理设计模式</strong>：Spring AOP功能的实现。</p>
<p>3.<strong>单例设计模式</strong>：Spring中的bean默认都是单例的。</p>
<p>4.<strong>模板方法模式</strong>：Spring中的jdbcTemplate、hibernateTemplate等以Template结尾的对数据库操作的类，它们就使用到了模板模式。</p>
<p>5.<strong>包装器设计模式</strong>：我们的项目需要连接多个数据库，而且不同的客户在每次访问中根据需要会去访问不同的数据库。这种模式让我们可以根据客户的需求能够动态切换不同的数据源。</p>
<p>6.<strong>观察者模式</strong>：Spring<strong>事件驱动模型</strong>就是观察者模式很经典的一个应用。</p>
<p>7.<strong>适配器模式</strong>：Spring AOP的增强或通知（Advice）使用到了适配器模式、Spring MVC中也是用到了适配器模式适配Controller。</p>
<p>https://blog.csdn.net/fei1234456/article/details/106693892</p>
<h2 id="spring-事务">Spring 事务</h2>
<h3 id="spring-管理事务的方式有几种">Spring 管理事务的⽅式有⼏种？</h3>
<ol>
<li><strong>编程式事务</strong>，在代码中硬编码。(不推荐使⽤)</li>
<li><strong>声明式事务</strong>，在配置⽂件中配置（推荐使⽤）</li>
</ol>
<p><strong>声明式事务</strong>⼜分为两种：</p>
<ol>
<li>基于<strong>XML</strong>的声明式事务</li>
<li>基于<strong>注解</strong>的声明式事务 <strong>Transactional</strong></li>
</ol>
<h3 id="spring-事务中的隔离级别有哪几种">Spring 事务中的隔离级别有哪⼏种?</h3>
<ul>
<li>TransactionDefinition.I <strong>SOLATION_DEFAUL</strong>T: 使⽤后端数据库默认的隔离级别，Mysql默认采⽤的 <strong>REPEATABLE_READ</strong>隔离级别 Oracle 默认采⽤的 READ_COMMITTED隔离级别.</li>
<li>TransactionDefinition.ISOLATION_READ_UNCOMMITTED: 最低的隔离级别，允许读取尚未提交的数据变更，可能会导致脏读、幻读或不可重复读</li>
<li>TransactionDefinition.ISOLATION_READ_COMMITTED: 允许读取并发事务已经提交的数据，可以阻⽌脏读，但是幻读或不可重复读仍有可能发⽣</li>
<li>TransactionDefinition.ISOLATION_REPEATABLE_READ: 对同⼀字段的多次读取结果都是⼀致的，除⾮数据是被本身事务⾃⼰所修改，可以阻⽌脏读和不可重复读，但幻读仍有可能发⽣。</li>
<li>TransactionDefinition.ISOLATION_SERIALIZABLE: 最⾼的隔离级别，完全服从ACID的隔离级别。所有的事务依次逐个执⾏，这样事务之间就完全不可能产⽣⼲扰，也就是说，该级别可以防⽌脏读、不可重复读以及幻读。但是这将严重影响程序的性能。通常情况下也不会⽤到该级别。</li>
</ul>
<h3 id="spring-事务中哪几种事务传播行为">Spring 事务中哪⼏种事务传播⾏为?</h3>
<p><strong>⽀持当前事务的情况：</strong></p>
<ul>
<li>TransactionDefinition.PROPAGATION_REQUIRED： 如果当前存在事务，则加⼊该事务；如果当前没有事务，则创建⼀个新的事务。</li>
<li>TransactionDefinition.PROPAGATION_SUPPORTS： 如果当前存在事务，则加⼊该事务；如果当前没有事务，则以⾮事务的⽅式继续运⾏。</li>
<li>TransactionDefinition.PROPAGATION_MANDATORY： 如果当前存在事务，则加⼊该事务；如果当前没有事务，则抛出异常。（mandatory：强制性）</li>
</ul>
<p><strong>不⽀持当前事务的情况</strong>：</p>
<ul>
<li>TransactionDefinition.PROPAGATION_REQUIRES_NEW： 创建⼀个新的事务，如果当前存在事务，则把当前事务挂起。</li>
<li>TransactionDefinition.PROPAGATION_NOT_SUPPORTED： 以⾮事务⽅式运⾏，如果当前存在事务，则把当前事务挂起。</li>
<li>TransactionDefinition.PROPAGATION_NEVER： 以⾮事务⽅式运⾏，如果当前存在事务，则抛出异常。</li>
</ul>
<p><strong>其他情况：</strong></p>
<ul>
<li>TransactionDefinition.PROPAGATION_NESTED： 如果当前存在事务，则创建⼀个事务作为当前事务的嵌套事务来运⾏；如果当前没有事务，则该取值等价于TransactionDefinition.PROPAGATION_REQUIRED。</li>
</ul>
<h3 id="transactionalrollbackfor-exceptionclass注解了解吗">@Transactional(rollbackFor = Exception.class)注解了解吗？</h3>
<p>我们知道：Exception分为运⾏时异常RuntimeException和⾮运⾏时异常。事务管理对于企业应⽤来说是⾄关重要的，即使出现异常情况，它也可以保证数据的⼀致性。</p>
<p>当 @Transactional 注解作⽤于类上时，该类的所有 public ⽅法将都具有该类型的事务属性，同时，我们也可以在⽅法级别使⽤该标注来覆盖类级别的定义。如果类或者⽅法加了这个注解，那么这个类⾥⾯的⽅法抛出异常，就会回滚，数据库⾥⾯的数据也会回滚。</p>
<p>在 @Transactional 注解中如果不配置 rollbackFor 属性,那么事物只会在遇到 <strong>RuntimeException 的时候才会回滚</strong>,加上 rollbackFor=Exception.class ,可以让事物在遇到⾮运⾏时异常时也</p>
<h3 id="springboot和spring-mvc的区别是什么">springboot和spring MVC的区别是什么</h3>
<p>Spring 最初利用“工厂模式”（DI）和“代理模式”（AOP）解耦应用组件。大家觉得挺好用，于是按照这种模式搞了一个 MVC框架（一些用Spring 解耦的组件），用开发 web 应用（ SpringMVC ）。然后发现每次开发都写很多样板代码，为了简化工作流程，于是开发出了一些“懒人整合包”（starter），这套就是 Spring Boot。</p>
<p>所以，用最简练的语言概括就是：</p>
<p>Spring 是一个“引擎”；</p>
<p>Spring MVC 是基于Spring的一个 MVC 框架；</p>
<p>Spring Boot 是基于Spring4的条件注册的一套快速开发整合</p>
<h2 id="jpa">JPA</h2>
<h2 id="如何使用jpa在数据库中非持久化一个字段">如何使⽤JPA在数据库中⾮持久化⼀个字段？</h2>
<p>假如我们有有下⾯⼀个类：</p>
<figure data-type="image" tabindex="8"><img src="https://i.imgtg.com/2023/02/14/dqVFP.png" alt="dqVFP.png" loading="lazy"></figure>
<p>如果我们想让 secrect 这个字段不被持久化，也就是不被数据库存储怎么办？我们可以采⽤下⾯⼏种⽅法：</p>
<figure data-type="image" tabindex="9"><img src="https://i.imgtg.com/2023/02/14/dqYRb.png" alt="dqYRb.png" loading="lazy"></figure>
<h2 id="spring线程安全问题"><a href="https://blog.csdn.net/weixin_43030522/article/details/107614334">spring线程安全问题</a></h2>
<p>spring 的 bean 的scope<br>
spring容器中管理的bean有五种作用域：<br>
1、<strong>singleton</strong>：单例、也是默认的<br>
2、<strong>prototype</strong>：原型，即每次需要该bean都会创建一个新的bean<br>
3、request：请求级别，即每次请求创建一个bean，适用于WebApplicationContext<br>
4、session：session会话级别，同一个session共享一个bean<br>
5、application：应用程序级别，同一个程序共享一个bean</p>
<p>从单例与原型Bean,去说线程安全<br>
对于原型模式的Bean,每次都会创建一个新对象，也就是线程之间并不存在Bean共享，不会有线程安全的问题。<br>
对于单例Bean,所有线程都共享一个单例实例Bean,因此是存在资源的竞争。<br>
如果单例Bean,是一个无状态Bean，也就是线程中的操作不会对Bean的成员执行查询以外的操作，那么这个单例Bean是线程安全的。<br>
<strong>比如spring mvc 的 Controller、Service、Dao等，这些Bean大多是无状态的，只关注于方法本身。</strong><br>
<strong>对于有状态的bean，spring官方提供的bean，一般提供了通过ThreadLocal去解决线程安全的方法。</strong><br>
比如RequestContextHolder、TransactionSynchronizationManager、LocaleContextHolder等。<br>
使用ThreadLocal的好处是使得多线程场景下，多个线程对这个单例Bean的成员变量并不存在资源的竞争，因为ThreadLocal为每个线程保存线程私有的数据。这是一种以空间换时间的方式。</p>
<h2 id="spring中-单例模式和原型模式的区别">spring中 单例模式和原型模式的区别</h2>
<p>简单说来，单例就是用的一个对象。 原型就是拷贝的这个对象。</p>
<p><strong>单例模式和原型模式多次调用hashcode相同么</strong><br>
单例模式多次调用hashcode是相同的。</p>
<p>原型模式多次调用hashcode是不同的。</p>
<p>如何在spring中验证原型模式hashcode不同<br>
在2个类中，分别注入一个原型模式的对象，打印hashcode就可以看出来。</p>
<p>注： 一个类中是看不出来的，因为一个类中注入的时候只调用一次。</p>
<p><strong>有个需求，当每次调用这个对象的时候，生成一个新日期，用bean的形式好么</strong><br>
这个要区分下情况。<br>
如果this.date=new Date(); 写在构造器里是不好用的，因为bean只加载一次。 这个new Date()只在spring创建对象的时候执行一次。 所以一直不变。</p>
<p>解决方案：<br>
可以把this.date=new Date(); 写在一个方法里，然后再返回该bean对象，方法每次调用都会执行一遍逻辑，所以date会变化。</p>
<p><strong>原型模式</strong><br>
存在一个对象，每次新建对象都是拷贝这个对象的属性值<br>
分为浅复制与深复制<br>
区别在于对象里面的引用类型对象属性是否是同一个</p>
<h2 id="jwt原理">JWT原理</h2>
<p>参考https://blog.csdn.net/lh_hebine/article/details/99695927</p>
<p>JWT是为了在网络应用环境之间传递声明而执行的一种基于JSON 的开放标准</p>
<p>JWT组成</p>
<p><strong>头部</strong></p>
<p>​	声明类型</p>
<p>​	加密算法</p>
<p>再进行base加密得到第一部分</p>
<p><strong>载荷</strong> 用于存放有效的信息 不存放敏感的信息</p>
<p>​	标准中注册的声明</p>
<p>​	公共的声明</p>
<p>​	私有的声明</p>
<p>再进行base加密得到第二部分</p>
<p><strong>签证</strong></p>
<p>header base加密后</p>
<p>payload base加密后</p>
<p>secret</p>
<p>通过前两者的加密后字符串 再通过头部声明的加密算法进行加密组成第三部分</p>
<h2 id="jwt认证流程">JWT认证流程</h2>
<p>在前后端分离的项目中：前端将用户的登录信息发送给服务器；服务器接受请求后为用户生成独一无二的认证信息--token，传给客户端浏览器；客户端将token保存在cookie或者storage中；在之后访问客户端都携带这个token请求服务器；服务器验证token的值，如果验证成功则给客户端返回数据。服务器并不保存token。</p>
<h2 id="maven是怎样解决依赖冲突的">maven是怎样解决依赖冲突的</h2>
<p>用Maven Helper插件，在插件安装好之后，我们打开pom.xml文件，在底部会多出一个Dependency Analyzer选项</p>
<p>点击 Dependency Analyzer，通过点击conflicts发现冲突，通过如下的方式在解决冲突；</p>
<h2 id="maven自动解决依赖冲突的规则是什么">maven自动解决依赖冲突的规则是什么？</h2>
<h3 id="第一原则路径最近者优先">第一原则：路径最近者优先</h3>
<p>项目A有如下的依赖关系：</p>
<p>A-&gt;B-&gt;C-&gt;X(1.0)</p>
<p>A-&gt;D-&gt;X(2.0)</p>
<p>则该例子中，X的版本是2.0</p>
<h3 id="第二原则路径相等先声明者优先">第二原则：路径相等，先声明者优先</h3>
<p>项目A有如下的依赖关系：</p>
<p>A-&gt;B-&gt;Y(1.0)</p>
<p>A-&gt;C-&gt;Y(2.0)</p>
<p>若pom文件中B的依赖坐标先于C进行声明，则最终Y的版本为1.0</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Mybatis]]></title>
        <id>https://lindamao.cn/post/mybatis/</id>
        <link href="https://lindamao.cn/post/mybatis/">
        </link>
        <updated>2020-11-14T06:25:02.000Z</updated>
        <content type="html"><![CDATA[<h2 id="和的区别是什么">#{}和${}的区别是什么？</h2>
<p>1）#{}是预编译处理，$ {}是字符串替换。</p>
<p>2）MyBatis在处理#{}时，会将SQL中的#{}替换为?号，使用<strong>PreparedStatement</strong>的set方法来赋值；MyBatis在处理 $ { } 时，就是把 ${ } 替换成变量的值。</p>
<p>3）使用 #{} 可以有效的防止SQL注入，提高系统安全性。</p>
<p>项目实战中使用,请阅读我博客中Java项目实战分类中的--<a href="https://www.cnblogs.com/liaowenhui/p/12217400.html">MySQL中in('5,6,7')只取第一个id为5对应的数据的思考</a>一文，谢谢。</p>
<p>要理解记忆这个题目,我觉得要抓住两点：</p>
<p>（1）$ 符号一般用来当作占位符，常使用Linux脚本的同学应该对此有更深的体会吧。既然是占位符，当然就是被用来替换的。知道了这点就能很容易区分$和#，从而不容易记错了。</p>
<p>（2）预编译的机制。预编译是提前对SQL语句进行预编译，而其后注入的参数将不会再进行SQL编译。我们知道，SQL注入是发生在编译的过程中，因为恶意注入了某些特殊字符，最后被编译成了恶意的执行操作。而预编译机制则可以很好的防止SQL注入。在某些特殊场合下只能用${}，不能用#{}。例如：在使用排序时ORDER BY ${id}，如果使用#{id}，则会被解析成ORDER BY “id”,这显然是一种错误的写法。</p>
<h2 id="xml-映射文件中除了常的-selectinsertupdaedelete-标签之外还有哪些标签">Xml 映射⽂件中，除了常⻅的 select|insert|updae|delete 标签之外，还有哪些标签？</h2>
<p>答：还有很多其他的标签， <resultMap> 、 <parameterMap> 、 <sql> 、 <include> 、 <selectKey> ，加上动态 sql 的 9个标签， trim|where|set|foreach|if|choose|when|otherwise|bind 等，其中为 sql ⽚段标签，通过<br>
<include> 标签引⼊ sql ⽚段， <selectKey> 为不⽀持⾃增的主键⽣成策略标</p>
<h2 id="最佳实践中通常一个-xml-映射文件都会写一个-dao-接口与之对应请问这个-dao-接口的工作原理是什么dao-接口里的方法参数不同时方法能重载吗">最佳实践中，通常⼀个 Xml 映射⽂件，都会写⼀个 Dao 接⼝与之对应，请问，这个 Dao 接⼝的⼯作原理是什么？Dao 接⼝⾥的⽅法，参数不同时，⽅法能重载吗？</h2>
<p>Dao 接⼝，是⼈们常说的 Mapper 接⼝，接⼝的全限名，就是映射⽂件中的 namespace的值，接⼝的⽅法名，就是映射⽂件中 MappedStatement 的 id 值，接⼝⽅法内的参数，就是传递给 sql 的参数。 Mapper 接⼝是没有实现类的，当调⽤接⼝⽅法时，接⼝全限名+⽅法名拼接字符串作为 key 值，可唯⼀定位⼀个 MappedStatement ，举com.mybatis3.mappers.StudentDao.findStudentById ，可以唯⼀找到 namespace为 com.mybatis3.mappers.StudentDao 下⾯ id = findStudentById 的 MappedStatement 。在 Mybatis<br>
中，每⼀个 <select> 、 <insert> 、 <update> 、 <delete> 标签，都会被解析为⼀个 MappedStatement 对象。</p>
<p><strong>Dao 接⼝⾥的⽅法，是不能重载的，因为是全限名+⽅法名的保存和寻找策略。</strong></p>
<p><strong>Dao 接⼝的⼯作原理是 JDK 动态代理</strong>，Mybatis 运⾏时会使⽤ JDK 动态代理为 Dao 接⼝⽣成代理 proxy 对象，代理对象 proxy 会拦截接⼝⽅法，转⽽执⾏ MappedStatement 所代表的 sql，然后将 sql 执⾏结果返回。</p>
<h2 id="mybatis工作流程">Mybatis工作流程</h2>
<p>1.通过SqlSessionFactoryBuilder创建SqlSessionFactory对象</p>
<p>2.通过SqlSessionFactory创建SqlSession对象</p>
<p>3.通过SqlSession拿到Mapper代理对象</p>
<p>4.通过MapperProxy调用Mapper中增删改查的方法</p>
<p>[参考](</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Mysql]]></title>
        <id>https://lindamao.cn/post/mysql/</id>
        <link href="https://lindamao.cn/post/mysql/">
        </link>
        <updated>2020-09-14T05:42:58.000Z</updated>
        <content type="html"><![CDATA[<h2 id="关系型数据库和非关系型数据库的区别">关系型数据库和非关系型数据库的区别</h2>
<ol>
<li>
<p><strong>数据存储结构</strong>：<br>
首先关系型数据库一般都有固定的表结构，并且需要通过DDL语句来修改表结构，不是很容易进行扩展，而非关系型数据库的存储机制就有很多了，比如基于文档的，K-V键值对的，还有基于图的等，对于数据的格式十分灵活没有固定的表结构，方便扩展，因此如果业务的数据结构并不是固定的或者经常变动比较大的，那么非关系型数据库是个好的选择</p>
<p>关系型数据库存储结构比较固定,不容易拓展</p>
<p>非关系型数据库结构不固定，容易拓展</p>
</li>
<li>
<p><strong>可扩展性</strong><br>
传统的关系型数据库给人一种横向扩展难，不好对数据进行分片等，而一些非关系型数据库则原生就支持数据的水平扩展(比如mongodb的sharding机制)，并且这可能也是很多NoSQL的一大卖点，其实象Mysql这种关系型数据库的水平扩展也并不是难，即使NoSQL水平扩展容易但对于向跨分片进行joins这种场景都没有什么太好的解决办法，不管是关系型还是非关系型数据库，解决水平扩展或者跨分片Joins这种场景，在应用层和数据库层中间加一层中间件来做数据处理也许是个好的办法</p>
</li>
<li>
<p><strong>数据一致性</strong><br>
关系型数据库一般强调的是数据最终一致性，而不没有像ACID一样强调数据的强一致性，从非关系型数据库中读到的有可能还是处于一个中间态的数据，因此如果你的业务对于数据的一致性要求很高，那么非关系型数据库并不一个很好的选择，非关系型数据库可能更多的偏向于OLAP场景，而关系型数据库更多偏向于OLTP场景</p>
<p>关系型数据库强调数据的一致性</p>
<p>非关系数据库不是很强调</p>
</li>
</ol>
<h2 id="三大范式">三大范式</h2>
<p>第一范式是最基本的范式。如果数据库表中的所有<strong>字段值都是不可分解的原子值</strong>，就说明该数据库表满足了第一范式。</p>
<p>数据库第二范式：<strong>关系模式必须满足第一范式，并且所有非主属性都完全依赖于主码</strong>。注意，符合第二范式的关系模型可能还存在数据冗余、更新异常等问题。关系模型（学号，姓名，专业编号，专业名称）中，姓名依赖于学号，而专业名称依赖于专业编号，不满足数据库第二范式</p>
<p>数据库第三范式：<strong>关系模型满足第二范式</strong>，所有非主属性对任何候选关键字都不存在传递依赖。即<strong>每个属性都跟主键有直接关系而不是间接关系</strong>。接着以学生表举例，对于关系模型（学号，姓名，年龄，性别，所在院校，院校地址，院校电话）院校地址，院校电话和学号不存在直接关系，因此不满足第三范式。</p>
<p>第一范式：数据具<strong>有原子</strong>性，不可再分。</p>
<p>第二范式：不允许出现部分依赖，即不允许出现复合主键。</p>
<p>第三范式：不存在传递依赖，即不允许出现某个字段依赖非主键。</p>
<h2 id="mysql的架构">MySQL的架构</h2>
<p>MySQL可以分为应用层,逻辑层,数据库引擎层,物理层。</p>
<p><strong>应用层</strong>：负责和<a href="">客户端</a>，响应<a href="">客户端</a>请求，建立连接，返回数据。</p>
<p><strong>逻辑层</strong>：包括SQK接口，解析器，优化器，Cache与buffer。</p>
<p><strong>数据库引擎层</strong>：有常见的MyISAM,InnoDB等等。</p>
<p><strong>物理层</strong>：负责文件存储，日志等等。</p>
<h2 id="存储引擎">存储引擎</h2>
<h3 id="一些常用命令">⼀些常⽤命令</h3>
<p>查看MySQL提供的所有存储引擎</p>
<p><strong>show engines</strong></p>
<p>查看MySQL当前默认的存储引擎</p>
<p><strong>show variables like '%storage_engine</strong></p>
<p>查看表的存储引擎</p>
<p><strong>show table status like &quot;tablename&quot;</strong></p>
<h3 id="myisam和innodb区别">MyISAM和InnoDB区别</h3>
<p><strong>MyISAM</strong>是MySQL的默认数据库引擎（5.5版之前）。虽然性能极佳，⽽且提供了⼤量的特性，包括全⽂索引、压缩、空间函数等，但MyISAM不⽀持事务和⾏级锁，⽽且最⼤的缺陷就是崩溃后⽆法安全恢复。不过，5.5版本之后，MySQL引⼊了<strong>InnoDB</strong>（事务性数据库引擎），MySQL5.5版本后默认的存储引擎为<strong>InnoDB</strong>。⼤多数时候我们使⽤的都是 <strong>InnoDB</strong> 存储引擎，但是在某些情况下使⽤ MyISAM 也是合适的⽐如读密集的情况下。（如果你不介意 MyISAM 崩溃恢复问题的话）。</p>
<p><strong>两者对比</strong></p>
<ol>
<li>
<p>是<strong>否⽀持⾏级锁</strong> : MyISAM 只有表级锁(table-level locking)，⽽InnoDB ⽀持⾏级锁(rowlevel locking)和表级锁,默认为⾏级锁。</p>
<p>InnoDB的行锁是实现在索引上的，而不是锁在物理行记录上。潜台词是，如果访问没有命中索引，也无法使用行锁，将要退化为表锁。</p>
</li>
<li>
<p><strong>是否⽀持事务和崩溃后的安全恢复</strong>： MyISAM 强调的是性能，每次查询具有原⼦性,其执⾏速度⽐InnoDB类型更快，但是不提供事务⽀持。但是InnoDB 提供事务⽀持事务，外部键等⾼级数据库功能。 具有事务(commit)、回滚(rollback)和<strong>崩溃修复能⼒</strong>(crashrecoverycapabilities)的事务安全(transaction-safe (ACID compliant))型表。</p>
</li>
<li>
<p><strong>是否⽀持外键</strong>： MyISAM不⽀持，⽽InnoDB⽀持</p>
</li>
<li>
<p><strong>是否⽀持MVCC</strong> ：仅 InnoDB ⽀持。应对⾼并发事务, MVCC⽐单纯的加锁更⾼效;MVCC只在 READ COMMITTED 和 REPEATABLE READ 两个隔离级别下⼯作;MVCC可以使⽤ 乐观(optimistic)锁 和 悲观(pessimistic)锁来实现;各数据库中MVCC实现并不统⼀。</p>
</li>
<li>
<p>I<strong>nnoDB是聚集索引</strong>，使用B+Tree作为索引结构，数据文件是和（主键）索引绑在一起的（表数据文件本身就是按B+Tree组织的一个索引结构），必须要有主键，通过主键索引效率很高。但是<strong>辅助索引需要两次查询</strong>，先查询到主键，然后再通过主键查询到数据。因此，主键不应该过大，因为主键太大，其他索引也都会很大。</p>
<p>MyISAM是非聚集索引，也是使用B+Tree作为索引结构，<strong>索引和数据文件是分离</strong>的，索引保存的是数据文件的<strong>指针</strong>。主键索引和辅助索引是独立的。</p>
<p>也就是说：InnoDB的B+树<strong>主键索引的叶子节点就是数据文件</strong>，<strong>辅助索引的叶子节点是主键的值</strong>；而MyISAM的B+树主键索引和辅助索引的叶子节点都是数据文件的地址指针。</p>
</li>
</ol>
<figure data-type="image" tabindex="1"><img src="https://img-blog.csdn.net/20180923094753224?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM1NjQyMDM2/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="img" loading="lazy"></figure>
<figure data-type="image" tabindex="2"><img src="https://img-blog.csdn.net/20180923094753230?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM1NjQyMDM2/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="img" loading="lazy"></figure>
<p>​	6.<strong>Innodb不支持全文索引，而MyISAM支持全文索引，在涉及全文索引领域的查询效率上MyISAM速度更快高；PS：5.7以后的InnoDB支持全文索引了</strong></p>
<p>​	7.<strong>MyISAM表格可以被压缩后进行查询操作</strong></p>
<p>​	8.<strong>InnoDB表必须有唯一索引（如主键）（用户没有指定的话会自己找/生产一个隐藏列Row_id来充当默认主键），而Myisam可以没有</strong></p>
<p>​	9.<strong>Innodb存储文件有frm、ibd，而Myisam是frm、MYD、MYI</strong></p>
<p>​    <strong>Innodb：frm是表定义文件，ibd是数据文件</strong></p>
<p>​    <strong>Myisam：frm是表定义文件，myd是数据文件，myi是索引文件</strong></p>
<h3 id="如何在两者之间选择">如何在两者之间选择</h3>
<ol>
<li>是否要支持事务，如果要请选择innodb，如果不需要可以考虑MyISAM；</li>
<li>如果表中绝大多数都只是读查询，可以考虑MyISAM，如果既有读也有写，请使用InnoDB。</li>
<li>系统奔溃后，MyISAM恢复起来更困难，能否接受；</li>
<li>MySQL5.5版本开始Innodb已经成为Mysql的默认引擎(之前是MyISAM)，说明其优势是有目共睹的，如果你不知道用什么，那就用InnoDB，至少不会差。</li>
</ol>
<h3 id="innodb为什么推荐使用自增id作为主键">InnoDB为什么推荐使用自增ID作为主键？</h3>
<p><strong>答：自增ID可以保证每次插入时B+索引是从右边扩展的，可以避免B+树和频繁合并和分裂（对比使用UUID）。如果使用字符串主键和随机主键，会使得数据随机插入，效率比较差。</strong></p>
<h3 id="innodb引擎的4大特性"><strong>innodb引擎的4大特性</strong></h3>
<ul>
<li><strong>插入缓冲（insert buffer)</strong></li>
<li><strong>二次写(double write)</strong></li>
<li><strong>自适应哈希索引(ahi)</strong></li>
<li><strong>预读(read ahead)</strong></li>
</ul>
<h3 id="innodb如何保证事务的原子性-持久性和一致性">InnoDB如何保证事务的原子性、持久性和一致性？</h3>
<ul>
<li>
<p><strong>undo log保障原子性</strong>。该log保存了事务发生之前的数据的一个版本，可以用于回滚，从而保证事务原子性。</p>
</li>
<li>
<p><strong>redo log保证事务的持久性</strong>，该log关注于事务的恢复.在重启mysql服务的时候，根据redo log进行重做，从而使事务有持久性。</p>
</li>
<li>
<p><strong>undo log+redo log保障一致性</strong>。事务中的执行需要redo log，如果执行失败，需要undo log 回滚。</p>
</li>
</ul>
<h3 id="hash索引和b树索引">Hash索引和B+树索引</h3>
<p>首先要知道Hash索引和B+树索引的底层实现原理:</p>
<p>hash索引底层就是hash表,进行查找时,调用一次hash函数就可以获取到相应的键值,之后进行回表查询获得实际数据.</p>
<p>B+树底层实现是多路平衡查找树.对于每一次的查询都是从根节点出发,查找到叶子节点方可以获得所查键值,然后根据查询判断是否需要回表查询数据.</p>
<p><strong>不同点</strong>:</p>
<ul>
<li>hash索引进行等值查询更快(一般情况下),但是却无法进行范围查询.</li>
</ul>
<p>因为在hash索引中经过hash函数建立索引之后,索引的顺序与原顺序无法保持一致,不能支持范围查询.而B+树的的所有节点皆遵循(左节点小于父节点,右节点大于父节点,多叉树也类似),天然支持范围.</p>
<ul>
<li>hash索引不支持模糊查询以及多列索引的最左前缀匹配.原理也是因为hash函数的不可预测.<strong>AAAA</strong>和<strong>AAAAB</strong>的索引没有相关性.</li>
<li>hash索引任何时候都避免不了回表查询数据,而B+树在符合某些条件(聚簇索引,覆盖索引等)的时候可以只通过索引完成查询.</li>
<li>hash索引虽然在等值查询上较快,但是不稳定.性能不可预测,当某个键值存在<strong>大量重复</strong>的时候,发生hash碰撞,此时效率可能极差.而B+树的查询效率比较稳定,对于所有的查询都是从根节点到叶子节点,且树的高度较低.</li>
</ul>
<p>因此,在大多数情况下,直接选择B+树索引可以获得<strong>稳定且较好</strong>的查询速度.而不需要使用hash索引.</p>
<h3 id="为什么使用b树">为什么使用B+树</h3>
<ul>
<li>虽然哈希索引是O(1)，树索引是O(log(n))，但SQL有很多“有序”需求，故数据库使用树型索引</li>
<li>很适合磁盘存储，能够充分利用<strong>局部性原理，磁盘预读</strong>
<ul>
<li><strong>局部性原理</strong>：软件设计要尽量遵循“数据读取集中”与“使用到一个数据，大概率会使用其附近的数据”，这样磁盘预读能充分提高磁盘IO</li>
<li><strong>数据预读</strong>：磁盘读写并不是按需读取，而是按页预读，一次会读一页的数据，每次加载更多的数据，以便未来减少磁盘IO</li>
</ul>
</li>
<li><strong>很低的树高度，能够存储大量数据，同时能有效的减少IO操作</strong>。</li>
<li><strong>索引本身占用的内存很小</strong></li>
<li>能够很好的支持<strong>单点查询，范围查询，有序性查询</strong></li>
<li><strong>查询效率稳定</strong></li>
<li>B+树存放数据数计算（https://blog.csdn.net/csdnlijingran/article/details/102309593）</li>
<li>不用B树的原因是因为<strong>B树不支持范围查找</strong>，B+树的范围查找只需要遍历叶子节点就行，而B树则需要中序遍历</li>
</ul>
<h2 id="一颗b树能存多少数据">一颗B+树能存多少数据</h2>
<p>https://blog.csdn.net/weixin_51867896/article/details/122799836</p>
<h2 id="字符集及校对规则">字符集及校对规则</h2>
<p>字符集指的是⼀种从⼆进制编码到某类字符符号的映射。校对规则则是指某种字符集下的排序规则。MySQL中每⼀种字符集都会对应⼀系列的校对规则。</p>
<p>MySQL采⽤的是类似继承的⽅式指定字符集的默认值，每个数据库以及每张数据表都有⾃⼰的默认值，他们逐层继承。⽐如：某个库中所有表的默认字符集将是该数据库所指定的字符集（这些表在没有指定字符集的情况下，才会采⽤默认字符集）</p>
<h2 id="查询缓存的使用">查询缓存的使⽤</h2>
<p>执⾏查询语句的时候，会先查询缓存。不过，MySQL 8.0 版本后移除，因为这个功能不太实⽤</p>
<p><strong>my.cnf</strong>加⼊以下配置，重启MySQL开启查询缓存</p>
<pre><code class="language-mysql">query_cache_size = 30M

query_cache_type=1
</code></pre>
<p>MySQL执⾏以下命令也可以开启查询缓存</p>
<figure data-type="image" tabindex="3"><img src="https://i.imgtg.com/2023/02/14/dqZTt.png" alt="dqZTt.png" loading="lazy"></figure>
<p><strong>开启查询缓存后在同样的查询条件以及数据情况下，会直接在缓存中返回结果</strong>。</p>
<p>这⾥的查询条件包括查询本身、当前要查询的数据库、客户端协议版本号等⼀些可能影响结果的信息。因此任何两个查询在任何字符上的不同都会导致缓存不命中。</p>
<p>此外，如果查询中包含任何⽤户⾃定义函数、存储函数、⽤户变量、临时表、MySQL库中的系统表，其查询结果也不会被缓存。</p>
<p>缓存建⽴之后，MySQL的查询缓存系统会跟踪查询中涉及的每张表，如果这些表（数据或结构）发⽣变化，那么和这张表相关的所有缓存数据都将失效。</p>
<p><strong>缓存虽然能够提升数据库的查询性能，但是缓存同时也带来了额外的开销，每次查询后都要做⼀次缓存操作，失效后还要销毁</strong>。</p>
<p>因此，开启缓存查询要谨慎，尤其对于写密集的应⽤来说更是如此。如果开启，要注意合理控制缓存空间⼤⼩，⼀般来说其⼤⼩设置为<strong>⼏⼗MB</strong>比较合适。</p>
<p>此外，还可以通过<strong>sql_cache和sql_no_cache</strong>来控制某个查询语句是否需要缓存</p>
<h2 id="事务">事务</h2>
<h3 id="什么是事务">什么是事务?</h3>
<p>事务是逻辑上的⼀组操作，要么都执⾏，要么都不执⾏。</p>
<h3 id="事物的四大特性acid">事物的四⼤特性(ACID)</h3>
<p>1**.原⼦性（Atomicity**）： 事务是最⼩的执⾏单位，不允许分割。事务的原⼦性确保动作要么	全部完成，要么完全不起作⽤；</p>
<ol start="2">
<li><strong>⼀致性（Consistency）</strong>： 执⾏事务前后，数据保持⼀致，多个事务对同⼀个数据读取的结果是相同的；</li>
<li><strong>隔离性（Isolation）</strong>： 并发访问数据库时，⼀个⽤户的事务不被其他事务所⼲扰，各并发事务之间数据库是独⽴的；</li>
<li><strong>持久性（Durability</strong>）： ⼀个事务被提交之后。它对数据库中数据的改变是持久的，即使数据库发⽣故障也不应该对其有任何影响。</li>
</ol>
<h3 id="并发事务带来哪些问题">并发事务带来哪些问题?</h3>
<ul>
<li><strong>脏读(Dirty read</strong>): 当一个事务正在访问数据并且对数据进行了修改,而这种修改还没有提 交到数据库中,这时另外一个事务也访问了这个数据,然后使用了这个数据。因为这个数据 是还没有提交的数据,那么另外一个事务读到的这个数据是“脏数据”,依据“脏数据”所做的 操作可能是不正确的。<strong>一改一读</strong></li>
<li><strong>丢失修改(Lost to modify)</strong>: 指在一个事务读取一个数据时,另外一个事务也访问了该数 据,那么在第一个事务中修改了这个数据后,第二个事务也修改了这个数据。这样第一个事 务内的修改结果就被丢失,因此称为丢失修改。 例如:事务1读取某表中的数据A=20,事 务2也读取A=20,事务1修改A=A-1,事务2也修改A=A-1,最终结果A=19,事务1的修改被丢失。<strong>两个改</strong></li>
<li><strong>不可重复读(Unrepeatable read):</strong> 指在一个事务内多次读同一数据。在这个事务还没有结 束时,另一个事务也访问该数据。那么,在第一个事务中的两次读数据之间,由于第二个事 务的修改导致第一个事务两次读取的数据可能不太一样。这就发生了在一个事务内两次读到 的数据是不一样的情况,因此称为不可重复读。<strong>一改一读</strong></li>
<li><strong>幻读(Phantom read)</strong>: 幻读与不可重复读类似。它发 生在一个事务(T1)读取了几行数 据,接着另一个并发事务(T2)插入了一些数据时。在随后的查询中,第一个事务(T1) 就会发现多了一些原本不存在的记录,就好像发生了幻觉一样,所以称为幻读。<strong>一改一读</strong>
<ul>
<li><strong>不可重复读的重点</strong>是修改比如多次读取一条记录发现其中某些列的值被修改,幻读的重点在于新增或者删除比如多次读取一条记录发现记录增多或减少了。</li>
<li><strong>幻读的问题存在</strong>是因为新增或者更新操作，这时如果进<strong>行范围查询的时候</strong>（加锁查询），会出现不一致的问题</li>
</ul>
</li>
</ul>
<h3 id="事务隔离级别有哪些mysql的默认隔离级别是">事务隔离级别有哪些?MySQL的默认隔离级别是?</h3>
<ul>
<li>
<p>READ-UNCOMMITTED(<strong>读取未提交</strong>)： 最低的隔离级别，允许读取尚未提交的数据变更，可能会导致脏读、幻读或不可重复读。</p>
<ul>
<li><strong>一个事务还没提交，它做的变更就能被别的事务看到</strong></li>
</ul>
</li>
<li>
<p>READ-COMMITTED(<strong>读取已提交</strong>)： 允许读取并发事务已经提交的数据，可以阻⽌脏读，但是幻读或不可重复读仍有可能发⽣。</p>
<ul>
<li><strong>一个事务提交后，它做的变更才能被别的事务看到</strong></li>
</ul>
</li>
<li>
<p>REPEATABLE-READ(<strong>可重复读</strong>)： 对同⼀字段的多次读取结果都是⼀致的，除⾮数据是被本身事务⾃⼰所修改，可以阻⽌脏读和不可重复读，但幻读仍有可能发⽣</p>
<ul>
<li><strong>一个事务执行过程中看到的数据总是和事务启动时看到的数据是一致的。在这个级别下事务未提交，做出的变更其它事务也看不到</strong>。</li>
</ul>
</li>
<li>
<p>SERIALIZABLE(<strong>可串⾏化</strong>)： 最⾼的隔离级别，完全服从ACID的隔离级别。所有的事务依次逐个执⾏，这样事务之间就完全不可能产⽣⼲扰，也就是说，该级别可以防⽌脏读、不可重复读以及幻读。</p>
<ul>
<li><strong>对于同一行记录进行读写会分别加读写锁，当发生读写锁冲突，后面执行的事务需等前面执行的事务完成才能继续执行。</strong><br>
<img src="https://i.imgtg.com/2023/02/14/dqvvx.png" alt="dqvvx.png" loading="lazy"></li>
</ul>
</li>
</ul>
<p>MySQL InnoDB 存储引擎的<strong>默认</strong>⽀持的隔离级别是 <strong>REPEATABLE-READ（可重读</strong>）.</p>
<p><strong>SELECT @@tx_isolation</strong>查看支持的默认的隔离级别</p>
<figure data-type="image" tabindex="4"><img src="https://i.imgtg.com/2023/02/14/dqmOp.png" alt="dqmOp.png" loading="lazy"></figure>
<p>这⾥需要注意的是：与 SQL 标准不同的地⽅在于 InnoDB 存储引擎在 <strong>REPEATABLE-READ（可重读）</strong></p>
<p>事务隔离级别下使⽤的是<strong>Next-Key Lock 锁算法，因此可以避免幻读的产⽣</strong>，这与其他数据库系统(如 SQL Server)是不同的。</p>
<p>所以说InnoDB 存储引擎的默认⽀持的隔离级别是 REPEATABLE-READ（可重读）已经可以完全保证事务的隔离性要求，即达到了SQL标准的 SERIALIZABLE(可串⾏化) 隔离级别。</p>
<p>因为隔离级别越低，事务请求的锁越少，所以⼤部分数据库系统的隔离级别都READCOMMITTED(读取提交内容) ，但是你要知道的是InnoDB 存储引擎默认使⽤ REPEAaTABLE-READ（可重读） 并不会有任何性能损失。</p>
<p>InnoDB 存储引擎在 <strong>分布式事务</strong> 的情况下⼀般会⽤到 <strong>SERIALIZABLE(可串⾏化)</strong> 隔离级别。</p>
<h3 id="可重复读的实现原理">可重复读的实现原理</h3>
<p><em>Repeatable Read</em>（可重复读）：一个事务在执行过程中可以看到其他事务已经提交的新插入的记录（读已经提交的，其实是读早于本事务开始且已经提交的），<strong>但是不能看到其他事务对已有记录的更新（即晚于本事务开始的）</strong>，并且，该事务不要求与其他事务是“可串行化”的。</p>
<p><strong>简单的来说就是当前事务在堆当前的某条数据在其他事务的影响下重读的结果是一样的</strong></p>
<p><strong>解决方法</strong></p>
<p>使用MVCC（多版本并发控制）。<strong>InnoDB为每行记录添加了一个版本号（系统版本号</strong>），每当修改数据时，版本号加一。<br>
在读取事务开始时，系统会给事务一个当前版本号，<strong>事务会读取版本号&lt;=当前版本号的数</strong>据，这时就算另一个事务插入一个数据，并立马提交，新插入这条数据的版本号会比读取事务的版本号高，因此读取事务读的数据还是不会变。</p>
<p>InnoDB 的可重复读的实现，利用了实现 MVCC 技术的快照技术。这是 MVCC 和基于封锁技术这两个并非控制技术的结合之处。</p>
<p>在<em>RR</em>隔离级别下为事务设置了一个“一致性读视图（即快照）”，之后读取数据，就是根据这个快照来获取，这样，就不能看到他晚于本事务的事务对已有记录的更新（更新生成新版本，必然不在旧的快照所限定的范围内）。</p>
<p>根据隔离级别判断是不是要使用一个新的快照，如果是可重复读，则不使用新快照，沿用老的快照，这样就能保证所有的读操作看到的是同一个数据状态；同时也确保了读已提交隔离级别下一个事务块内的不同语句的读操作看到的不是同一个数据状态。</p>
<p>总结：</p>
<p>参考 https://blog.csdn.net/huanghanqian/article/details/79517480</p>
<h2 id="mysql锁">Mysql锁</h2>
<p>按锁粒度分类：<br>
1. ⾏锁：锁某⾏数据，锁粒度最⼩，并发度⾼<br>
2. 表锁：锁整张表，锁粒度最⼤，并发度低<br>
3. <strong>间隙锁</strong>：锁的是⼀个区间</p>
<p>还可以分为：<br>
1. 共享锁：也就是读锁，⼀个事务给某⾏数据加了读锁，其他事务也可以读，但是不能写<br>
2. 排它锁：也就是写锁，⼀个事务给某⾏数据加了写锁，其他事务不能读，也不能写</p>
<p>还可以分为：<br>
1. 乐观锁：并不会真正的去锁某⾏记录，⽽是通过⼀个版本号来实现的<br>
2. 悲观锁：上⾯所的⾏锁、表锁等都是悲观锁</p>
<p>在事务的隔离级别实现中，就需要利⽤锁来解决幻读</p>
<h3 id="锁机制与innodb锁算法">锁机制与InnoDB锁算法</h3>
<p><strong>MyISAM和InnoDB存储引擎使⽤的锁：</strong></p>
<ul>
<li>MyISAM采⽤表级锁(table-level locking)。</li>
<li>InnoDB⽀持⾏级锁(row-level locking)和表级锁,默认为⾏级锁</li>
</ul>
<p><strong>表级锁和⾏级锁对⽐：</strong></p>
<ul>
<li>表级锁： MySQL中锁定 <strong>粒度最⼤</strong> 的⼀种锁，对当前操作的整张表加锁，实现简单，资源消<br>
耗也比较少，加锁快，不会出现死锁。其锁定粒度最⼤，触发锁冲突的概率最⾼，并发度最<br>
低，MyISAM和 InnoDB引擎都⽀持表级锁。</li>
<li>⾏级锁： MySQL中锁定 <strong>粒度最⼩</strong> 的⼀种锁，只针对当前操作的⾏进⾏加锁。 ⾏级锁能⼤<br>
⼤减少数据库操作的冲突。其加锁粒度最⼩，并发度⾼，但加锁的开销也最⼤，加锁慢，会<br>
出现死锁。</li>
</ul>
<p><strong>InnoDB存储引擎的锁的算法有三种：</strong></p>
<ul>
<li>Record lock：<strong>单个⾏记录上的锁</strong></li>
<li>Gap lock：<strong>间隙锁，锁定⼀个范围，不包括记录本身 目的是为了防止同一个事物的两次当前读，出现幻读的情况</strong></li>
<li>Next-key lock：<strong>record+gap 锁定⼀个范围，包含记录本身</strong></li>
</ul>
<p><strong>相关知识点</strong></p>
<ol>
<li>innodb对于⾏的查询使⽤next-key lock</li>
<li>Next-locking keying为了解决Phantom Problem幻读问题</li>
<li>当查询的索引含有唯⼀属性时，将next-key lock降级为record key</li>
<li><strong>Gap锁设计的⽬的是为了阻⽌多个事务将记录插⼊到同⼀范围内，⽽这会导致幻读问题的产⽣</strong></li>
<li>有两种⽅式显式关闭gap锁：（除了外键约束和唯⼀性检查外，其余情况仅使⽤recordlock）  不推荐
<ol>
<li>将事务隔离级别设置为RC(可重复读)</li>
<li>将参数innodb_locks_unsafe_for_binlog设置为1</li>
</ol>
</li>
</ol>
<h2 id="间隙锁死锁">间隙锁死锁</h2>
<p>https://blog.csdn.net/java_beautiful/article/details/125572280</p>
<h3 id="mysql中的按粒度的锁分类">MySQL中的按粒度的锁分类</h3>
<ul>
<li>
<p>表级锁: 对当前操作的整张表加锁,实现简单，加锁快，但并发能力低。</p>
</li>
<li>
<p>行锁: 锁住某一行，如果表存在索引，那么记录锁是锁在索引上的，如果表没有索引，那么 InnoDB 会创建一个隐藏的聚簇索引加锁。行级锁能大大减少数据库操作的冲突。其加锁粒度最小，并发度高，但加锁的开销也最大，加锁慢，会出现死锁。</p>
</li>
<li>
<p>Gap 锁：也称为间隙锁: 锁定一个范围但不包括记录本身。其目的是为了防止同一事物的两次当前读出现幻读的情况。</p>
</li>
<li>
<p>Next-key Lock： 行锁+gap锁。</p>
</li>
</ul>
<h3 id="如何解决数据库死锁">如何解决数据库死锁</h3>
<ol>
<li><strong>预先检测到死锁的循环依赖，并立即返回一个错误</strong>。</li>
<li><strong>当查询的时间达到锁等待超时的设定后放弃锁请求</strong>。</li>
</ol>
<h2 id="解释一下什么是池化设计思想-什么是数据库连接池-为什么需要数据库连接池">解释⼀下什么是池化设计思想 什么是数据库连接池 为什么需要数据库连接池</h2>
<p>池化设计应该不是⼀个新名词。我们常⻅的如java线程池、jdbc连接池、redis连接池等就是这类设计的代表实现。</p>
<p>这种设计会初始预设资源，解决的问题就是抵消每次获取资源的消耗，如创建线程的开销，获取远程连接的开销等。就好⽐你去⻝堂打饭，打饭的⼤妈会先把饭盛好⼏份放那⾥，你来了就直接拿着饭盒加菜即可，不⽤再临时⼜盛饭⼜打菜，效率就⾼了。</p>
<p>除了初始化资源，池化设计还包括如下这些特征：池⼦的初始值、池⼦的活跃值、池⼦的最⼤值等，这些特征可以直接映射到java线程池和数据库连接池的成员属性中。</p>
<p><strong>数据库连接本质就是⼀个 socket 的连接</strong>。数据库服务端还要维护⼀些缓存和⽤户权限信息之类的 所以占⽤了⼀些内存。我们可以把数据库连接池是看做是<strong>维护的数据库连接的缓存</strong>，以便将来需要对数据库的请求时可以重⽤这些连接。为每个⽤户打开和维护数据库连接，尤其是对动态数据库驱动的⽹站应⽤程序的请求，既昂贵⼜浪费资源。</p>
<p><strong>在连接池中，创建连接后，将其放置在池</strong>中，<strong>并再次使⽤它，因此不必建⽴新的连接。如果使⽤了所有连接，则会建⽴⼀个新连接并将其添加到池中</strong>。 连接池还减少了⽤户必须等待建⽴与数据库的连接的时间。</p>
<h2 id="分库分表之后id-主键如何处理">分库分表之后,id 主键如何处理</h2>
<p>因为要是分成多个表之后，每个表都是从 1 开始累加，这样是不对的，我们需要⼀个全局唯⼀的id 来⽀持。<br>
<strong>⽣成全局 id 有下⾯这⼏种⽅式：</strong></p>
<ul>
<li>
<p><strong>UUID</strong>：不适合作为主键，因为太⻓了，并且⽆序不可读，查询效率低。比较适合⽤于⽣成唯⼀的名字的标示⽐如⽂件的名字。</p>
</li>
<li>
<p><strong>数据库⾃增 id</strong> : 两台数据库分别设置不同步⻓，⽣成不重复ID的策略来实现⾼可⽤。这种⽅式⽣成的 id 有序，但是需要独⽴部署数据库实例，成本⾼，还会有性能瓶颈。</p>
</li>
<li>
<p><strong>利⽤ redis ⽣成 id</strong> : 性能比较好，灵活⽅便，不依赖于数据库。但是，引⼊了新的组件造成系统更加复杂，可⽤性降低，编码更加复杂，增加了系统成本。</p>
</li>
<li>
<p><strong>Twitter的snowflake算法</strong> ：Github 地址：https://github.com/twitter-archive/snowflake。</p>
</li>
<li>
<p><strong>美团的Leaf分布式ID⽣成系统</strong> ：Leaf 是美团开源的分布式ID⽣成器，能保证全局唯⼀性、趋势递增、单调递增、信息安全，⾥⾯也提到了⼏种分布式⽅案的对⽐，但也需要依赖关系数据库、Zookeeper等中间件。感觉还不错。</p>
<ul>
<li>美团技术团队的⼀篇⽂章：https://tech.meituan.com/2017/04/21/mt-leaf.html 。</li>
</ul>
</li>
</ul>
<h2 id="一条sql语句执行得很慢的原因有哪些">⼀条SQL语句执⾏得很慢的原因有哪些</h2>
<p>参考连接：https://www.cnblogs.com/kubidemanong/p/10734045.html</p>
<p>1、大多数情况下很正常，<strong>偶尔很慢</strong>，则有如下原因</p>
<p>(1)、<strong>数据库在刷新脏页</strong>，例如 redo log 写满了需要同步到磁盘。</p>
<p>(2)、<strong>执行的时候</strong>，<strong>遇到锁</strong>，如表锁、行锁。</p>
<p>2、这条 SQL 语句一直执行的很慢，则有如下原因。</p>
<p>(1)、<strong>没有用上索引</strong>：例如该字段没有索引导致走全表扫描；由于对字段进行运算（select * from t where c - 1 = 1000;）、函数操作（pow(c,2) = 1000;）导致无法用索引。</p>
<p>(2)、<strong>数据库选错了索引</strong>。</p>
<h2 id="索引">索引</h2>
<h3 id="mysql有哪些常见索引类型">Mysql有哪些常见索引类型？</h3>
<ul>
<li>
<p>数据结构角度</p>
<p>B-Tree索引</p>
<p>哈希索引</p>
<p>R-Tree索引</p>
<p>全文索引</p>
</li>
<li>
<p>物理存储角度</p>
<p>主键索引（聚簇索引）：叶子节点存的是整行的数据</p>
<p>非主键索引（二级索引）：叶子节点存的主键的值</p>
</li>
</ul>
<h3 id="在哪些情况下会发生针对该列创建了索引但是在查询的时候并没有使用呢"><strong>在哪些情况下会发生针对该列创建了索引但是在查询的时候并没有使用呢?</strong></h3>
<ul>
<li>
<p>使用不等于查询,</p>
</li>
<li>
<p>不匹配最左前缀原则</p>
</li>
<li>
<p>列参与了数学运算或者函数</p>
</li>
<li>
<p>在字符串like时左边是通配符.类似于'%aaa'.</p>
</li>
<li>
<p>当mysql分析<strong>全表扫描比使用索引快的时候不使用索引</strong></p>
</li>
<li>
<p>当使用联合索引,前面一个条件为范围查询,后面的即使符合最左前缀原则,也无法使用索引</p>
<p>参考https://blog.csdn.net/c1776167012/article/details/120788728</p>
</li>
</ul>
<h3 id="简述hash索引">简述Hash索引</h3>
<p>哈希索引对于<strong>每一行数据计算一个哈希码</strong>，<strong>并将所有的哈希码存储在索引中</strong>，同时在哈希表中保存指向每个数据行的指针。只有 Memory 引擎显式支持哈希索引。</p>
<p>Hash索引<strong>不支持范围查询</strong>，无法用于<a href="">排序</a>，也不支持部分索引列匹配查找。</p>
<h3 id="简述自适应hash索引">简述自适应Hash索引</h3>
<p><strong>InnoDB对于频繁使用的某些索引值，会在内存中基于 B-Tree 索引之上再创键一个哈希索引，这也被称为自适应Hash索引。</strong></p>
<h3 id="简述聚集索引和稀疏索引">简述聚集索引和稀疏索引</h3>
<p>聚集索引按每张表的主键构建一棵B+树，数据库中的每个搜索键值都有一个索引记录，每个数据页通过双向链表连接。表数据访问更快，但表更新代价高。</p>
<p>稀疏索引不会为每个搜索关键字创建索引记录。搜索过程需要，我们<strong>首先按索引记录进行操作</strong>，并按顺序搜索，直到找到所需的数据为止。</p>
<h3 id="简述辅助索引与回表查询">简述辅助索引与回表查询</h3>
<p>辅助索引是非聚集索引，叶子节点不包含记录的全部数据，<strong>包含了一个书签用来告诉InnoDB哪里可以找到与索引相对应的行数据</strong>。</p>
<p>通过辅助索引查询，先通过书签查到聚集索引，再根据聚集索引查对应的值，需要两次，也称为<strong>回表查询</strong>。</p>
<h3 id="简述联合索引和最左匹配原则">简述联合索引和最左匹配原则</h3>
<p><strong>联合索引是指对表上的多个列的关键词进行索引</strong>。</p>
<p>对于联合索引的查询，如果精确匹配联合索引的左边连续一列或者多列，则mysql会一直向右匹配直到遇到范围查询（&lt;,between,like）就停止匹配。Mysql会对第一个索引字段数据进行排序，在第一个字段基础上，再对第二个字段排序。</p>
<p>参考：https://blog.csdn.net/sinat_41917109/article/details/88944290</p>
<figure data-type="image" tabindex="5"><img src="https://i.imgtg.com/2023/02/14/dqpNU.png" alt="dqpNU.png" loading="lazy"></figure>
<h3 id="简述覆盖索引">简述覆盖索引</h3>
<p>**覆盖索引指一个索引包含或覆盖了所有需要查询的字段的值，**不需要回表查询，即索引本身存了对应的值。</p>
<h3 id="基于主键索引的查询和非主键索引的查询有什么区别">基于主键索引的查询和非主键索引的查询有什么区别？</h3>
<p>对于select * from 主键=XX，基于主键的普通查询仅查找主键这棵树</p>
<p>对于select * from 非主键=XX，基于非主键的查询有可能存在回表过程（回到主键索引树搜索的过程称为回表）<strong>，因为非主键索引叶子节点仅存主键值，无整行全部信息。</strong></p>
<h3 id="非主键索引的查询一定会回表吗">非主键索引的查询一定会回表吗？</h3>
<p>不一定，当查询语句的要求字段全部命中索引，不用回表查询。<strong>如select 主键 from 非主键=XX，此时非主键索引叶子节点即可拿到主键信息，不用回表。</strong></p>
<h2 id="为什么数据库不用红黑树-用b树">为什么数据库不用红黑树 用B+树</h2>
<p>红黑树的出度为 2，而 B Tree 的出度一般都非常大**。红黑树的树高 h 很明显比 B Tree 大非常多，IO次数很多，导致会比较慢，因此检索的次数也就更多**。</p>
<p><strong>B+Tree 相比于 B-Tree 更适合外存索引，拥有更大的出度</strong>，IO次数较少，检索效率会更高。</p>
<h3 id="创建的索引有没有被使用到或者说怎么才可以知道这条语句运行很慢的原因"><strong>创建的索引有没有被使用到?或者说怎么才可以知道这条语句运行很慢的原因?</strong></h3>
<p>MySQL提供了<strong>explain</strong>命令来查看语句的执行计划,MySQL在执行某个语句之前,会将该语句过一遍查询优化器,之后会拿到对语句的分析,也就是执行计划,其中包含了许多信息. <strong>可以通过其中和索引有关的信息来分析是否命中了索引</strong>,例如possilbe_key,key,key_len等字段,分别说明了此语句可能会使用的索引,实际使用的索引以及使用的索引长度.</p>
<h3 id="主键索引和唯一索引的区别">主键索引和唯一索引的区别</h3>
<p>1.主键为一种约束，唯一索引为一种索引，本质上就不同；</p>
<p>2.主键创建后一定包含唯一性索引，而唯一索引不一定就是主键；</p>
<p>3.主键不允许空值，唯一索引可以为空；</p>
<p>4.<strong>主键可以被其他表引用，而唯一索引不可以</strong>；</p>
<p>5.一个表最多只能创建一个主键，而可以创建多个唯一索引；</p>
<p>6.主键和索引都是键，<strong>主键是逻辑键</strong>，索引为物理键，即主键不实际存在。</p>
<h2 id="简述mysql使用explain-的关键字段">简述MySQL使用EXPLAIN 的关键字段</h2>
<p>explain关键字用于分析sql语句的执行情况，可以通过他进行sql语句的性能分析。</p>
<p>type：表示连接类型，从好到差的类型<a href="">排序</a>为</p>
<ul>
<li>system：系统表，数据已经加载到内存里。</li>
<li>const：常量连接，通过索引一次就找到。</li>
<li>eq_ref：唯一性索引扫描，返回所有匹配某个单独值的行。</li>
<li>ref：非主键非唯一索引等值扫描，const或eq_ref改为普通非唯一索引。</li>
<li>range：范围扫描，在索引上扫码特定范围内的值。</li>
<li>index：索引树扫描，扫描索引上的全部数据。</li>
<li>all：全表扫描。</li>
</ul>
<p>key：显示MySQL实际决定使用的键。</p>
<p>key_len：显示MySQL决定使用的键长度，长度越短越好</p>
<p>Extra：额外信息</p>
<ul>
<li>Using filesort：MySQL使用外部的索引<a href="">排序</a>，很慢需要优化。</li>
<li>Using temporary：使用了临时表保存中间结果，很慢需要优化。</li>
<li>Using index：使用了覆盖索引。</li>
<li>Using where：使用了where。</li>
</ul>
<h2 id="mysql插入数据的流程">MySQL插入数据的流程</h2>
<p>https://blog.csdn.net/zhaoliang831214/article/details/82711350</p>
<p>https://blog.csdn.net/weixin_40581617/article/details/80623276</p>
<ol>
<li><strong>会话状态转换为update</strong></li>
<li><strong>激活事物状态由 not_active 变为 active</strong></li>
<li><strong>查找定位数据</strong></li>
<li><strong>进行乐观插入</strong></li>
</ol>
<h2 id="mysql语句执行流程">Mysql语句执行流程</h2>
<ul>
<li>
<p>流程：</p>
<ul>
<li>
<p><strong>连接器：</strong> 身份认证和权限相关(登录 MySQL 的时候)。</p>
</li>
<li>
<p><strong>查询缓存:</strong> 执行查询语句的时候，会先查询缓存（MySQL 8.0 版本后移除，因为这个功能不太实用）。</p>
</li>
<li>
<p><strong>分析器</strong>:</p>
<p>没有命中缓存的话，SQL 语句就会经过分析器，分析器说白了就是要先看你的 SQL 语句要干嘛，再检查你的 SQL 语句语法是否正确。</p>
<ul>
<li><strong>第一步，词法分析</strong>，一条 SQL 语句有多个字符串组成，首先要<strong>提取关键字</strong>，比如 select，提出查询的表，提出字段名，提出查询条件等等。做完这些操作后，就会进入第二步。</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>第二步，语法分析</strong>，主要就是<strong>判断你输入的 sql 是否正确</strong>，是否符合 MySQL 的语法。完成这 2 步之后，MySQL 就准备开始执行了，但是如何执行，怎么执行是最好的结果呢？这个时候就需要优化器上场了。</p>
<ul>
<li>
<p><strong>优化器</strong>：</p>
<p>按照 MySQL 认为最优的方案去执行。</p>
<ul>
<li>https://zhuanlan.zhihu.com/p/192707721</li>
</ul>
</li>
<li>
<p>MySQL 会帮我去使用他自己认为的最好的方式去优化这条 SQL 语句，并生成一条条的执行计划。</p>
<ul>
<li>创建了多个索引，MySQL 会依据成本最小原则来选择使用对应的索引，这里的成本主要包括两个方面, IO 成本和 CPU 成本
<ul>
<li><strong>IO 成本</strong>: 即从磁盘把数据加载到内存的成本，默认情况下，读取数据页的 IO 成本是 1，MySQL 是以页的形式读取数据的，即当用到某个数据时，并不会只读取这个数据，而会把这个数据相邻的数据也一起读到内存中，这就是有名的程序局部性原理，所以 MySQL 每次会读取一整页，一页的成本就是 1。所以 IO 的成本主要和页的大小有关</li>
<li><strong>CPU 成本</strong>：将数据读入内存后，还要检测数据是否满足条件和排序等 CPU 操作的成本，显然它与行数有关，默认情况下，检测记录的成本是 0.2。</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>执行器:</strong> 执行语句，然后从存储引擎返回数据。</p>
</li>
</ul>
</li>
</ul>
<figure data-type="image" tabindex="6"><img src="http://note.mxecy.cn/docs/%E5%9B%BE%E7%89%87/MySql/Mysql%E6%9F%A5%E8%AF%A2%E8%BF%87%E7%A8%8B.png" alt="img" loading="lazy"></figure>
<p><strong>总结</strong></p>
<ol>
<li><a href="">客户端</a>首先通过连接器进行<strong>身份认证和权限相关</strong></li>
<li>如果是执行查询语句的时候，<strong>会先查询缓存</strong>，但MySQL 8.0 版本后该步骤移除。</li>
<li>没有命中缓存的话，<strong>SQL 语句就会经过解析器，分析语句，包括语法检查等等</strong>。</li>
<li>通过<strong>优化器</strong>，将用户的SQL语句按照 MySQL 认为最优的方案去执行。</li>
<li><strong>执行语句</strong>，并从存储引擎返回数据。</li>
</ol>
<h2 id="简述mysql优化流程">简述MySQL优化流程</h2>
<ol>
<li>通过<strong>慢日志</strong>定位执行较慢的SQL语句  HOW VARIABLES LIKE '%query%'   查询慢日志相关信息</li>
<li>利用<strong>explain对这些关键字段进行分析</strong></li>
<li>根据分析结果进行优化</li>
</ol>
<h2 id="sql执行顺序">SQL执行顺序</h2>
<pre><code class="language-sql">-- 语法顺序
select distinct 
        &lt;select_list&gt;
from
    &lt;left_table&gt;&lt;join_type&gt;
join &lt;right_table&gt; on &lt;join_condition&gt;
where
    &lt;where_condition&gt;
group by
    &lt;group_by_list&gt;
having
    &lt;having_condition&gt;
order by
    &lt;order_by_condition&gt;
limit &lt;limit number&gt;


-- 执行顺序
1、from &lt;left_table&gt;&lt;join_type&gt;
2、on &lt;join_condition&gt;
3、&lt;join_type&gt; join &lt;right_table&gt;
4、where &lt;where_condition&gt;
5、group by &lt;group_by_list&gt;
6、having &lt;having_condition&gt;
7、select
8、distinct &lt;select_list&gt;
9、order by &lt;order_by_condition&gt;
10、limit &lt;limit_number&gt;
</code></pre>
<h2 id="基本优化">基本优化</h2>
<p>参考</p>
<p>https://mp.weixin.qq.com/s?__biz=Mzg2OTA0Njk0OA==&amp;mid=2247485117&amp;idx=1&amp;sn=92361755b7c3de488b415ec4c5f46d73&amp;chksm=cea24976f9d5c060babe50c3747616cce63df5d50947903a262704988143c2eeb4069ae45420&amp;token=79317275&amp;lang=zh_CN%23rd</p>
<ul>
<li>
<p>数据类型选择：选择能够满足业务需求的最小数据类型。同时对于数值类型，如果没有负数，则使用<code>unsigned</code></p>
</li>
<li>
<p>如果只查询一条记录，如是否存在，需要加上<code>limit</code>阻断后续的查找。</p>
</li>
<li>
<p>禁止使用 SELECT * 必须使用 SELECT &lt;字段列表&gt; 查询统计所有 count（*）会统计值为NULL的行，而count（列名）不会统计值为NULL的行。</p>
</li>
<li>
<p>主键外键约束在<strong>应用层解决</strong>。</p>
</li>
<li>
<p>O<strong>R改写成IN</strong>：OR的效率是n级别，IN的效率是log(n)级别，in的个数建议控制在200以内</p>
</li>
<li>
<p>尽量避免在WHERE子句中使用!=或&lt; &gt;操作符，否则将引擎放弃使用索引而进行全表扫描 &lt;&gt;等价于!=</p>
</li>
<li>
<p>对于连续数值，使用BETWEEN不用IN：SELECT id FROM t WHERE num BETWEEN 1 AND 5</p>
</li>
<li>
<p>单表数据保持在500w以内，如果大了就进行分表</p>
</li>
<li>
<p><strong>禁止数据库中存储图片，图片等二进制数据</strong></p>
</li>
<li>
<p><strong>尽可能把所有列定义为 NOT NULL</strong>：<strong>索引 NULL 列需要额外的空间来保存</strong>，所以要占用更多的空间进行比较和计算时要对 NULL 值做特别的处理</p>
</li>
<li>
<p>财务相关数据使用decimal类型</p>
<ul>
<li><strong>单表索引不要超过5个</strong></li>
</ul>
</li>
<li>
<p><strong>禁止给表的每一列建立单独的索引</strong>。使用联合索引代替</p>
</li>
<li>
<p><strong>建立联合索引</strong>：</p>
<ul>
<li>将区分度高的放在最左侧。（区分度=列中不同值的数量/列的总行数）</li>
<li>尽量把字段长度小的列放在联合索引的最左侧（因为字段长度越小，一页能存储的数据量越大，IO 性能也就越好）</li>
<li>使用最频繁的列放到联合索引的左侧（这样可以比较少的建立一些索引）</li>
</ul>
</li>
<li>
<p><strong>避免使用子查询，可以把子查询优化为 join 操作</strong>：通常子查询在 in 子句中，且子查询中为简单 SQL(不包含 union、group by、order by、limit 从句) 时,才可以把子查询转化为关联查询进行优化。</p>
<ul>
<li><strong>子查询的结果集无法使用索引，通常子查询的结果集会被存储到临时表中，不论是内存临时表还是磁盘临时表都不会存在索引，所以查询性能会受到一定的影响。特别是对于返回结果集比较大的子查询，其对查询性能的影响也就越大</strong>。</li>
</ul>
</li>
<li>
<p>避免使用 JOIN 关联太多的表</p>
</li>
<li>
<p>WHERE 从句中禁止对列进行函数转换和计算</p>
</li>
<li>
<p>超 100 万行的批量写 (UPDATE,DELETE,INSERT) 操作,要分批多次进行操作</p>
<ul>
<li><strong>大批量操作可能会造成严重的主从延迟</strong>：主从环境中,大批量操作可能会造成严重的主从延迟，大批量的写操作一般都需要执行一定长的时间， 而只有当主库上执行完成后，才会在其他从库上执行，所以会造成主库与从库长时间的延迟情况</li>
<li><strong>binlog 日志为 row 格式时会产生大量的日志</strong>：大批量写操作会产生大量日志，特别是对于 row 格式二进制数据而言，由于在 row 格式中会记录每一行数据的修改，我们一次修改的数据越多，产生的日志量也就会越多，日志的传输和恢复所需要的时间也就越长，这也是造成主从延迟的一个原因</li>
<li><strong>避免产生大事务操作</strong>：大批量修改数据，一定是在一个事务中进行的，这就会造成表中大批量数据进行锁定，从而导致大量的阻塞，阻塞会对 MySQL 的性能产生非常大的影响。特别是长时间的阻塞会占满所有数据库的可用连接，这会使生产环境中的其他应用无法连接到数据库，因此一定要注意大批量写操作要进行分批</li>
</ul>
</li>
<li>
<p>将or条件改写成<code>union all</code></p>
</li>
<li>
<p>将<code>xx is not null</code>改写成<code>ifnull((xx,0) &gt; 0)</code></p>
</li>
<li>
<p>少用内联子查询（select后有子查询），因为Sql返回多少行，内联子查询就要执行多少次</p>
</li>
<li>
<p>基于成本的优化器CBO对子查询的处理能力比较弱，可以使用inner join</p>
</li>
</ul>
<h3 id="limit">Limit</h3>
<ul>
<li>
<p>原因：Limit分页时，如<code>limit offset, size</code>会扫描前<code>offset + size</code>行，然后去掉前面的<code>offset</code>行，返回最后的<code>size</code>行。当<code>offset</code>过大的时候，或者有<code>where</code>条件的时候会走全表查询。效率极低。</p>
</li>
<li>
<p>解决方案：</p>
<ul>
<li>
<p>利用<strong>覆盖索引</strong>进行优化：</p>
<ul>
<li>
<pre><code class="language-sql">SELECT * FROM tableName
WHERE id &gt;= (SELECT id FROM tableName ORDER BY id LIMIT 500000 , 1)
LIMIT 2;
-- 其中，id为主键，在子查询中，只查询了id，因此可以利用覆盖索引查询出第500000的id的位置（不用回表查询）。然后通过id走索引会表查询出数据
</code></pre>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="like">Like</h3>
<ul>
<li>
<p>原因：<strong>因为B+树的最左前缀匹配。导致全模糊查询以及左模糊查询无法生效。会触发全表查询。</strong></p>
</li>
<li>
<p><strong>解决方案：</strong></p>
<ul>
<li>
<p><strong>利用覆盖索引优化</strong>（同上，在要模糊的字段上加索引，减少回表查询）：</p>
<ul>
<li>
<pre><code class="language-sql">explain select * from tableName where id in (select id FROM tableName where name like &quot;%searchKey%&quot;);
</code></pre>
</li>
</ul>
</li>
<li>
<p>干掉左边的模糊匹配：<a href="https://jeffkemponoracle.com/2008/01/like-with-wildcard-at-start-can-use-an-index/">参考</a></p>
</li>
<li>
<p>使用全文索引（建立全文索引 + ES分词）：</p>
<ul>
<li>
<pre><code class="language-sql">SELECT * FROM tableName WHERE MATCH(`name`) AGAINST('searchKey')
</code></pre>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="大表优化">大表优化</h3>
<p>当MySQL单表记录数过⼤时，数据库的CRUD性能会明显下降，⼀些常⻅的优化措施如下</p>
<ul>
<li>
<p><strong>限制数据范围</strong>：务必禁止不带任何限制数据范围条件的查询语句。比如:我们当用户在查询订单历史的时候,我们可以控制在一个月的范围内;</p>
</li>
<li>
<p><strong>读写分离</strong>：经典的数据库拆分方案,主库负责写,从库负责读;</p>
</li>
<li>
<p><strong>垂直分区</strong>：<strong>简单来说垂直拆分是指数据表列的拆分,把一张列比较多的表拆分为多张表</strong>。例如,用户表中既有用户的登录信息又有用户的基本信息,可以将用户表拆分成两个单独的表,甚至放到单独的库做分库。（<strong>数据库范式</strong>）</p>
</li>
</ul>
<figure data-type="image" tabindex="7"><img src="https://i.imgtg.com/2023/02/14/dqJLY.png" alt="dqJLY.png" loading="lazy"></figure>
<p>​	<strong>垂直拆分的优点</strong>： 可以使得列数据变⼩，在查询时减少读取的Block数，减少I/O次数。此外，垂直分区可以简化表的结构，易于维护。</p>
<p>​	<strong>垂直拆分的缺点：</strong> 主键会出现冗余，需要管理冗余列，并会引起Join操作，可以通过在应⽤层进⾏Join来解决。此外，垂直分区会让事务变得更加复杂；</p>
<ul>
<li>
<p>保持数据表结构不变,通过某种策略存储数据分片。这样每一片数据分散到不同的表或者库中,达到了分布式的目的。 水平拆分可以支撑非常大的数据量。（<strong>分表</strong>）</p>
</li>
<li>
<p>⽔平分区 ：保持数据表结构不变，通过某种策略存储数据分⽚。这样每⼀⽚数据分散到不同的表或者库中，达到了分布式的⽬的。 ⽔平拆分可以⽀撑⾮常⼤的数据量。⽔平拆分是指数据表⾏的拆分，表的⾏数超过200万⾏时，就会变慢，这时可以把⼀张的表的数<br>
据拆成多张表来存放。举个例⼦：我们可以将⽤户信息表拆分成多个⽤户信息表，这样就可以避免单⼀表数据量过⼤对性能造成影响。</p>
</li>
</ul>
<figure data-type="image" tabindex="8"><img src="https://i.imgtg.com/2023/02/14/dqPuv.png" alt="dqPuv.png" loading="lazy"></figure>
<p>⽔平拆分可以⽀持⾮常⼤的数据量。需要注意的⼀点是：分表仅仅是解决了单⼀表数据过⼤的问题，但由于表的数据还是在同⼀台机器上，其实对于提升MySQL并发能⼒没有什么意义，所以<br>
<strong>⽔平拆分最好分库 。</strong><br>
⽔平拆分能够 <strong>⽀持⾮常⼤的数据量存储，应⽤端改造也少，但 分⽚事务难以解决</strong> ，跨节点Join性能差，逻辑复杂。<strong>尽量不要对数据进⾏分⽚</strong>，<strong>因为拆分会带来逻辑、部署、运维的各种复杂度</strong> ，⼀般的数据表在优化得当的情况下⽀撑千万以下的数据量是没有太⼤问题的。如果实在要分⽚，尽量选择客户端分⽚架构，这样可以减少⼀次和中间件的⽹络I/O。<br>
<strong>下⾯补充⼀下数据库分⽚的两种常⻅⽅案：</strong></p>
<p>​	<strong>客户端代理</strong>： <strong>分⽚逻辑在应⽤端，封装在jar包中，通过修改或者封装JDBC层来实现</strong>。 当<br>
当⽹的 <strong>Sharding-JDBC</strong> 、阿⾥的TDDL是两种⽐᫾常⽤的实现。</p>
<p>​	<strong>中间件代理</strong>： <strong>在应⽤和数据中间加了⼀个代理层。分⽚逻辑统⼀维护在中间件服务中</strong>。 我<br>
们现在谈的 Mycat 、360的Atlas、⽹易的DDB等等都是这种架构的实现。</p>
<h2 id="清理表碎片">清理表碎片</h2>
<h3 id="mysql中删除">Mysql中删除</h3>
<ul>
<li>Mysql可以通过<strong>drop</strong>、<strong>truncate</strong>、<strong>delete</strong>删除数据
<ul>
<li><code>drop table table_name</code>：不管是innoDB还是MyISAM都会立刻释放空间</li>
<li><code>truncate table table_name</code>：不管是innoDB还是MyISAM都会立刻释放空间</li>
<li><code>delete from table_name</code>：删除表的全部数据，对于MyISAM会立刻释放磁盘空间，对于InnoDB不会释放磁盘空间</li>
<li><code>delete from table_name where xxx</code>：带条件的删除，不管是InnoDB还是MyISAM都不会释放磁盘空间</li>
<li><code>delete</code> 操作后，使用<code>optimize table table_name</code>会立即释放磁盘空间，不管是InnoDB还是MyISAM</li>
</ul>
</li>
<li>对于delete的数据虽然没有释放磁盘空间，但是下次插入数据时，仍然可以使用这部分空间。</li>
</ul>
<h3 id="mysql表碎片">Mysql表碎片</h3>
<ul>
<li>产生原因：删除的原因导致的
<ul>
<li>删除一行内容后，该段空间就会变为空白、被留空，在一段时间内的大量删除操作，会是的留空的空间比存储列表内容所使用的空间更大。</li>
<li>执行插入操作时，MySql会尝试使用空白空间，但如果某个空白空间一直没有被大小合适的数据占用，就会产生碎片</li>
</ul>
</li>
<li><strong>当碎片多的时候，将会影响b+树查询性能</strong>（如果是SSD的话则不会）。</li>
</ul>
<h2 id="mysql读取">Mysql读取</h2>
<ul>
<li>Mysql预读：Mysql的<strong>预读分为线性预读（单位为extend）<strong>和</strong>随机预读（单位为页）</strong>
<ul>
<li>线性预读（linear read-ahead）：线性预读的读取单位为extend，可以通过<code>innodb_read_ahead_threshold</code>来指定大小，默认为56。如果一个extend中顺序读取的page大于等于该变量时，MySQL就会把下一个extend预读到buffer pool中（<strong>注意MySql buffer pool的变种LRU机制</strong>）</li>
<li>随机预读（randomread-ahead）：随机预读方式则是表示当同一个extent中的一些page在buffer pool中发现时，Innodb会将该extent中的剩余page一并读到buffer pool中。
<ul>
<li>由于随机预读方式给innodb code带来了一些不必要的复杂性，同时在性能也存在不稳定性，在5.5中已经将这种预读方式废弃，默认是OFF。若要启用此功能，即将配置变量设置innodb_random_read_ahead为ON。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="mvcc">MVCC</h2>
<p>参考https://www.jianshu.com/p/8845ddca3b23</p>
<ul>
<li>
<p>MVCC（Multi-Version Concurrency Control）多版本并发控制，MVCC 是一种并发控制的方法，一般在数据库管理系统中，实现对数据库的并发访问，它在不同的数据库引擎中有不同的实现。MySQL中MVCC只能在Repeatable Read（读可重复读）、Read Committed（读可提交）这两个隔离级别下工作。</p>
<ul>
<li><strong>读提交总是读取数据的最新行</strong>，而不是复合当前事务版本的数据行</li>
<li><strong>序列化会对所有的读取操作加锁</strong></li>
</ul>
</li>
<li>
<p>在MVCC中，删除语句并不会导致要删除的记录真正被删除，而是在丢弃相应的undo log时，才会删除相应的行及索引记录。</p>
</li>
</ul>
<p><strong>实现原理</strong></p>
<ul>
<li>数据库隐藏字段：
<ul>
<li>DB_TRX_ID：6byte，最近修改(修改/插入)事务ID：记录创建这条记录/最后一次修改该记录的事务ID</li>
<li>DB_ROLL_PTR：7byte，回滚指针，指向这条记录的上一个版本（存储于rollback segment里）</li>
<li>DB_ROW_ID：6byte，隐含的自增ID（隐藏主键），如果数据表没有主键，InnoDB会自动以DB_ROW_ID产生一个聚簇索引</li>
</ul>
</li>
</ul>
<h3 id="mysql-mvcc具体实现方式是哪一种">MySQL MVCC具体实现方式是哪一种</h3>
<p>参考:https://blog.csdn.net/SnailMann/article/details/94724197</p>
<p><strong>隐式字段</strong></p>
<p><strong>undo日志</strong></p>
<p><strong>Read View(读视图)</strong></p>
<h3 id="mvcc能解决什么问题好处是">MVCC能解决什么问题，好处是？</h3>
<h4 id="数据库并发场景有三种分别为">数据库并发场景有三种，分别为：</h4>
<ul>
<li>读-读：不存在任何问题，也不需要并发控制</li>
<li>读-写：有线程安全问题，可能会造成事务隔离性问题，可能遇到脏读，幻读，不可重复读</li>
<li>写-写：有线程安全问题，可能会存在更新丢失问题，比如第一类更新丢失，第二类更新丢失</li>
</ul>
<h4 id="mvcc带来的好处是">MVCC带来的好处是？</h4>
<p>**多版本并发控制（MVCC）**是一种用来解决读-写冲突的无锁并发控制，也就是为事务分配单向增长的时间戳，<strong>为每个修改保存一个版本，版本与事务时间戳关联</strong>，读操作只读该事务开始前的数据库的快照。 所以MVCC可以为数据库解决以下问题</p>
<ul>
<li>
<p>在并发读写数据库时，可以做到在读操作时不用阻塞写操作，写操作也不用阻塞读操作，提高了数据库并发读写的性能</p>
</li>
<li>
<p>同时还可以解决脏读，幻读，不可重复读等事务隔离问题，但不能解决<strong>更新丢失问题</strong></p>
</li>
</ul>
<h4 id="小结一下咯">小结一下咯</h4>
<p>总之，MVCC就是因为大牛们，不满意只让数据库采用悲观锁这样性能不佳的形式去解决读-写冲突问题，而提出的解决方案，所以在数据库中，因为有了MVCC，所以我们可以形成两个组合：</p>
<ul>
<li>MVCC + 悲观锁<br>
MVCC解决读写冲突，悲观锁解决写写冲突</li>
<li>MVCC + 乐观锁<br>
MVCC解决读写冲突，乐观锁解决写写冲突<br>
这种组合的方式就可以最大程度的提高数据库并发性能，并解决读写冲突，和写写冲突导致的问题</li>
</ul>
<h3 id="读提交和可重复读都基于mvcc实现有什么区别">读提交和可重复读都基于MVCC实现，有什么区别？</h3>
<p>在可重复读级别下，只会在<strong>事务开始前创建视图</strong>，事务中后续的查询共用一个视图。</p>
<p>而读提交级别下<strong>每个语句执行前都会创建新的视图</strong>。因此对于可重复读，查询只能看到事务创建前就已经提交的数据。</p>
<h2 id="简述mysql中的日志log">简述MySQL中的日志log</h2>
<p><strong>redo log</strong>: 存储引擎级别的log（InnoDB有，MyISAM没有），该<strong>log关注于事务</strong>的<strong>恢复</strong>.在重启mysql服务的时候，根据redo log进行<strong>重做</strong>，从而使事务有<strong>持久性</strong>。</p>
<p><strong>undo</strong> log：是存储引擎级别的log（InnoDB有，MyISAM没有）<strong>保证数据的原子性</strong>，该log保存了事务发生之前的数据的一个版本，可以用于<strong>回滚</strong>，<strong>是MVCC的重要实现方法之一</strong>。</p>
<p><strong>bin log</strong>：数据库级别的log，关注<strong>恢复数据库的数据</strong>。</p>
<h2 id="mysql是如何保证主备一致的">MySQL是如何保证主备一致的</h2>
<p><strong>MySQL通过bin log（二进制日志）实现主备一致</strong>。bin log记录了<strong>所有修改了数据库或可能修改数据库的语句</strong>，而不会记录select、show这种不会修改数据库的语句。</p>
<p>在备份的过程中，<strong>主库A会有一个专门的线程将主库A的bin log发送给 备库B进行备份</strong>。其中bin log有三种记录格式：</p>
<ul>
<li><strong>statement</strong>:记录对数据库进行修改的语句本身，有可能会记录一些额外的相关信息。
<ul>
<li>优点是binlog日志量少，IO压力小，性能较高。</li>
<li>缺点是由于记录的信息相对较少，在不同库执行时由于上下文的环境不同可能导致主备不一致。</li>
</ul>
</li>
<li><strong>row</strong>:记录对数据库做出修改的语句所影响到的数据行以及对这些行的修改。比如当修改涉及多行数据，会把涉及的每行数据都记录到bin log。
<ul>
<li>优点是能够完全的还原或者复制日志被记录时的操作。</li>
<li>缺点是日志量占用空间较大，IO压力大，性能消耗较大。</li>
</ul>
</li>
<li><strong>mixed</strong>:混合使用上述两种模式，一般的语句使用statment方式进行保存，如果遇到一些特殊的函数，则使用row模式进行记录。MySQL自己会判断这条SQL语句是否可能引起主备不一致，如果有可能，就用row格式， 否则就用statement格式。但是在生产环境中，一般会使用row模式。</li>
</ul>
<h2 id="redo-log与bin-log的区别">redo log与bin log的区别？</h2>
<ol>
<li>redo log是<strong>InnoDB引擎特</strong>有的，只记录该引擎中表的<strong>修改记录</strong>。bin log是MySQL的<strong>Server层</strong>实现的，会记录<strong>所有引擎</strong>对数据库的修改。</li>
<li>redo log是<strong>物理</strong>日志，记录的是在具体某个数据页上做了什么修改；bin log是<strong>逻辑</strong>日志，记录的是这个语句的原始逻辑。</li>
<li>redo log是<strong>循环</strong>写的，<strong>空间固定会用完</strong>；bin log是可以追加写入的，bin log文件写到一定大小后会<strong>切换</strong>到下一个，<strong>并不会覆盖以前的日志</strong>。</li>
</ol>
<h2 id="什么时候redo-log会触发写磁盘">什么时候redo log会触发写磁盘</h2>
<p>https://blog.csdn.net/wuzhenwei0419/article/details/105258902/</p>
<h2 id="crash-safe能力是什么">crash-safe能力是什么</h2>
<p>InnoDB通过redo log保证即使数据库发生异常重启，之前<strong>提交的记录</strong>都不会丢失，这个能力称为crash-safe。</p>
<h2 id="wal技术是什么">WAL技术是什么</h2>
<p>WAL的全称是Write-Ahead Logging，它的关键点就是**先写日志，再写磁盘。**事务在提交写入磁盘前，会先写到redo log里面去。如果直接写入磁盘涉及磁盘的随机I/O访问，涉及磁盘随机I/O访问是非常消耗时间的一个过程，相比之下先写入redo log，后面再找合适的时机批量刷盘能提升性能。</p>
<h2 id="两阶段提交是什么">两阶段提交是什么</h2>
<p>为了<strong>保证binl og和redo log两份日志的逻辑一致</strong>，最终保证恢复到主备数据库的数据是一致的，采用两阶段提交的机制。</p>
<ol>
<li>执行器调用存储引擎接口，存储引擎将修改更新到内存中后，将修改操作记录redo log中，此时redo log处于<strong>prepare</strong>状态。</li>
<li>存储引擎告知<strong>执行器执行完毕</strong>，执行器生成这个操作对应的bin log，并把binlog写入磁盘。</li>
<li>执行器调用引擎的<strong>提交事务接口</strong>，引擎把刚刚写入的redo log改成提交<strong>commit</strong>状态，更新完成。</li>
</ol>
<h2 id="只靠bin-log可以支持数据库崩溃恢复吗">只靠bin log可以支持数据库崩溃恢复吗</h2>
<p>不可以。 历史原因：</p>
<ol>
<li>InnoDB在作为MySQL的插件加入MySQL引擎家族之前，就已经是一个提供了崩溃恢复和事务支持的引擎了。InnoDB接入了MySQL后，发现既然bin log没有崩溃恢复的能力，那引入InnoDB原有的redo log来保证崩溃恢复能力。 实现原因：</li>
<li><strong>bin log没有记录数据页修改的详细信息，不具备恢复数据页的能力</strong>。binlog记录着数据行的增删改，但是不记录事务对数据页的改动，这样细致的改动只记录在redo log中。当一个事务做增删改时，其实涉及到的数据页改动非常细致和复杂，包括行的字段改动以及行头部以及数据页头部的改动，甚至b+tree会因为插入一行而发生若干次页面分裂，那么事务也会把所有这些改动记录下来到redo log中。因为数据库系统进程crash时刻，磁盘上面页面镜像可以非常混乱，其中有些页面含有一些正在运行着的事务的改动，而一些已提交的事务的改动并没有刷上磁盘。事务恢复过程可以理解为是要把没有提交的事务的页面改动都去掉，并把已经提交的事务的页面改动都加上去这样一个过程。这些信息，都是binlog中没有记录的，只记录在了存储引擎的redo log中。</li>
<li>操作写入binlog可细分为write和fsync两个过程，write指的就是指把日志写入到文件系统的page cache，并没有把数据持久化到磁盘,fsync才是将数据持久化到磁盘的操作。通过参数设置sync_binlog为0的时候，表示每次提交事务都只write，不fsync。此时数据库崩溃可能导致部分提交的事务以及binlog日志由于没有持久化而丢失。</li>
</ol>
<h2 id="简述mysql主从复制">简述MySQL主从复制</h2>
<p>MySQL提供主从复制功能，可以方便的<strong>实现数据的多处自动备份</strong>，不仅能增加数据库的安全性，还能进行<strong>读写分离</strong>，提升<strong>数据库负载性能</strong>。</p>
<p>主从复制流程：</p>
<ol>
<li>在事务完成之前，主库在<strong>bin log</strong>上记录这些改变，<strong>完成bin log写入过程后，主库通知存储引擎提交事物</strong></li>
<li>从库将主库的bin log复制到对应的中继日志，即开辟一个I/O工作线程，I/O线程在主库上打开一个普通的连接，然后开始bin log dump process，将这些事件写入中继日志。从主库的bin log中读取事件，如果已经读到最新了，线程进入睡眠并等待ma主库产生新的事件。</li>
</ol>
<p><strong>读写分离：即只在MySQL主库上写，只在MySQL从库上读，以减少数据库压力，提高性能。</strong></p>
<h2 id="sql-truncate-delete和drop的异同">SQL truncate 、delete和drop的异同</h2>
<p>https://blog.csdn.net/biglxl/article/details/73301965</p>
<p><strong>相同点</strong></p>
<p>1.truncate和不带where子句的delete、以及drop都会删除表内的数据。</p>
<p>2.drop、truncate都是DDL语句(数据定义语言),执行后会自动提交。</p>
<p><strong>不同点</strong></p>
<p>1.truncate 和 delete 只删除数据不删除表的结构(定义)<br>
drop 语句将删除表的结构被依赖的约束(constrain)、触发器(trigger)、索引(index)；依赖于该表的存储过程/函数将保留,但是变为 invalid 状态（无效状态）。</p>
<p>2.delete 语句是数据库操作语言(dml)，这个操作会放到 rollback segement 中，事务提交之后才生效；如果有相应的 trigger（触发器），执行的时候将被触发。</p>
<p>truncate、drop 是数据库定义语言(ddl)，操作立即生效，原数据不放到 rollback segment 中，不能回滚，操作不触发 trigger（触发器）。<br>
（rollback segment可以理解为是一个存储状态的区域，它相当于保存操作前数据库的状态信息，当操作执行成功后继续存储当前状态，当操作失败时回滚即恢复到操作之前保存的状态）</p>
<p>3.速度，一般来说: drop&gt; truncate &gt; delete<br>
原因：<br>
drop 删除了表的数据及表的结构即从数据库中删除该表<br>
truncate 只删除数据<br>
delete 有条件的删除表中数据（没有条件即没有where语句即删除表中所有数据）</p>
<h2 id="数据模型描述">数据模型描述</h2>
<p>数据模型的组成要素有：</p>
<p>1**.数据结构**，描述数据库的组成对象以及对象之间的联系，数据结构是所描述的对象类型的集合，是对系统静态特征的描述</p>
<p>2.<strong>数据操作</strong>，是指对数据库中各种对象的实例允许执行的操作的集合，主要有查询和更新。</p>
<p>3.<strong>数据的完整性约束条件</strong>，是一组完整性规则的集合。完整性规则是给定的数据模型中数据及其联系所具有的之约和依存规则，用以限定符合数据模型的数据库状态以及状态的变化，以保证数据的正确、有效、相容。</p>
<h2 id="异常">异常</h2>
<p>删除操作异常是指不该删除的数据被删除；</p>
<p>插入操作异常是指应该插入的数据未被插入；</p>
<h2 id="having条件">Having条件</h2>
<p>having和group by 区别</p>
<p>having是对于group by分组后结果进行筛选，group by是进行分组</p>
<p>where 子句和 having子句区别</p>
<p>where是对查询进行限制条件，<strong>having只是对于group by后的结果进行限制</strong></p>
<p>所以用having就一定要和group by连用，且是先group by XXX 再having XXX，用group by不一有having（<strong>它只是一个筛选条件用的</strong>）</p>
<p>where后不可以加聚合函数，但是having可以添加聚合函数</p>
<p><strong>都是实际的比预期操作的少</strong>3</p>
<h2 id="select执行顺序">select执行顺序</h2>
<p>写法顺序：select--from--where--group by--having--order by</p>
<p>执行顺序：from--where--group by--having--select--order by  就是select要放后面，如果有order by，则order by放最后，因为order by 是对结果进行排序</p>
<h2 id="用于调用存储过程的对象">用于调用存储过程的对象</h2>
<p>CallableStatemet 用于调用存储过程的对象</p>
<p><a href="https://www.cnblogs.com/borter/p/9562391.html">Statement和PreparedStatement都是用来发送和执行SQL语句的</a></p>
<p><a href="https://www.cnblogs.com/borter/p/9562403.html">ResultSet是结果集对象</a></p>
<h2 id="sql注入和解决方法">SQL注入和解决方法</h2>
<p><strong>什么是SQL注入？</strong></p>
<p>SQL注入就是在系统登陆窗口或其他一切可输入文本中输入一段SQL语句，由于“SQL注入”是利用未过滤/未审核用户输入的攻击方法，其实就是让应用运行本不应该运行的SQL代码，如果应用毫无防备地创建了SQL字符串并且运行了它们，就会造成一些出人意料的结果。</p>
<p><strong>简单的sql注入语句</strong></p>
<p>String sql = &quot;select * from user_table where username=</p>
<p>' &quot;+userName+&quot; ' and password=' &quot;+password+&quot; '&quot;;</p>
<p>改写成</p>
<p>SELECT * FROM user_table WHERE username=</p>
<p>'’or 1 = 1 -- and password='’</p>
<p><strong>SQL注入解决方法</strong><br>
解决SQL注入问题的关键是对所有可能来自用户输入的数据进行严格的检查、对数据库配置使用最小权限原则。</p>
<p>1、所有的查询语句都使用数据库提供的参数化查询接口，参数化的语句使用参数而不是将用户输入变量嵌入到SQL语句中。当前几乎所有的数据库系统都提供了参数化SQL语句执行接口，使用此接口可以非常有效的防止SQL注入攻击。</p>
<p>​	MyBatis提供了两种支持动态 sql 的语法 #{} 和 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mrow></mrow><mi mathvariant="normal">，</mi><mi mathvariant="normal">其</mi><mi mathvariant="normal">中</mi></mrow><annotation encoding="application/x-tex">{}，其中</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0em;vertical-align:0em;"></span><span class="mord"></span><span class="mord cjk_fallback">，</span><span class="mord cjk_fallback">其</span><span class="mord cjk_fallback">中</span></span></span></span>{} 是简单的<a href="https://so.csdn.net/so/search?q=%E5%AD%97%E7%AC%A6%E4%B8%B2%E6%9B%BF%E6%8D%A2&amp;spm=1001.2101.3001.7020">字符串替换</a>，而 #{} 在预处理时，会把参数部分用一个占位符 ? 代替，可以有效的防止sql的注入</p>
<p>2、对进入数据库的特殊字符（’”\尖括号&amp;*;等）进行转义处理，或编码转换。</p>
<p>3、严格限制变量类型，比如整型变量就采用intval()函数过滤，数据库中的存储字段必须对应为int型。</p>
<p>4、数据长度应该严格规定，能在一定程度上防止比较长的SQL注入语句无法正确执行。</p>
<p>5、网站每个数据层的编码统一，建议全部使用UTF-8编码，上下层编码不一致有可能导致一些过滤模型被绕过。</p>
<p>6、严格限制网站用户的数据库的操作权限，给此用户提供仅仅能够满足其工作的权限，从而最大限度的减少注入攻击对数据库的危害。</p>
<p>7、避免网站显示SQL错误信息，比如类型错误、字段不匹配等，防止攻击者利用这些错误信息进行一些判断。</p>
<p>8、在网站发布之前建议使用一些专业的SQL注入检测工具进行检测，及时修补这些SQL注入漏洞。</p>
<p>9、确认PHP配置文件中的magicquotesgpc选项保持开启</p>
<h2 id="log日志有几个级别">log日志有几个级别</h2>
<p>https://blog.csdn.net/jYF_666/article/details/102776645</p>
<p>log4j定义了8个级别的log（除去OFF和ALL，可以说分为6个级别），优先级从高到低依次为：OFF、FATAL、ERROR、WARN、INFO、DEBUG、TRACE、 ALL。<br>
Log4j建议只使用四个级别，优先级从高到低分别是 <strong>ERROR、WARN、INFO、DEBUG</strong>。</p>
<h2 id="mysql常用函数">Mysql常用函数</h2>
<p>https://www.bilibili.com/read/cv3838568/</p>
<p>1.<strong>聚合函数</strong><br>
聚合函数是平时比较常用的一类函数，这里列举如下：</p>
<p>COUNT(col)   统计查询结果的行数</p>
<p>MIN(col)   查询指定列的最小值</p>
<p>MAX(col)   查询指定列的最大值</p>
<p>SUM(col)   求和，返回指定列的总和</p>
<p>AVG(col)   求平均值，返回指定列数据的平均值</p>
<p>2.<strong>数值型函数</strong><br>
数值型函数主要是对数值型数据进行处理，得到我们想要的结果，常用的几个列举如下，具体使用方法大家可以试试看。</p>
<p>ABS(x)   返回x的绝对值</p>
<p>BIN(x)   返回x的二进制</p>
<p>CEILING(x)   返回大于x的最小整数值</p>
<p>EXP(x)   返回值e（自然对数的底）的x次方</p>
<p>FLOOR(x)   返回小于x的最大整数值</p>
<p>GREATEST(x1,x2,...,xn)   返回集合中最大的值</p>
<p>LEAST(x1,x2,...,xn)   返回集合中最小的值</p>
<p>LN(x)   返回x的自然对数</p>
<p>LOG(x,y)   返回x的以y为底的对数</p>
<p>MOD(x,y)   返回x/y的模（余数）</p>
]]></content>
    </entry>
</feed>